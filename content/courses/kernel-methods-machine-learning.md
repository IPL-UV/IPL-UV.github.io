---
title: "Kernel Methods in Machine Learning"
img: "sskpls.webp"
image_alt: "sskpls"
link: "https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/kernel_course.zip"
---

**Course Duration:** 30 hours  
**Instructor:** G. Camps-Valls

Two fundamental operations in Machine Learning such as regression and classification involve drawing nonlinear boundaries or functions through a set of (labeled or unlabeled) training samples. These boundaries or functions at certain (test) samples can be deduced from the similarities between the test sample and the training samples. These similarities can be encoded in Kernels, and the representer theorem can be used to obtain expressions for the functions at any test sample. In this course, we will also review the application of the kernelization of scalar products (e.g., as in the covariance matrix) to obtain nonlinear generalizations of classical feature extraction methods.