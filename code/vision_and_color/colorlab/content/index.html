<!doctype html><html lang=en-us dir=ltr><head><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin=anonymous referrerpolicy=no-referrer><link rel="shortcut icon" href=/images/favicon.ico type=image/x-icon><link rel=stylesheet href=/style/style.css><script src=/js/mode.js></script><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js></script></head></head><nav class="navbar navbar-expand-lg bg-body-tertiary fixed-top"><div class=container-fluid><a href=./ class="d-lg-none d-flex align-items-center a_logonav"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" height=30 class=logo_nav>
<span class="ms-2 text-isp">ISP</span>
</a><button class="navbar-toggler ms-auto" type=button data-bs-toggle=collapse data-bs-target=#navbarTogglerDemo01 aria-controls=navbarTogglerDemo01 aria-expanded=false aria-label="Toggle navigation" style=height:40px>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarTogglerDemo01><ul class="navbar-nav mx-auto mb-lg-0"><li class="nav-item px-2 nav-item-highlight d-none d-lg-block"><a class="nav-link a" aria-current=page href=/>ISP</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/people/>People</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle a" href=/research/philosophy id=navbarDropdownResearch role=button aria-expanded=false>Research</a><ul class=dropdown-menu aria-labelledby=navbarDropdownResearch><li><a class="dropdown-item a" href=/research/machine_learning/>Machine learning</a></li><li><a class="dropdown-item a" href=/research/visual_neuroscience/>Visual neuroscience</a></li><li><a class="dropdown-item a" href=/research/visual_brain/>Visual brain</a></li><li><a class="dropdown-item a" href=/research/earth_science/>Earth science</a></li><li><a class="dropdown-item a" href=/research/social_science>Social science</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/projects/>Projects</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/facilities/>Facilities</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle a" href=/publications/journals/ id=navbarDropdownPublications role=button aria-expanded=false>Publications</a><ul class=dropdown-menu aria-labelledby=navbarDropdownPublications><li><a class="dropdown-item a" href=/publications/journals/>Journals</a></li><li><a class="dropdown-item a" href=/publications/conferences/>Conferences</a></li><li><a class="dropdown-item a" href=/publications/books/>Books</a></li><li><a class="dropdown-item a" href=/publications/talks/>Talks</a></li><li><a class="dropdown-item a" href=/publications/technical_reports/>Technical Reports</a></li><li><a class="dropdown-item a" href=/publications/theses/>Theses</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/code/>Code</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/data/>Data</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/seminars/>Seminars</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/courses/>Courses</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/collaborators/>Collaborators</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/news/>News</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/contact/>Contact</a></li></ul></div></div></nav><style>.navbar{--bs-navbar-padding-y:0rem !important;background-color:#222!important}.a{color:#949494!important}.a:hover{color:#fff!important}.nav-item-highlight{padding:.4rem}.nav-item-highlight:hover{background-color:#2d70aa!important}.dropdown-menu{background-color:#333!important;color:#fff!important;display:block}.dropdown-item{color:#949494!important}.dropdown-item:hover{background-color:#2d70aa!important;color:#fff!important}.navbar-nav li.nav-item .nav-link,.dropdown-menu .dropdown-item{transition:color .3s,background-color .3s}.nav-link.active,.dropdown-item.active{color:#fff!important;background-color:#007bff!important}.navbar-toggler-icon{background-image:url("data:image/svg+xml,%3csvg viewBox='0 0 30 30' xmlns='http://www.w3.org/2000/svg'%3e%3cpath stroke='white' stroke-width='2' stroke-linecap='round' stroke-miterlimit='10' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e")}.navbar-toggler{border:none}.navbar-toggler:focus{outline:none}@media(min-width:992px){.dropdown-menu{display:none}.dropdown:hover .dropdown-menu{display:block}}@media(max-width:991px){.navbar-nav{max-height:calc(100vh - 56px);overflow-y:auto}.navbar-nav::-webkit-scrollbar{width:9px}.navbar-nav::-webkit-scrollbar-thumb{background-color:#888;border-radius:10px}.navbar-nav::-webkit-scrollbar-thumb:hover{background-color:#555}.navbar-nav .nav-link{font-size:1.2rem}.dropdown-menu .dropdown-item{font-size:1rem}.dropdown-toggle::after{display:inline-block;margin-left:.255em;vertical-align:.255em;content:"";border-top:.3em solid;border-right:.3em solid transparent;border-bottom:0;border-left:.3em solid transparent}.navbar .dropdown-toggle::after{content:none!important}.navbar-toggler-icon{width:1.2em;height:1.2em}.navbar-toggler{border:none!important}.navbar-toggler:focus{box-shadow:none!important}.d-flex{height:45px}.a_logonav{text-decoration:none!important}.text-isp{font-size:1.3rem;color:#9d9d9d;display:inline-block;vertical-align:middle;text-decoration:none!important}.navbar-nav{max-height:calc(50vh - 56px);overflow-y:auto}}</style><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll(".navbar .dropdown");e.forEach(function(e){let t=e.querySelector(".dropdown-toggle");t.addEventListener("click",function(e){window.innerWidth<992&&e.target===t&&(window.location.href=t.href)});let n=e.querySelectorAll(".dropdown-item");n.forEach(function(e){e.addEventListener("click",function(){window.location.href=e.href})})}),document.addEventListener("click",function(t){window.innerWidth<992&&!t.target.closest(".navbar .dropdown")&&e.forEach(function(e){e.querySelector(".dropdown-menu").classList.remove("show")})})})</script><main><div class=container><div class="content-container grid-layout"><div class=box-header><h1>ColorLab: The Matlab Toolbox for Colorimetry and Color Vision</h1></div><div class=box-abstract><p><p><strong>ColorLab</strong> is a color computation and visualization toolbox to be used in the MATLAB environment. <strong>ColorLab</strong> is intended to deal with color in general-purpose quantitative colorimetric applications as color image processing and psychophysical experimentation.</p><p><strong>ColorLab</strong> uses colorimetrically meaningful representations of color and color images (tristimulus values, chromatic coordinates and luminance, or, dominant wavelength, purity and luminance), in any primaries system of the tristimulus colorimetry (including CIE standards as CIE XYZ or CIE RGB). <strong>ColorLab</strong> relates this variety of colorimetric representations to the usual device-dependent discrete-color representation, i.e. it solves the problem of displaying a colorimetrically specified scene in the monitor within the accuracy of the VGA.</p><p>A number of other interesting color representations are also provided, as CIE uniform color spaces (as CIE Lab and CIE Luv, opponent color representations based on advanced color vision models, and color appearance representations (RLab, LLab, SVF and CIECAMs). All these representations are invertible, so the result of image processing made in these colorimetrically meaningful representations can always be inverted back to the tristimulus representation at hand, and be displayed. <strong>ColorLab</strong> includes useful visualization routines to represent colors in the tristimulus space or in the chromatic diagram of any color basis, as well as an advanced vector quantization scheme for color palette design. An extensive color data base is also included, with the CIE 1931 color matching functions, reflectance data of 1250 chips from the Munsell Book of Color, McAdam ellipses, normalized spectra of a number of standard CIE illuminants, matrices to change to a number of tristimulus representations, and calibration data of an ordinary CRT monitor.</p><p>The standard tools in ColorLab (and in <a href=./../vistalab><strong>VistaLab</strong></a>) are the necessary building blocks to develop more sophisticated vision models included in the dedicated site <a href=./../vistamodels><strong>VistaModels</strong></a>.</p><h1 id=table-of-contents>Table of Contents</h1><ul><li><a href=#colorfulness-edition-using-the-purity>Colorfulness edition using the purity</a></li><li><a href=#hue-based-segmentation-and-edition-using-the-dominant-wavelength>Hue-based segmentation and edition using the dominant wavelength</a></li><li><a href=#luminance-edition-in-cd/m2>Luminance edition in cd/m2</a></li><li><a href=#changing-the-spectral-illumination-standard-and-user-defined-illuminants>Changing the spectral illumination (standard and user defined illuminants)</a></li><li><a href=#playing-with-mcadam-ellipses-and-munsell-chips>Playing with McAdam ellipses and Munsell chips</a></li><li><a href=#chromatic-induction-in-llab>Chromatic induction in LLab</a></li></ul><h1 id=colorfulness-edition-using-the-purity>Colorfulness edition using the purity</h1><p>Colorimetric Purity and Excitation Purity are the descriptors of colorfulness in Tristimulus Colorimetry. Both of them are available in ColorLab. In the example below we analyze the colors of an image in the CIE XYZ system and reduce the excitation purity by a constant factor leaving the luminace and the dominant wavelength unaltered in order to obtain an image with reduced colorfulness. Other posibilities to obtain this effect with ColorLab include using any other tristimulus representations or changing the colorfulness descriptors in a number of available non-linear color appearance models.</p><h1 id=hue-based-segmentation-and-edition-using-the-dominant-wavelength>Hue-based segmentation and edition using the dominant wavelength</h1><p>The Dominant Wavelength is the descriptor of hue in Tristimulus Colorimetry. In the example below we first segment the flowers by selecting a range of wavelenghts (in the CIE XYZ chromatic diagram) and then, we modify their hue by applying a rotation to the chromatic coordinates. Other posibilities to obtain this effect with ColorLab include using any other tristimulus representation or changing (rotating) the hue descriptor in a number of available non-linear color appearance models.</p><h1 id=luminance-edition-in-cdm24>Luminance edition in cd/m24</h1><p>The Luminance is the descriptor of brightness in Tristimulus Colorimetry. In the example below we reduce the luminance by reducing the lenght of the tristimulus vectors by a constant factor in an arbitrary (RBG) tristimulus space (note how the chromatic diagram is twisted). Of course the chromatic coordinates remain the same (as can be seen in the figures below). Other posibilities to obtain this effect with ColorLab include using any other tristimulus representation or changing the brightness descriptor in a number of available non-linear color appearance models.</p><h1 id=changing-the-spectral-illumination-standard-and-user-defined-illuminants>Changing the spectral illumination (standard and user defined illuminants)</h1><p>ColorLab is able to deal with the spectro-radiometric description of color images or estimate it from their (usual) colorimetric description by using the Munsell reflectances data set. In this way, the effect of changing the spectral radiance of the illuminant may be simulated by obtaining the new tristimulus values with the new illuminant. In the example below, each pixel of the original image is assumed to be a patch with a given (or estimated) reflectance under white light illumination. The user may define a different illuminant (in this case a purple radiation) and apply it to the reflectances, thus obtaining the new image and the new (tristimulus) colors. Of course, this can be done in any tristimulus representation. But, better than that, if non-linear color appearance models are used together with the corresponding pair procedure [JOSA A 04], color constancy may be predicted!.</p><h1 id=playing-with-mcadam-ellipses-and-munsell-chips>Playing with McAdam ellipses and Munsell chips</h1><p>Now you can easily check the non-uniformity of the tristimulus space in your computer screen! As ColorLab comes with the McAdam ellipses database and the Munsell chips database, its color reproduction ability allows you to generate the right colors to prove that your discrimination is not Euclidean.
In the first example below, we distort two given colors (green and blue) in by a constant factor in the chromatic diagram in the principal directions of the ellipsoids. Despite the eventual inaccuracies introduced by the use of a generic calibration, it is clear that blues are more different each other (the ellipse is smaller!) and the distortion in every case is more noticeable when it is done in the short direction of the ellipse.
The second example shows a set of Munsell chips of different chroma which are chosen to depart each other a constant number of JNDs.</p><h1 id=chromatic-induction-in-llab>Chromatic induction in LLab</h1><p>The perception of a test is modified by the stimuli in the surround. This is referred to as chromatic induction. In the example below, the (physically constant) gray test in the center changes its hue to blueish as the surround gets more yellow. Non-linear color appearance models are required to understand this effect.</p><h2 id=key-capabilities>Key Capabilities</h2><ul><li><strong>Visualization</strong>: Visualize color in tristimulus spaces or chromatic diagrams.</li><li><strong>Transformation</strong>: Move between tristimulus and non-linear color models like CIECAM.</li><li><strong>Quantitative Processing</strong>: Apply functions for color purity, luminance, and hue manipulation.</li><li><strong>Extensive Color Database</strong>: Includes CIE color matching functions, Munsell chips, McAdam ellipses, and more.</li></ul><h2 id=download-colorlab>Download ColorLab</h2><ul><li><strong>Toolbox</strong>: <a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Colorlab.zip>Colorlab.zip (15MB)</a></li><li><strong>User Guide</strong>: <a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/COLORLAB_userguide.pdf>ColorLab_userguide.pdf (12MB)</a></li></ul></p></div><aside class=box-gallery><div class=gallery-grid><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/colorlab1.webp","[Samples of the Munsell Book of Color illuminated](#the-matlab-toolbox-for-colorimetry-and-color-vision)","Samples of the Munsell Book of Color illuminated using CIE standard illuminants D65 (top) and A (bottom). ColorLab comes with many spectral reflectances and spectral radiances of standard sources and objects. These can be used as input data to solve the corresponding pair problem [[Neur.Comp.12](https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Neco_accepted_2012.pdf), [PLoS ONE 14](https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Gutmann_PLOS_ONE_2014.pdf)].")'><img src=/images/code/colorlab1.webp alt="[Samples of the Munsell Book of Color illuminated](#the-matlab-toolbox-for-colorimetry-and-color-vision)"></a><p class=gallery-title><a href=#the-matlab-toolbox-for-colorimetry-and-color-vision>Samples of the Munsell Book of Color illuminated</a></p><div class=gallery-description><p>Samples of the Munsell Book of Color illuminated using CIE standard illuminants D65 (top) and A (bottom). ColorLab comes with many spectral reflectances and spectral radiances of standard sources and objects. These can be used as input data to solve the corresponding pair problem [<a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Neco_accepted_2012.pdf>Neur.Comp.12</a>, <a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Gutmann_PLOS_ONE_2014.pdf>PLoS ONE 14</a>].</p></div></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/colorlab2.webp","[Pairs predicted with standard CIELab and CIECAM](#the-matlab-toolbox-for-colorimetry-and-color-vision)","Corresponding pairs predicted with standard CIELab and CIECAM (implemented in Colorlab, left) are compared with our statistically-based algorithms: the nonlinear Sequential Principal Curves Analysis (top-right) [Neur.Comp.12](https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Neco_accepted_2012.pdf), and the linear Higher Order Canonical Correlation Analysis (bottom-right) [PLoS ONE 14](https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Gutmann_PLOS_ONE_2014.pdf).")'><img src=/images/code/colorlab2.webp alt="[Pairs predicted with standard CIELab and CIECAM](#the-matlab-toolbox-for-colorimetry-and-color-vision)"></a><p class=gallery-title><a href=#the-matlab-toolbox-for-colorimetry-and-color-vision>Pairs predicted with standard CIELab and CIECAM</a></p><div class=gallery-description><p>Corresponding pairs predicted with standard CIELab and CIECAM (implemented in Colorlab, left) are compared with our statistically-based algorithms: the nonlinear Sequential Principal Curves Analysis (top-right) <a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Neco_accepted_2012.pdf>Neur.Comp.12</a>, and the linear Higher Order Canonical Correlation Analysis (bottom-right) <a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Gutmann_PLOS_ONE_2014.pdf>PLoS ONE 14</a>.</p></div></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/colorfulness.webp","[Desaturating clock](#colorfulness-edition-using-the-purity)","Colorimetric Purity and Excitation Purity are the descriptors of colorfulness in Tristimulus Colorimetry. Both of them are available in ColorLab. In the example below we analyze the colors of an image in the CIE XYZ system and reduce the excitation purity by a constant factor leaving the luminace and the dominant wavelength unaltered in order to obtain an image with reduced colorfulness. Other posibilities to obtain this effect with ColorLab include using any other tristimulus representations or changing the colorfulness descriptors in a number of available non-linear color appearance models.")'><img src=/images/code/colorfulness.webp alt="[Desaturating clock](#colorfulness-edition-using-the-purity)"></a><p class=gallery-title><a href=#colorfulness-edition-using-the-purity>Desaturating clock</a></p><div class=gallery-description><p>Colorimetric Purity and Excitation Purity are the descriptors of colorfulness in Tristimulus Colorimetry. Both of them are available in ColorLab. In the example below we analyze the colors of an image in the CIE XYZ system and reduce the excitation purity by a constant factor leaving the luminace and the dominant wavelength unaltered in order to obtain an image with reduced colorfulness. Other posibilities to obtain this effect with ColorLab include using any other tristimulus representations or changing the colorfulness descriptors in a number of available non-linear color appearance models.</p></div></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/hue1.webp","[Artificial Flowers (Original)](#hue-based-segmentation-and-edition-using-the-dominant-wavelength)","Red flowers are segmented by selecting the colors in a certain range of dominant wavelengths.")'><img src=/images/code/hue1.webp alt="[Artificial Flowers (Original)](#hue-based-segmentation-and-edition-using-the-dominant-wavelength)"></a><p class=gallery-title><a href=#hue-based-segmentation-and-edition-using-the-dominant-wavelength>Artificial Flowers (Original)</a></p><div class=gallery-description><p>Red flowers are segmented by selecting the colors in a certain range of dominant wavelengths.</p></div></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/hue2.webp","[Artificial Flowers (Modified)](#hue-based-segmentation-and-edition-using-the-dominant-wavelength)","Rotation of the corresponding chromatic coordinates leads to a series of artificial flowers.")'><img src=/images/code/hue2.webp alt="[Artificial Flowers (Modified)](#hue-based-segmentation-and-edition-using-the-dominant-wavelength)"></a><p class=gallery-title><a href=#hue-based-segmentation-and-edition-using-the-dominant-wavelength>Artificial Flowers (Modified)</a></p><div class=gallery-description><p>Rotation of the corresponding chromatic coordinates leads to a series of artificial flowers.</p></div></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/luminance.webp","[Marilyn in dim light](#luminance-edition-in-cd/m2)","The reduction in the length of the tristimulus does not change the intersection with the chromatic diagram.")'><img src=/images/code/luminance.webp alt="[Marilyn in dim light](#luminance-edition-in-cd/m2)"></a><p class=gallery-title><a href=#luminance-edition-in-cd/m2>Marilyn in dim light</a></p><div class=gallery-description><p>The reduction in the length of the tristimulus does not change the intersection with the chromatic diagram.</p></div></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/irradiance.webp","[The pink room key](#changing-the-spectral-illumination-standard-and-user-defined-illuminants)","Digital images can be turned into spectral arrays and these can be illuminated with customized light.")'><img src=/images/code/irradiance.webp alt="[The pink room key](#changing-the-spectral-illumination-standard-and-user-defined-illuminants)"></a><p class=gallery-title><a href=#changing-the-spectral-illumination-standard-and-user-defined-illuminants>The pink room key</a></p><div class=gallery-description><p>Digital images can be turned into spectral arrays and these can be illuminated with customized light.</p></div></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/mcadam.webp","[Color discrimination (McAdam ellipses, top) and Uniformly distributed colors (Munsell chips, bottom)](#playing-with-mcadam-ellipses-and-munsell-chips)","Color discrimination (McAdam ellipses, top): Bigger discrimination in the blue-purple region than in the green region. Anisotropic JNDs in color is an example of the MAximum Differentiation (MAD) concept [Malo & Simoncelli SPIE 15](https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/malo15a-reprint.pdf). Uniformly distributed colors (Munsell chips, bottom): Constant perceptual differences in Munsell chips imply they distribute in ellipsoids around the white point similarly to the corresponding McAdam ellipse.")'><img src=/images/code/mcadam.webp alt="[Color discrimination (McAdam ellipses, top) and Uniformly distributed colors (Munsell chips, bottom)](#playing-with-mcadam-ellipses-and-munsell-chips)"></a><p class=gallery-title><a href=#playing-with-mcadam-ellipses-and-munsell-chips>Color discrimination (McAdam ellipses, top) and Uniformly distributed colors (Munsell chips, bottom)</a></p><div class=gallery-description><p>Color discrimination (McAdam ellipses, top): Bigger discrimination in the blue-purple region than in the green region. Anisotropic JNDs in color is an example of the MAximum Differentiation (MAD) concept <a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/malo15a-reprint.pdf>Malo & Simoncelli SPIE 15</a>. Uniformly distributed colors (Munsell chips, bottom): Constant perceptual differences in Munsell chips imply they distribute in ellipsoids around the white point similarly to the corresponding McAdam ellipse.</p></div></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/color_junto.webp","[Prediction of induced color with LLab](#chromatic-induction-in-llab)","The Llab non-linear color representation was used to compute the corresponding colors of the central test in a gray surround. The results are shown in the CIE xy diagram. Note that as the surround increases the colorfulness, an oposite reaction is induced in the test. This numerical result was used to generate a set of different stimuli in a constant gray background giving rise to the same perception as the central test on a changing background (see below).")'><img src=/images/code/color_junto.webp alt="[Prediction of induced color with LLab](#chromatic-induction-in-llab)"></a><p class=gallery-title><a href=#chromatic-induction-in-llab>Prediction of induced color with LLab</a></p><div class=gallery-description><p>The Llab non-linear color representation was used to compute the corresponding colors of the central test in a gray surround. The results are shown in the CIE xy diagram. Note that as the surround increases the colorfulness, an oposite reaction is induced in the test. This numerical result was used to generate a set of different stimuli in a constant gray background giving rise to the same perception as the central test on a changing background (see below).</p></div></div><div id=imageModal class=modal><span class=modal-close onclick=closeModal()>&#215;</span>
<img class=modal-content id=modalImage><div id=modalCaption class=modal-caption></div></div></div></aside><section class="box-references title2"><h2>References</h2><ul class=references-list><li><strong><a href=# target=_blank class=references-name>ColorLab: the Matlab toolbox for Colorimetry and Color Vision. Univ. Valencia 2002</a></strong><br><span>J. Malo & M.J. Luque.</span><br><em></em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/josa_04.pdf target=_blank class=references-name>Corresponding-pair procedure: a new approach to simulation of dichromatic color perception</a></strong><br><span>P. Capilla, M. Diez, M.J. Luque, & J. Malo</span><br><em>JOSA A 21(2): 176-186 (2004)</em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Neco_accepted_2012.pdf target=_blank class=references-name>Nonlinearities and Adaptation of Color Vision from Sequential Principal Curves Analysis</a></strong><br><span>V. Laparra, S. Jimenez, G. Camps & J. Malo</span><br><em>Neural Computation 24(10): 2751-2788 (2012)</em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Gutmann_PLOS_ONE_2014.pdf target=_blank class=references-name>Spatio-Chromatic Adaptation via Higher-Order Canonical Correlation Analysis of Natural Images</a></strong><br><span>M. Gutmann, V. Laparra, A. Hyvarinen & J. Malo</span><br><em>PLoS ONE 9(2): e86481 (2014)</em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/LaparraMalo15.pdf target=_blank class=references-name>Visual aftereffects and sensory nonlinearities from a single statistical framework</a></strong><br><span>V. Laparra & J. Malo</span><br><em>Frontiers in Human Neuroscience 9:557 (2015)</em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Luque06.pdf target=_blank class=references-name>Effect of a Yellow Filter on Brightness Evaluated by Asymmetric Matching: Measurements and Predictions</a></strong><br><span>M.J. Luque, et al.</span><br><em>J. Opt. A - Pure Appl. Opt. (Inst. of Physics), 8 (5): 398-408 (2006)</em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Chorro09.pdf target=_blank class=references-name>Analyzing the metrics of the perceptual space in a new multistage physiological colour vision model</a></strong><br><span>E. Chorro, F.M. Martínez‐Verdú, D. de Fez, P. Capilla, & M.J. Luque</span><br><em>Color Res. Appl., 34: 359-366 (2009)</em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Luque10.pdf target=_blank class=references-name>Images Perceived after Chromatic or Achromatic Contrast Sensitivity Losses</a></strong><br><span>M.J. Luque, et al.</span><br><em>Optom. Vision Sci., 87 (5): 313-322 (2010)</em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Capilla12.pdf target=_blank class=references-name>Simulating Images Seen by Patients with Inhomogeneous Sensitivity Losses</a></strong><br><span>P. Capilla, M.J. Luque, M. Diez</span><br><em>Optom. Vision Sci., 89 (10): 1543-1556 (2012)</em></li><li><strong><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Luque14.pdf target=_blank class=references-name>Software for simulating dichromatic perception of video streams</a></strong><br><span>M.J. Luque, D. de Fez, & P. Acevedo</span><br><em>Color Res. Appl., 39: 486-491 (2014)</em></li></ul></section><section class="box-enlaces title2"><h2>Download</h2><ul class=enlaces-list><li><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Colorlab.zip>Matlab Toolbox (version 4.0)</a></li><li><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/COLORLAB_userguide.pdf>Colorlab User Guide</a></li></ul></section></div></div></main></body><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js@1.0.0/src/bibtex_js.min.js defer></script></html>