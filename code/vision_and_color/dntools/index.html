<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><link rel="shortcut icon" href=/images/isp_ico.webp type=image/x-icon><link href=https://fonts.cdnfonts.com/css/twentieth-century-for-kenmore rel=stylesheet><link rel=stylesheet href=/style/style.css><link rel=stylesheet href=/style/bootstrap-cosmo.min.css><link rel=stylesheet href=/style/bootstrap-theme.css><link rel=stylesheet href=/style/bootstrap.css><link rel=stylesheet href=/style/bootstrap.min.css><link rel=stylesheet href=/style/bootswatch.min.css><script src=/js/mode.js></script><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-D8CVQKS51G"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D8CVQKS51G")</script></head><body><nav class=custom-navbars><div class=custom-container><a href=/ class="custom-logo custom-hide-on-large"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" class=custom-logo_nav>
<span class=custom-text-isp>ISP</span>
</a><button class=navbar-toggler aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class=custom-navbar-collapse><ul class=custom-navbar-nav><li class="custom-nav-item custom-desktop-only"><a class=custom-nav-link href=/>ISP</a></li><li class=custom-nav-item><a class=custom-nav-link href=/people/>People</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/research/philosophy/>Research</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/research/philosophy/>Philosophy</a></li><li><a class=custom-dropdown-item href=/research/machine_learning/>Machine learning</a></li><li><a class=custom-dropdown-item href=/research/visual_neuroscience/>Visual science</a></li><li><a class=custom-dropdown-item href=/research/visual_brain/>Image processing</a></li><li><a class=custom-dropdown-item href=/research/earth_science/>Earth science</a></li><li><a class=custom-dropdown-item href=/research/social_science>Social science</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/projects/>Projects</a></li><li class=custom-nav-item><a class=custom-nav-link href=/facilities/>Facilities</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/publications/journals/>Publications</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/publications/journals/>Journals</a></li><li><a class=custom-dropdown-item href=/publications/conferences/>Conferences</a></li><li><a class=custom-dropdown-item href=/publications/books/>Books</a></li><li><a class=custom-dropdown-item href=/publications/talks/>Talks</a></li><li><a class=custom-dropdown-item href=/publications/theses/>Theses</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/code/>Code</a></li><li class=custom-nav-item><a class=custom-nav-link href=/data/>Data</a></li><li class=custom-nav-item><a class=custom-nav-link href=/seminars/>Seminars</a></li><li class=custom-nav-item><a class=custom-nav-link href=/courses/>Courses</a></li><li class=custom-nav-item><a class=custom-nav-link href=/collaborators/>Collaborators</a></li><li class=custom-nav-item><a class=custom-nav-link href=/news/>News</a></li><li class=custom-nav-item><a class=custom-nav-link href=/contact/>Contact</a></li></ul></div></div></nav><main><div class=container><div class=content-container><div class=grid-container id=grid-container><div class=grid-item><a href><img src=/images/code alt="Psychophysically Tuned Divisive Normalization Approximately. Factorizes the PDF of Natural Images. V. Laparra and J. Malo."></a><div class=text><a href class=nameLink_a>Psychophysically Tuned Divisive Normalization Approximately. Factorizes the PDF of Natural Images. V. Laparra and J. Malo.</a><p><p>The conventional approach in Computational Neuroscience in favor of the efficient coding hypothesis goes from image statistics to perception. It has been argued that the behavior of the early stages of biological visual processing (e.g. spatial frequency analyzers and their non-linearities) may be obtained from image samples and the efficient coding hypothesis using no psychophysical or physiological information.</p><p>In this work we address the same issue in the opposite direction, from perception to image statistics: we show that psychophysically fitted image representation in V1 has appealing statistical properties, e.g. approximate PDF factorization and substantial mutual information reduction, even though no statistical information is used to fit the V1 model. These results are a complementary evidence in favor of the efficient coding hypothesis.</p></p></div></div></div><p>DNTools is a MATLAB toolbox that models texture perception using Orthonormal Wavelets and Divisive Normalization. It simulates a V1 cortex model tuned to image quality opinions and is found to perform non-linear ICA on natural images.</p></div></div></main></body><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script></html>