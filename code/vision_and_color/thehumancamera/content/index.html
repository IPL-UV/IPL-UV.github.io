<!doctype html><html lang=en-us dir=ltr><head><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous><link rel="shortcut icon" href=/images/favicon.ico type=image/x-icon><link rel=stylesheet href=/github/style/style.min.f7dd1c60a6cdba402b3b03b09262e8921a1b461c6157b54a640584ac10ed246e.css integrity="sha256-990cYKbNukArOwOwkmLokhobRhxhV7VKZAWErBDtJG4=" crossorigin=anonymous><script src=/github/js/mode.f2979a93a325fecf9605263bd141398a311c8e23388ed7dcff74f92f7e632866.js integrity="sha256-8peak6Ml/s+WBSY70UE5ijEcjiM4jtfc/3T5L35jKGY=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js></script></head></head><nav class="navbar navbar-expand-lg bg-body-tertiary fixed-top"><div class=container-fluid><a href=/ class="d-lg-none d-flex align-items-center a_logonav"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" height=30 class=logo_nav>
<span class="ms-2 text-isp">ISP</span>
</a><button class="navbar-toggler ms-auto" type=button data-bs-toggle=collapse data-bs-target=#navbarTogglerDemo01 aria-controls=navbarTogglerDemo01 aria-expanded=false aria-label="Toggle navigation" style=height:40px>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarTogglerDemo01><ul class="navbar-nav mx-auto mb-lg-0"><li class="nav-item px-2 nav-item-highlight d-none d-lg-block"><a class="nav-link a" aria-current=page href=/github/>ISP</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/people/>People</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle a" href=/github/research/philosophy id=navbarDropdownResearch role=button aria-expanded=false>Research</a><ul class=dropdown-menu aria-labelledby=navbarDropdownResearch><li><a class="dropdown-item a" href=/github/research/machine_learning/>Machine learning</a></li><li><a class="dropdown-item a" href=/github/research/visual_neuroscience/>Visual neuroscience</a></li><li><a class="dropdown-item a" href=/github/research/visual_brain/>Visual brain</a></li><li><a class="dropdown-item a" href=/github/research/earth_science/>Earth science</a></li><li><a class="dropdown-item a" href=/github/research/social_science>Social science</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/projects/>Projects</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/facilities/>Facilities</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle a" href=/github/publications/journals/ id=navbarDropdownPublications role=button aria-expanded=false>Publications</a><ul class=dropdown-menu aria-labelledby=navbarDropdownPublications><li><a class="dropdown-item a" href=/github/publications/journals/>Journals</a></li><li><a class="dropdown-item a" href=/github/publications/conferences/>Conferences</a></li><li><a class="dropdown-item a" href=/github/publications/books/>Books</a></li><li><a class="dropdown-item a" href=/github/publications/talks/>Talks</a></li><li><a class="dropdown-item a" href=/github/publications/technical_reports/>Technical Reports</a></li><li><a class="dropdown-item a" href=/github/publications/theses/>Theses</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/code/>Code</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/data/>Data</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/seminars/>Seminars</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/courses/>Courses</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/collaborators/>Collaborators</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/news/>News</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/contact/>Contact</a></li></ul></div></div></nav><style>.navbar{--bs-navbar-padding-y:0rem !important;background-color:#222!important}.a{color:#949494!important}.a:hover{color:#fff!important}.nav-item-highlight{padding:.4rem}.nav-item-highlight:hover{background-color:#2d70aa!important}.dropdown-menu{background-color:#333!important;color:#fff!important;display:block}.dropdown-item{color:#949494!important}.dropdown-item:hover{background-color:#2d70aa!important;color:#fff!important}.navbar-nav li.nav-item .nav-link,.dropdown-menu .dropdown-item{transition:color .3s,background-color .3s}.nav-link.active,.dropdown-item.active{color:#fff!important;background-color:#007bff!important}.navbar-toggler-icon{background-image:url("data:image/svg+xml,%3csvg viewBox='0 0 30 30' xmlns='http://www.w3.org/2000/svg'%3e%3cpath stroke='white' stroke-width='2' stroke-linecap='round' stroke-miterlimit='10' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e")}.navbar-toggler{border:none}.navbar-toggler:focus{outline:none}@media(min-width:992px){.dropdown-menu{display:none}.dropdown:hover .dropdown-menu{display:block}}@media(max-width:991px){.navbar-nav{max-height:calc(100vh - 56px);overflow-y:auto}.navbar-nav::-webkit-scrollbar{width:9px}.navbar-nav::-webkit-scrollbar-thumb{background-color:#888;border-radius:10px}.navbar-nav::-webkit-scrollbar-thumb:hover{background-color:#555}.navbar-nav .nav-link{font-size:1.2rem}.dropdown-menu .dropdown-item{font-size:1rem}.dropdown-toggle::after{display:inline-block;margin-left:.255em;vertical-align:.255em;content:"";border-top:.3em solid;border-right:.3em solid transparent;border-bottom:0;border-left:.3em solid transparent}.navbar .dropdown-toggle::after{content:none!important}.navbar-toggler-icon{width:1.2em;height:1.2em}.navbar-toggler{border:none!important}.navbar-toggler:focus{box-shadow:none!important}.d-flex{height:45px}.a_logonav{text-decoration:none!important}.text-isp{font-size:1.3rem;color:#9d9d9d;display:inline-block;vertical-align:middle;text-decoration:none!important}.navbar-nav{max-height:calc(50vh - 56px);overflow-y:auto}}</style><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll(".navbar .dropdown");e.forEach(function(e){let t=e.querySelector(".dropdown-toggle");t.addEventListener("click",function(e){window.innerWidth<992&&e.target===t&&(window.location.href=t.href)});let n=e.querySelectorAll(".dropdown-item");n.forEach(function(e){e.addEventListener("click",function(){window.location.href=e.href})})}),document.addEventListener("click",function(t){window.innerWidth<992&&!t.target.closest(".navbar .dropdown")&&e.forEach(function(e){e.querySelector(".dropdown-menu").classList.remove("show")})})})</script><main><div class=container><div class="content-container grid-layout"><div class=box-header><h1>New Compressive Sensing Algorithms from Natural and Artificial Brain Networks. L.M. Mart√≠nez and J. Malo.</h1></div><div class=box-abstract><p><h1 id=methods-related-to-the-human-camera>Methods related to the Human Camera</h1><h2 id=let-the-brain-do-image-coding-for-you-it-is-better-than-jpeg2000>Let the brain do image coding for you: it is better than JPEG2000</h2><p>The long term <em>Human Camera</em> goal could be seen as a new Brain Machine Interface (BMI) for image transmission in which the nontrivial feature extraction and dimensionality reduction stage is done by a human brain instead of by the conventional compression algorithm. The (input) signal should be reconstructed (from the neural signal) at the receiver.</p><p>Here we present an oversimplified, but illustrative, example of the decoding of the cortical signal to show some of the computational issues of the modeling and BMI problems, its relations with image compression and enhancement, and to show that we already are working with the technologies that allow the inference of the stimulus from the neural response.</p><h1 id=simplified-forward-model-to-start-playing-with>Simplified (Forward) Model to start playing with</h1><p>The considered example uses (i) a nonlinear response based on divisive normalization and fitted with psychophysics (Carandini et al. 2012, Malo et al. 2006, Malo et al. 2010), (ii) different distortion sources that modify the nonlinear signal as for instance, random neural noise or additional pooling stages not considered in the assumed model, (iii) dimensionality reduction, i.e. missing responses in the recorded signal. Of course, this model will be augmented in different ways (e.g. including irregular spatial sampling, the diversity in shapes of the receptive fields (Martinez et al. 2014), the adaptive interaction in the nonlinear stage (Schwartz et al. 2009), or correlated noise patterns.</p><p>Multi information numbers (in bits) between four coefficients of the different representation show the redundancy reduction along the path, which is consistent with the efficient encoding hypothesis [Olshausen96, Schwartz01], and is consistent with our previous results [Malo06b, Malo10].</p><h1 id=reconstructions-from-the-stochastic-responses-of-the-partially-or-totally-unknown-model>Reconstructions from the (stochastic) responses of the (partially or totally) unknown model</h1><p>Next figure shows the reconstruction using different inversion techniques: linear (similar to [stanley99]), Kernel (similar to [Miyawaki08]), and analytic, as in [Malo06b]. The example explores the effect of different distortion sources (noise and elements not considered in the model) on top of a representation of reduced dimensionality (we are missing 61% of the neurons -those tuned to high frequencies-). The good properties of analytic inversion could be used to complement (as prior knowledge) the current regression techniques.</p><p>Estimated stimuli from the neural signal under different distortion sources (dimensionality reduction, different neural noise and additional pooling stages not considered in the forward model). In this numerical experiment linear reconstruction is more sensitive to distortion, which is alleviated by nonlinear regression, which still displays significant artifacts. The analytical inverse seems to reconstruct better but also amplifies the noise. The knowledge extracted from the structure of the inverse should be included in the conventional methods.</p></p></div><aside class=box-gallery><div class=gallery-grid><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/otros_BMIs.webp","[Current state-of-the-art in reconstruction from neural recordings](#methods-related-to-the-human-camera)","")'><img src=/images/code/otros_BMIs.webp alt="[Current state-of-the-art in reconstruction from neural recordings](#methods-related-to-the-human-camera)"></a><p class=gallery-title><a href=#methods-related-to-the-human-camera>Current state-of-the-art in reconstruction from neural recordings</a></p></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/the_model.webp","[Simplified (Forward) Model](#simplified-forward-model-to-start-playing-with)","")'><img src=/images/code/the_model.webp alt="[Simplified (Forward) Model](#simplified-forward-model-to-start-playing-with)"></a><p class=gallery-title><a href=#simplified-forward-model-to-start-playing-with>Simplified (Forward) Model</a></p></div><div class=gallery-item><a href=javascript:void(0); class=gallery-thumbnail onclick='openModal("/images/code/reconstruct_BMI.webp","[Reconstructions from the (stochastic) responses of the model](#reconstructions-from-the-stochastic-responses-of-the-partially-or-totally-unknown-model)","")'><img src=/images/code/reconstruct_BMI.webp alt="[Reconstructions from the (stochastic) responses of the model](#reconstructions-from-the-stochastic-responses-of-the-partially-or-totally-unknown-model)"></a><p class=gallery-title><a href=#reconstructions-from-the-stochastic-responses-of-the-partially-or-totally-unknown-model>Reconstructions from the (stochastic) responses of the model</a></p></div><div id=imageModal class=modal><span class=modal-close onclick=closeModal()>&#215;</span>
<img class=modal-content id=modalImage><div id=modalCaption class=modal-caption></div></div></div></aside><section class="box-references title2"><h2>References</h2><ul class=references-list><li><strong>On the Suitable Domain for SVM Training in Image Coding</strong><br><span>G. Camps, G. G√≥mez, J. Guti√©rrez, J. Malo</span><br><em>Journal of Machine Learning Research, Vol. 9: 49-66 (2008)</em></li><li><strong>Normalization as a Canonical Neural Computation</strong><br><span>M. Carandini, D. Heeger</span><br><em>Nature Reviews. Neuroscience, 13(1): 51-62 (2012)</em></li><li><strong>Perceptual Adaptive Insensitivity for SVM Image Coding</strong><br><span>G. G√≥mez, G. Camps, J. Guti√©rrez, J. Malo</span><br><em>IEEE Transactions on Neural Networks, 16(6): 1574-1581 (2005)</em></li><li><strong>Neural Decoding of Visual Imagery During Sleep</strong><br><span>T. Horikawa, M. Tamaki, Y. Miyawaki, Y. Kamitani</span><br><em>Science, 340: 639-642 (2013)</em></li><li><strong>The Role of Spatial Information in Disentangling the Irradiance-Reflectance-Transmittance Ambiguity</strong><br><span>S. Jim√©nez, J. Malo</span><br><em>IEEE Transactions on Geoscience and Remote Sensing, 52(8): 4881-4894 (2014)</em></li><li><strong>Divisive Normalization Image Quality Metric Revisited</strong><br><span>V. Laparra, J. Mu√±oz, J. Malo</span><br><em>Journal of the Optical Society of America A, 27(4): 852-864 (2010)</em></li><li><strong>Iterative Gaussianization: From ICA to Random Rotations</strong><br><span>V. Laparra, G. Camps-Valls, J. Malo</span><br><em>IEEE Transactions on Neural Networks, 22(4): 537-549 (2011)</em></li><li><strong>Dimensionality Reduction via Regression in Hyperspectral Imagery</strong><br><span>V. Laparra, G. Camps-Valls, J. Malo</span><br><em>Submitted to IEEE Journal of Selected Topics in Signal Processing (2014)</em></li><li><strong>Non-linear Image Representation for Efficient Perceptual Coding</strong><br><span>J. Malo, I. Epifanio, R. Navarro, E. Simoncelli</span><br><em>IEEE Transactions on Image Processing, 15(1): 68-80 (2006)</em></li><li><strong>Method, Apparatus and Software for Color Image Compression Based on Non-linear Perceptual Representations and Machine Learning</strong><br><span>J. Malo, J. Guti√©rrez, G. Camps, M.J. Luque</span><br><em>Patent Ref. P200801943, Oficina Espa√±ola de Patentes y Marcas (2008)</em></li><li><strong>Psychophysically Tuned Divisive Normalization Approximately Factorizes the PDF of Natural Images</strong><br><span>J. Malo, V. Laparra</span><br><em>Neural Computation, 22(12): 3179-3206 (2010)</em></li><li><strong>Statistical Wiring of Thalamic Receptive Fields Optimizes Spatial Sampling of the Retinal Image</strong><br><span>L.M. Mart√≠nez, M. Molano, X. Wang, F.T. Sommer, J.A. Hirsch</span><br><em>Neuron, 81: 943-956 (2014)</em></li><li><strong><a href="https://www.youtube.com/watch?v=lYfnfMschHg" target=_blank class=references-name>Decoding the Mind's Eye: Visual Image Reconstruction from Human Brain Activity Using a Combination of Multiscale Local Image Decoders</a></strong><br><span>Y. Miyawaki, H. Uchida, O. Yamashita, M.A. Sato, Y. Morito, H.C. Tanabe, N. Sadato, Y. Kamitani</span><br><em>Neuron, 60(5): 915-929 (2008)</em></li><li><strong><a href="https://www.youtube.com/watch?v=FR0qJ17Rsvc" target=_blank class=references-name>Reconstructing Visual Experiences from Brain Activity Evoked by Natural Movies</a></strong><br><span>S. Nishimoto, A.T. Vu, T. Naselaris, Y. Benjamini, B. Yu, J.L. Gallant</span><br><em>Current Biology, 21(19): 1641-1646 (2011)</em></li><li><strong>Emergence of Simple-cell Receptive Field Properties by Learning a Sparse Code for Natural Images</strong><br><span>B.A. Olshausen, D. Field</span><br><em>Nature, 381: 607-609 (1996)</em></li><li><strong>Natural Signal Statistics and Sensory Gain Control</strong><br><span>O. Schwartz, E.P. Simoncelli</span><br><em>Nature Neuroscience, 4(8): 819-825 (2001)</em></li><li><strong>Spike-triggered Neural Characterization</strong><br><span>O. Schwartz, J.W. Pillow, N.C. Rust, E.P. Simoncelli</span><br><em>Journal of Vision, 6: 484-507 (2006)</em></li><li><strong>Perceptual Organization of the Tilt Illusion</strong><br><span>O. Schwartz, P. Dayan, T. Sejnowski</span><br><em>Journal of Vision, 9(4): 19.1-19 (2009)</em></li><li><strong><a href=http://www.stanley.bme.gatech.edu/publications/stanley_dan_1999.pdf target=_blank class=references-name>Reconstruction of Natural Scenes from Ensemble Responses in the Lateral Geniculate Nucleus</a></strong><br><span>G.B. Stanley, F.F. Li, Y. Dan</span><br><em>Journal of Neuroscience, 19(18): 8036-8042 (1999)</em></li></ul></section><section class="box-enlaces title2"><h2>Download</h2><div class=enlaces-description><p>See brain_machine_interface.m for an overview. It requires including in the matlab path all the subfolders in the zip file.</p></div><ul class=enlaces-list><li><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/bmi.zip>Matlab Toolbox (Specific code to reproduce the experiments in this illustration)</a></li><li><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Project_Martinez_Malo_BFU2014_58776_R.pdf>Project Proposal BFU2014-58776</a></li></ul></section></div></div></main></body><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js@1.0.0/src/bibtex_js.min.js defer></script></html>