<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin=anonymous referrerpolicy=no-referrer><link rel="shortcut icon" href=/try-isp-page/images/isp_ico.webp type=image/x-icon><link rel=stylesheet href=/try-isp-page/style/style.css><script src=/try-isp-page/js/mode.js></script><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js></script></head><nav class=custom-navbars><div class=custom-container><a href=/ class="custom-logo custom-hide-on-large"><img src=/try-isp-page/images/isp_logo_sinfondo.webp alt="ISP Icon" class=custom-logo_nav>
<span class=custom-text-isp>ISP</span>
</a><button class=navbar-toggler aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class=custom-navbar-collapse><ul class=custom-navbar-nav><li class="custom-nav-item custom-desktop-only"><a class=custom-nav-link href=/try-isp-page/>ISP</a></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/people/>People</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/try-isp-page/research/philosophy/>Research</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/try-isp-page/research/philosophy/>Philosophy</a></li><li><a class=custom-dropdown-item href=/try-isp-page/research/machine_learning/>Machine learning</a></li><li><a class=custom-dropdown-item href=/try-isp-page/research/visual_neuroscience/>Visual science</a></li><li><a class=custom-dropdown-item href=/try-isp-page/research/visual_brain/>Image processing</a></li><li><a class=custom-dropdown-item href=/try-isp-page/research/earth_science/>Earth science</a></li><li><a class=custom-dropdown-item href=/try-isp-page/research/social_science>Social science</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/projects/>Projects</a></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/facilities/>Facilities</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/try-isp-page/publications/journals/>Publications</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/try-isp-page/publications/journals/>Journals</a></li><li><a class=custom-dropdown-item href=/try-isp-page/publications/conferences/>Conferences</a></li><li><a class=custom-dropdown-item href=/try-isp-page/publications/books/>Books</a></li><li><a class=custom-dropdown-item href=/try-isp-page/publications/talks/>Talks</a></li><li><a class=custom-dropdown-item href=/try-isp-page/publications/technical_reports/>Technical Reports</a></li><li><a class=custom-dropdown-item href=/try-isp-page/publications/theses/>Theses</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/code/>Code</a></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/data/>Data</a></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/seminars/>Seminars</a></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/courses/>Courses</a></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/collaborators/>Collaborators</a></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/news/>News</a></li><li class=custom-nav-item><a class=custom-nav-link href=/try-isp-page/contact/>Contact</a></li></ul></div></div></nav><main><div class=container><div class=content-container><div class=title-container><h1>Feature extraction, dimensionality reduction and manifold learning</h1></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>DRR: Dimensionality Reduction via Regression</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=./ddr/content><img src=/try-isp-page/images/code/drr_image3.webp alt="DRR Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>Dimensionality Reduction via Regression (DRR) is a manifold learning technique aimed at removing residual statistical dependence between PCA components due to dataset curvature. DRR predicts PCA coefficients from neighboring coefficients using multivariate regression, generalizing PPA. It advances dimensionality reduction methods by using curves instead of straight lines.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Dimensionality reduction via regression in hyperspectral imagery. Laparra, V., Malo, J., and Camps-Valls, G. IEEE Journal on Selected Topics in Signal Processing, 9(6):1026-1036, 2015.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>EPLS: Unsupervised Sparse Convolutional Neural Networks for Feature Extraction</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://sites.google.com/site/adriromsor/epls><img src=/try-isp-page/images/code/epls.webp alt="EPLS Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>EPLS (Enhancing Population and Lifetime Sparsity) is an unsupervised feature learning algorithm designed for sparse representations in convolutional neural networks. It is meta-parameter free, simple, and fast.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Unrolling loopy top-down semantic feedback in convolutional deep networks. Gatta, C., Romero, A., van de Weijer, J. Deep-vision workshop CVPR, 2014.</li><li>Unsupervised Deep Feature Extraction Of Hyperspectral Images. Romero, A., Gatta, C., Camps-Valls, G. IEEE Workshop on Hyperspectral Image and Signal Processing, Whispers, 2014.</li><li>Unsupervised Deep Feature Extraction for Remote Sensing Image Classification. Romero, A., Gatta, C., Camps-Valls, G. IEEE Transactions on Geoscience and Remote Sensing, 2015.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>HOCCA: Higher Order Canonical Correlation Analysis</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=./hocca/content><img src=/try-isp-page/images/code/hocca.webp alt="HOCCA Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>HOCCA is a linear manifold learning technique that applies to datasets from the same source. It finds independent components in each dataset that are related across datasets, thus combining the goals of ICA and CCA.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Spatio-Chromatic Adaptation via Higher-Order Canonical Correlation Analysis of Natural Images. Gutmann, M.U., Laparra, V., Hyv√§rinen, A., Malo, J. PLoS ONE, 9(2):e86481, 2014.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>KEMA: Kernel Manifold Alignment</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://github.com/dtuia/KEMA><img src=/try-isp-page/images/code/simpsonize.webp alt="KEMA Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>KEMA extends SSMA by using kernel methods for better semantic alignments of multisource data.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Kernel Manifold Alignment for Domain Adaptation. Tuia, D., Camps-Valls, G. PLoS ONE, 2016.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>KSNR: Kernel Signal to Noise Ratio</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_feature/ksnr.zip><img src=/try-isp-page/images/code/signal-noise.webp alt="KSNR Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>KSNR is a feature extraction method that maximizes signal variance while minimizing noise variance in a reproducing kernel Hilbert space (RKHS). It provides noise-free features for dimensionality reduction, outperforming kPCA in correlated noise scenarios.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Learning with the kernel signal to noise ratio. Gomez-Chova, L., Camps-Valls, G. IEEE International Workshop on Machine Learning for Signal Processing, MLSP, 2012.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>OKECA: Optimized Kernel Entropy Component Analysis</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_feature/okeca_v1.zip><img src=/try-isp-page/images/code/okeca.webp alt="OKECA Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>OKECA is a kernel feature extraction method based on entropy estimation in Hilbert spaces. It provides sparse and compact results, useful for data visualization and dimensionality reduction.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Optimized Kernel Entropy Components. Izquierdo-Verdiguier, E., Laparra, V., Jenssen, R., G√≥mez-Chova, L., Camps-Valls, G. IEEE Transactions on Neural Networks and Learning Systems, 2016.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>PPA: Principal Polynomial Analysis</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=./ppa/content><img src=/try-isp-page/images/code/ppa_code.webp alt="PPA Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>Principal Polynomial Analysis (PPA) is a manifold learning technique that generalizes PCA by using principal polynomials to capture nonlinear data patterns. It improves PCA‚Äôs energy compaction ability, reducing dimensionality reduction errors. PPA defines a manifold-dependent metric that generalizes Mahalanobis distance for curved manifolds.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Principal polynomial analysis. Laparra, V., Jim√©nez, S., Tuia, D., Camps-Valls, G., Malo, J. International Journal of Neural Systems, 24(7), 2014.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>RBIG: Rotation-Based Iterative Gaussianization</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=./rbig/content><img src=/try-isp-page/images/code/softwa1.gif alt="RBIG Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>RBIG is an invertible multivariate Gaussianization transform that uses univariate histogram Gaussianization and multivariate rotation. This method is useful for multivariate PDF estimation and associated applications.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Iterative gaussianization: From ICA to random rotations. Laparra, V., Camps-Valls, G., Malo, J. IEEE Transactions on Neural Networks, 22(4):537-549, 2011.</li><li>PCA Gaussianization for one-class remote sensing image classification. Laparra, V., Mu√±oz-Mar√≠, J., Camps-Valls, G., Malo, J. Proceedings of SPIE, 7477, 2009.</li><li>PCA Gaussianization for image processing. Laparra, V., Camps-Valls, G., Malo, J. Proceedings - International Conference on Image Processing, ICIP, 2009.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>ROCK-PCA: Rotated Complex Kernel PCA for Nonlinear Spatio-Temporal Data Analysis</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://github.com/DiegoBueso/ROCK-PCA><img src=/try-isp-page/images/code/rock.webp alt="ROCK-PCA Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>The rotated complex kernel PCA (ROCK-PCA) works in reproducing kernel Hilbert spaces to account for nonlinear processes, operates in the complex domain to handle both spatial and temporal features and time-lagged correlations. It adds an extra rotation for improved flexibility and physical consistency, providing an explicitly resolved spatio-temporal decomposition of Earth and climate data cubes.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Nonlinear PCA for Spatio-Temporal Analysis of Earth Observation Data. Bueso, D., Piles, M., and Camps-Valls, G. IEEE Transactions on Geoscience and Remote Sensing, 58(8), 2020.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>SIMFEAT: A Simple MATLAB(tm) Toolbox of Linear and Kernel Feature Extraction</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_feature/simfeat.zip><img src=/try-isp-page/images/code/feat_extr2.webp alt="SIMFEAT Toolbox Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>SIMFEAT is a toolbox that includes linear and kernel feature extraction methods. Linear methods: PCA, MNF, CCA, PLS, OPLS. Kernel methods: KPCA, KMNF, KCCA, KPLS, KOPLS, KECA.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Kernel multivariate analysis framework for supervised subspace learning: A tutorial on linear and kernel multivariate methods. Arenas-Garcia, J., Petersen, K.B., Camps-Valls, G., Hansen, L.K. IEEE Signal Processing Magazine, 30(4):16-29, 2013.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>SPCA: Sequential Principal Curves Analysis</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=./spca/content><img src=/try-isp-page/images/code/Cuerno_crit_1_ori_dom.webp alt="SPCA Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>SPCA is an invertible manifold learning technique that generalizes PCA by using nonparametric principal curves instead of straight lines. It includes multivariate histogram equalization to fulfill either NonLinear ICA or optimal Vector Quantization.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Nonlinearities and adaptation of color vision from sequential principal curves analysis. Laparra, V., Jim√©nez, S., Camps-Valls, G., Malo, J. Neural Computation, 24(10):2751-2788, 2012.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>SSKPLS: Semisupervised Kernel Partial Least Squares</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_feature/sskpls_toolbox.zip><img src=/try-isp-page/images/code/sskpls.webp alt="SSKPLS Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>SSKPLS utilizes probabilistic cluster kernels for nonlinear feature extraction. It builds kernel functions from data, outperforming standard kernel functions and information theoretic kernels like Fisher and mutual information kernels.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Spectral clustering with the probabilistic cluster kernel. Izquierdo-Verdiguier, E., Jenssen, R., G√≥mez-Chova, L., Camps-Valls, G. Neurocomputing, 149(C):1299-1304, 2015.</li><li>Semisupervised kernel feature extraction for remote sensing image analysis. Izquierdo-Verdiguier, E., Gomez-Chova, L., Bruzzone, L., Camps-Valls, G. IEEE Transactions on Geoscience and Remote Sensing, 52(9):5567-5578, 2014.</li></ul></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>SSMA: SemiSupervised Manifold Alignment</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_feature/ssma.zip><img src=/try-isp-page/images/code/ssma.webp alt="SSMA Image"></a></div><div class="panel-description col-md-6"><h5><p class=text-justify>The SSMA Toolbox is a MATLAB tool for semisupervised manifold alignment of data without corresponding pairs, requiring only a small set of labeled samples in each domain.</p></h5></div><div class="panel-references col-md-4"><h6><b>References</b></h6><ul class=references-list><li>Semisupervised manifold alignment of multimodal remote sensing images. Tuia, D., Volpi, M., Trolliet, M., Camps-Valls, G. IEEE Transactions on Geoscience and Remote Sensing, 52(12):7708-7720, 2014.</li></ul></div></div></div></div><p></p></div></div></main></body><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script></html>