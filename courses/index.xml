<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>courses on ISP - Image and Signal Processing group</title><link>https://ipl-uv.github.io/courses/</link><description>Recent content in courses on ISP - Image and Signal Processing group</description><generator>Hugo</generator><language>en-us</language><atom:link href="https://ipl-uv.github.io/courses/index.xml" rel="self" type="application/rss+xml"/><item><title>Information Theory for Visual Communication</title><link>https://ipl-uv.github.io/courses/information-theory-visual-communication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/information-theory-visual-communication/</guid><description>Course Duration: 30 hours
Instructor: J. Malo
In this course, I introduce the elements of information theory required to understand why Uniformization or Gaussianization of density functions and noise in the system are key for the transmission of visual information. This knowledge is the basis of our long-standing agenda on developing invertible transforms for uniformization (SPCA, PPA, DRR) and Gaussianization (RBIG), and our research to calibrate neural noise in the visual system and Divisive Normalization models.</description></item><item><title>Statistical Signal Processing</title><link>https://ipl-uv.github.io/courses/statistical-signal-processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/statistical-signal-processing/</guid><description>Course Duration: 60 hours
Instructor: G. Camps-Valls
Material for a master course on (statistical) signal processing. I cover the essential background for engineers and physicists interested in signal processing: Probability and random variables, discrete time random processes, spectral estimation, signal decomposition and transforms, and an introduction to information theory.
Material</description></item><item><title>Human Vision: Facts, Mechanistic Models, and Principled Theories</title><link>https://ipl-uv.github.io/courses/human-vision-mechanistic-models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/human-vision-mechanistic-models/</guid><description>Course Duration: 30 hours
Instructor: J. Malo
In this course, I introduce the facts on color vision from radiometry and photometry, the vision of spatio-temporal textures, the models of mechanisms and circuits that (kind of) reproduce these facts, and the statistical elements of theories that explain the facts.
Material</description></item><item><title>Representation of Spatial Information</title><link>https://ipl-uv.github.io/courses/representation-spatial-information/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/representation-spatial-information/</guid><description>Course Duration: 30 hours
Instructor: J. Malo
Statistical regularities in photographic images imply that certain representations of spatial information are better than others in terms of coding efficiency. In this course, we present the information theory concepts (entropy, multi-information, correlation and negentropy) for unsupervised feature extraction or dictionary learning required in image coding. Redundancy in images and sequences is reviewed, and basic techniques for compact information representation are introduced such as vector quantization, predictive coding, and transform coding.</description></item><item><title>Color Vision and Colorimetry</title><link>https://ipl-uv.github.io/courses/color-vision-colorimetry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/color-vision-colorimetry/</guid><description>Course Duration: 30 hours
Instructor: J. Malo
Color is a 5-dimensional perception that is not only related to the spectrum coming from an object, but also strongly related to its spatio-temporal context. It is a powerful feature that allows humans to make reliable inferences about objects that would be nice to understand and mimic in artificial vision. In this course, we derive the linear CIE tristimulus theory from its experimental color matching foundations.</description></item><item><title>Texture and Motion in the Visual Cortex</title><link>https://ipl-uv.github.io/courses/texture-motion-visual-cortex/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/texture-motion-visual-cortex/</guid><description>Course Duration: 40 hours
Instructor: J. Malo
Neurons in V1 and MT cortex play a determinant role in the analysis of the shape of objects, their spatial texture, and the estimation of retinal motion. In this course, we describe the basic psychophysical and physiological phenomena related to low-level spatio-temporal vision: the contrast sensitivity functions, masking, adaptation, and aftereffects. These facts are mediated by the context-dependent nonlinearities of the response of neurons with specific receptive fields.</description></item><item><title>Kernel Methods in Machine Learning</title><link>https://ipl-uv.github.io/courses/kernel-methods-machine-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/kernel-methods-machine-learning/</guid><description>Course Duration: 30 hours
Instructor: G. Camps-Valls
Two fundamental operations in Machine Learning such as regression and classification involve drawing nonlinear boundaries or functions through a set of (labeled or unlabeled) training samples. These boundaries or functions at certain (test) samples can be deduced from the similarities between the test sample and the training samples. These similarities can be encoded in Kernels, and the representer theorem can be used to obtain expressions for the functions at any test sample.</description></item><item><title>Hyperspectral Image Processing</title><link>https://ipl-uv.github.io/courses/hyperspectral-image-processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/hyperspectral-image-processing/</guid><description>Course Duration: 60 hours
Instructor: G. Camps-Valls
We introduce the main concepts of hyperspectral image processing. We start by a soft introduction to hyperspectral image processing, the standard processing chain, and the current challenges in the field. Then we analyze the current state of the art in several topics: feature extraction, supervised classification, unmixing and abundance estimation, and retrieval of biophysical parameters. All the methods and techniques studied are reviewed both theoretically and through MATLAB exercises.</description></item><item><title>Machine Learning and Signal Processing for Remote Sensing Data Analysis (IGARSS'14 tutorial)</title><link>https://ipl-uv.github.io/courses/remote-sensing-data-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/remote-sensing-data-analysis/</guid><description>Course Duration: N/A
Instructors: G. Camps-Valls and D. Tuia
In this tutorial, we will present the remote sensing image processing chain, and take the attendants on a tour of different strategies for feature extraction, classification, unmixing, retrieval, and pattern analysis for data understanding. On the one hand, we will present powerful methodologies for remote sensing data classification: extracting knowledge from data, including interactive approaches via active learning, classifiers that encode prior knowledge and invariances, semi-supervised learning that exploits the information of unlabeled data, and domain adaptation to compensate for shifts in the ever-changing data distributions.</description></item><item><title>The GLaSS Training Material Builds on the Global Lakes Use Cases</title><link>https://ipl-uv.github.io/courses/glass-training-material/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/glass-training-material/</guid><description>Course Duration: N/A
Instructor: Ana B. Ruescas &amp;amp; GLaSS team
The GLaSS training material builds on the global lakes use cases of GLaSS. It allows students and professionals in fields such as aquatic ecology, environmental technology, remote sensing, and GIS to learn about the possibilities of optical remote sensing of water quality, by using the Sentinel-2 and Sentinel-3 satellites and Landsat 8.
Material</description></item><item><title>Remote Sensing for Water Quality</title><link>https://ipl-uv.github.io/courses/remote-sensing-water-quality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/remote-sensing-water-quality/</guid><description>Course Duration: N/A
Instructor: Anna B. Ruescas
Anna B. Ruescas leads this session on remote sensing for water quality, as part of the 2023 ESA Earth Observation Advanced Training Course at the Wroclaw University of Environmental and Life Sciences.
Watch the Lectures!</description></item><item><title>Satellite-based Tools for Investigating Aquatic Ecosystems</title><link>https://ipl-uv.github.io/courses/satellite-based-tools-aquatic-ecosystems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ipl-uv.github.io/courses/satellite-based-tools-aquatic-ecosystems/</guid><description>Course Duration: N/A
Instructor: Anna B. Ruescas
Anna B. Ruescas participates in this session on the use of Sentinel Constellation SNAP Tools, as part of the 2023 Satellite-based Tools for Investigating Aquatic Ecosystems Training at the Trevor Platt Science Foundation.
Lectures</description></item></channel></rss>