<!doctype html><html lang=en-us dir=ltr><head><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin=anonymous referrerpolicy=no-referrer><link rel="shortcut icon" href=http://isp.uv.es/favicon.ico type=image/x-icon><link rel=stylesheet href=/style/style.css></head></head><body class=section-courses><nav class="navbar navbar-expand-lg bg-body-tertiary fixed-top"><div class=container-fluid><a href=/ class="d-lg-none d-flex align-items-center a_logonav"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" height=30 class=logo_nav>
<span class="ms-2 text-isp">ISP</span>
</a><button class="navbar-toggler ms-auto" type=button data-bs-toggle=collapse data-bs-target=#navbarTogglerDemo01 aria-controls=navbarTogglerDemo01 aria-expanded=false aria-label="Toggle navigation" style=height:40px>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarTogglerDemo01><ul class="navbar-nav mx-auto mb-lg-0"><li class="nav-item px-2 nav-item-highlight d-none d-lg-block"><a class="nav-link a" aria-current=page href=/>ISP</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/people/>People</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle a" href=/research/ id=navbarDropdownResearch role=button aria-expanded=false>Research</a><ul class=dropdown-menu aria-labelledby=navbarDropdownResearch><li><a class="dropdown-item a" href=/research/machine_learning/>Machine learning</a></li><li><a class="dropdown-item a" href=/research/visual_neuroscience/>Visual neuroscience</a></li><li><a class="dropdown-item a" href=/research/visual_brain/>Visual brain</a></li><li><a class="dropdown-item a" href=/research/earth_science/>Earth science</a></li><li><a class="dropdown-item a" href=/research/social_science>Social science</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/projects/>Projects</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/facilities/>Facilities</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle a" href=/publications/ id=navbarDropdownPublications role=button aria-expanded=false>Publications</a><ul class=dropdown-menu aria-labelledby=navbarDropdownPublications><li><a class="dropdown-item a" href=/publications/journals/>Journals</a></li><li><a class="dropdown-item a" href=/publications/conferences/>Conferences</a></li><li><a class="dropdown-item a" href=/publications/books/>Books</a></li><li><a class="dropdown-item a" href=/publications/talks/>Talks</a></li><li><a class="dropdown-item a" href=/publications/technical_reports/>Technical Reports</a></li><li><a class="dropdown-item a" href=/publications/theses/>Theses</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/code/>Code</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/data/>Data</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/seminars/>Seminars</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/courses/>Courses</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/collaborators/>Collaborators</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/news/>News</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/contact/>Contact</a></li></ul></div></div></nav><style>.navbar{--bs-navbar-padding-y:0rem !important;background-color:#222!important}.a{color:#949494!important}.a:hover{color:#fff!important}.nav-item-highlight{padding:.4rem}.nav-item-highlight:hover{background-color:#2d70aa!important}.dropdown-menu{background-color:#333!important;color:#fff!important;display:block}.dropdown-item{color:#949494!important}.dropdown-item:hover{background-color:#2d70aa!important;color:#fff!important}.navbar-nav li.nav-item .nav-link,.dropdown-menu .dropdown-item{transition:color .3s,background-color .3s}.nav-link.active,.dropdown-item.active{color:#fff!important;background-color:#007bff!important}.navbar-toggler-icon{background-image:url("data:image/svg+xml,%3csvg viewBox='0 0 30 30' xmlns='http://www.w3.org/2000/svg'%3e%3cpath stroke='white' stroke-width='2' stroke-linecap='round' stroke-miterlimit='10' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e")}.navbar-toggler{border:none}.navbar-toggler:focus{outline:none}@media(min-width:992px){.dropdown-menu{display:none}.dropdown:hover .dropdown-menu{display:block}}@media(max-width:991px){.navbar-nav{max-height:calc(100vh - 56px);overflow-y:auto}.navbar-nav::-webkit-scrollbar{width:9px}.navbar-nav::-webkit-scrollbar-thumb{background-color:#888;border-radius:10px}.navbar-nav::-webkit-scrollbar-thumb:hover{background-color:#555}.navbar-nav .nav-link{font-size:1.2rem}.dropdown-menu .dropdown-item{font-size:1rem}.dropdown-toggle::after{display:inline-block;margin-left:.255em;vertical-align:.255em;content:"";border-top:.3em solid;border-right:.3em solid transparent;border-bottom:0;border-left:.3em solid transparent}.navbar .dropdown-toggle::after{content:none!important}.navbar-toggler-icon{width:1.2em;height:1.2em}.navbar-toggler{border:none!important}.navbar-toggler:focus{box-shadow:none!important}.d-flex{height:45px}.a_logonav{text-decoration:none!important}.text-isp{font-size:1.3rem;color:#9d9d9d;display:inline-block;vertical-align:middle;text-decoration:none!important}.navbar-nav{max-height:calc(50vh - 56px);overflow-y:auto}}</style><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll(".navbar .dropdown");e.forEach(function(e){let t=e.querySelector(".dropdown-toggle");t.addEventListener("click",function(e){window.innerWidth<992&&e.target===t&&(window.location.href=t.href)});let n=e.querySelectorAll(".dropdown-item");n.forEach(function(e){e.addEventListener("click",function(){window.location.href=e.href})})}),document.addEventListener("click",function(t){window.innerWidth<992&&!t.target.closest(".navbar .dropdown")&&e.forEach(function(e){e.querySelector(".dropdown-menu").classList.remove("show")})})})</script><main><div class=container><div class=container><h1><span class="label label-info">Courses</span></h1><div class="row mb-4"><div class=col-md-3><img src=/images/courses/math.webp alt="Courses Intro" class=img-fluid style=width:100%></div><div class=col-md-9><p>Another formative experience in our group includes courses on Vision Science, Machine Learning and Image Processing for the PhD students in the IPL. These courses are closely related to our research, and the lectures are typically given at our university (<a href=http://www.uv.es/uvweb/master-remote-sensing/en/master-s-degree-remote-sensing-1285883190980.html>Remote sensing Master</a>, and <a href=http://www.uv.es/uvweb/master-electronic-engineering/en/master-s-degree-electronic-engineering-1285905409621.html>Electrical Engineering Master</a>, and the <a href="https://www.uv.es/uvweb/college/en/postgraduate-courses/official-master-s-degrees/official-master-s-degrees-offered/master-s-degree-basic-applied-neurosciences-1285848941532/Titulacio.html?id=1285859342470">Neuroscience Master</a>), as well as PhD and Master Programs in <a href=https://www.ioba.es/formacion/master-universitario-en-investigacion-en-ciencias-de-la-vision/>Vision Sciences (IOBA)</a> and <a href=http://pagines.uab.cat/mcv/>Computer Vision Master at Universitat Aut√≤noma de Barcelona</a>. Nevertheless, the courses below have readily evolved as a convenient introduction for PhD students to advanced issues not covered in conventional curricula.</p></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/Info_Theory2.webp alt="Information Theory for Visual Communication" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Information Theory for Visual Communication</h3><p class=facility-description><p><strong>Course Duration:</strong> 30 hours<br><strong>Instructor:</strong> J. Malo</p><p>In this course, I introduce the elements of information theory required to understand why Uniformization or Gaussianization of density functions and noise in the system are key for the transmission of visual information. This knowledge is the basis of our long-standing agenda on developing invertible transforms for uniformization (SPCA, PPA, DRR) and Gaussianization (RBIG), and our research to calibrate neural noise in the visual system and Divisive Normalization models.</p><p><a href=/files/courses/Info_theory_for_Neurosci_RBIG_infomax_DN_SPCA_PPA_DDR.zip>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/signal_theme.webp alt="Statistical Signal Processing" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Statistical Signal Processing</h3><p class=facility-description><p><strong>Course Duration:</strong> 60 hours<br><strong>Instructor:</strong> G. Camps-Valls</p><p>Material for a master course on (statistical) signal processing. I cover the essential background for engineers and physicists interested in signal processing: Probability and random variables, discrete time random processes, spectral estimation, signal decomposition and transforms, and an introduction to information theory.</p><p><a href=/files/courses/ps_2014.pdf>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/human.webp alt="Human Vision: Facts, Mechanistic Models, and Principled Theories" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Human Vision: Facts, Mechanistic Models, and Principled Theories</h3><p class=facility-description><p><strong>Course Duration:</strong> 30 hours<br><strong>Instructor:</strong> J. Malo</p><p>In this course, I introduce the facts on color vision from radiometry and photometry, the vision of spatio-temporal textures, the models of mechanisms and circuits that (kind of) reproduce these facts, and the statistical elements of theories that explain the facts.</p><p><a href=/files/courses/visual_percept.pptx>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/base.webp alt="Representation of Spatial Information" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Representation of Spatial Information</h3><p class=facility-description><p><strong>Course Duration:</strong> 30 hours<br><strong>Instructor:</strong> J. Malo</p><p>Statistical regularities in photographic images imply that certain representations of spatial information are better than others in terms of coding efficiency. In this course, we present the information theory concepts (entropy, multi-information, correlation and negentropy) for unsupervised feature extraction or dictionary learning required in image coding. Redundancy in images and sequences is reviewed, and basic techniques for compact information representation are introduced such as vector quantization, predictive coding, and transform coding. Application of these concepts in images is the basis of DCT and Wavelet representations, which are the core of JPEG and JPEG2000.</p><p><a href=/files/courses/Represent_Spatial_Information.zip>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/color.webp alt="Color Vision and Colorimetry" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Color Vision and Colorimetry</h3><p class=facility-description><p><strong>Course Duration:</strong> 30 hours<br><strong>Instructor:</strong> J. Malo</p><p>Color is a 5-dimensional perception that is not only related to the spectrum coming from an object, but also strongly related to its spatio-temporal context. It is a powerful feature that allows humans to make reliable inferences about objects that would be nice to understand and mimic in artificial vision. In this course, we derive the linear CIE tristimulus theory from its experimental color matching foundations. We derive the relations between spectrum and tristimulus vectors through the color matching functions, the chromatic coordinates, chromatic purity and luminance. Phenomenology of color discrimination and adaptation reveals the limitations of the linear description and sets the foundations of color appearance models. In addition, we link the above perceptual representations of color with the conventional representation of color in computers.</p><p><a href=/files/courses/Color_Vision.zip>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/mt_theoret_sensit.webp alt="Texture and Motion in the Visual Cortex" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Texture and Motion in the Visual Cortex</h3><p class=facility-description><p><strong>Course Duration:</strong> 40 hours<br><strong>Instructor:</strong> J. Malo</p><p>Neurons in V1 and MT cortex play a determinant role in the analysis of the shape of objects, their spatial texture, and the estimation of retinal motion. In this course, we describe the basic psychophysical and physiological phenomena related to low-level spatio-temporal vision: the contrast sensitivity functions, masking, adaptation, and aftereffects. These facts are mediated by the context-dependent nonlinearities of the response of neurons with specific receptive fields. We analyze the geometric properties of the standard model of V1 and their consequences in image discrimination. We introduce the concept of optical flow, its properties, and how this description of motion can be estimated from the 3D wavelet sensors in V1 and the aggregated sensors in MT.</p><p><a href=/files/courses/Color_Vision.zip>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/sskpls.webp alt="Kernel Methods in Machine Learning" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Kernel Methods in Machine Learning</h3><p class=facility-description><p><strong>Course Duration:</strong> 30 hours<br><strong>Instructor:</strong> G. Camps-Valls</p><p>Two fundamental operations in Machine Learning such as regression and classification involve drawing nonlinear boundaries or functions through a set of (labeled or unlabeled) training samples. These boundaries or functions at certain (test) samples can be deduced from the similarities between the test sample and the training samples. These similarities can be encoded in Kernels, and the representer theorem can be used to obtain expressions for the functions at any test sample. In this course, we will also review the application of the kernelization of scalar products (e.g., as in the covariance matrix) to obtain nonlinear generalizations of classical feature extraction methods.</p><p><a href=/files/courses/kernel_course.zip>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/hyper.webp alt="Hyperspectral Image Processing" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Hyperspectral Image Processing</h3><p class=facility-description><p><strong>Course Duration:</strong> 60 hours<br><strong>Instructor:</strong> G. Camps-Valls</p><p>We introduce the main concepts of hyperspectral image processing. We start by a soft introduction to hyperspectral image processing, the standard processing chain, and the current challenges in the field. Then we analyze the current state of the art in several topics: feature extraction, supervised classification, unmixing and abundance estimation, and retrieval of biophysical parameters. All the methods and techniques studied are reviewed both theoretically and through MATLAB exercises.</p><p><a href=/files/courses/esa_course.zip>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/remote_sensing.webp alt="Machine Learning and Signal Processing for Remote Sensing Data Analysis (IGARSS'14 tutorial)" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Machine Learning and Signal Processing for Remote Sensing Data Analysis (IGARSS'14 tutorial)</h3><p class=facility-description><p><strong>Course Duration:</strong> N/A<br><strong>Instructors:</strong> G. Camps-Valls and D. Tuia</p><p>In this tutorial, we will present the remote sensing image processing chain, and take the attendants on a tour of different strategies for feature extraction, classification, unmixing, retrieval, and pattern analysis for data understanding. On the one hand, we will present powerful methodologies for remote sensing data classification: extracting knowledge from data, including interactive approaches via active learning, classifiers that encode prior knowledge and invariances, semi-supervised learning that exploits the information of unlabeled data, and domain adaptation to compensate for shifts in the ever-changing data distributions. On the other hand, we will pay attention to recent advances in bio-geophysical parameter estimation that incorporate heteroscedasticity, online adaptation, and problem understanding. From there, we will take a leap towards the more challenging step of understanding the geoscience problems from data by reviewing the latest advances in (directed) graphical models, structure learning, and empirical causal inference. Beyond theory, we will also present results of recent studies illustrating all the covered issues. Finally, we will provide code to the attendees to try the different methodologies and provide a solid ground for their future experimentations.</p><p><a href=/files/courses/tutorial_igarss15.tar.gz>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/CarwH7tWIAAn2ry.jpg-large.webp alt="The GLaSS Training Material Builds on the Global Lakes Use Cases" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>The GLaSS Training Material Builds on the Global Lakes Use Cases</h3><p class=facility-description><p><strong>Course Duration:</strong> N/A<br><strong>Instructor:</strong> Ana B. Ruescas & GLaSS team</p><p>The GLaSS training material builds on the global lakes use cases of GLaSS. It allows students and professionals in fields such as aquatic ecology, environmental technology, remote sensing, and GIS to learn about the possibilities of optical remote sensing of water quality, by using the Sentinel-2 and Sentinel-3 satellites and Landsat 8.</p><p><a href=https://www.learn-eo.org/lessons_glass.php>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/gee_screenshot.webp alt="Google Earth Engine Introduction" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Google Earth Engine Introduction</h3><p class=facility-description><p><strong>Course Duration:</strong> N/A<br><strong>Instructors:</strong> Emma Izquierdo & Jordi Mu√±oz-Mar√≠</p><p>A short introduction to Google Earth Engine..</p><p><a href=./google-earth-engine-introduction/material>Material</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/EO_AnnaB_2023.webp alt="Remote Sensing for Water Quality" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Remote Sensing for Water Quality</h3><p class=facility-description><p><strong>Course Duration:</strong> N/A<br><strong>Instructor:</strong> Anna B. Ruescas</p><p>Anna B. Ruescas leads this session on remote sensing for water quality, as part of the 2023 ESA Earth Observation Advanced Training Course at the Wroclaw University of Environmental and Life Sciences.</p><p><a href="https://www.youtube.com/watch?v=d67aO2z06dI">Watch the Lectures!</a></p></p></div></div></div><div class="row facility mb-4"><div class=col-md-4><img src=/images/courses/annaB_SNAP23.webp alt="Satellite-based Tools for Investigating Aquatic Ecosystems" class=img-fluid style=width:100%></div><div class="col-md-8 d-flex align-items-center"><div><h3 class=facility-title>Satellite-based Tools for Investigating Aquatic Ecosystems</h3><p class=facility-description><p><strong>Course Duration:</strong> N/A<br><strong>Instructor:</strong> Anna B. Ruescas</p><p>Anna B. Ruescas participates in this session on the use of Sentinel Constellation SNAP Tools, as part of the 2023 Satellite-based Tools for Investigating Aquatic Ecosystems Training at the Trevor Platt Science Foundation.</p><p><a href="https://www.youtube.com/watch?v=pknYqAAtxRE">Lectures</a></p></p></div></div></div></div></div></main></body><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous></script></html>