<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous onerror='this.onerror=null,this.href="css/bootstrap.min.css"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer onerror='this.onerror=null,this.href="css/all.min.css"'><link rel="shortcut icon" href=/images/isp_ico.webp type=image/x-icon><link id=kenmore-font rel=stylesheet href=https://fonts.cdnfonts.com/css/twentieth-century-for-kenmore onerror='this.onerror=null,this.href="css/fonts/TwentiethCentury/fonts.css"'><link rel=stylesheet href=/css/style.css><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js onerror='this.onerror=null,this.src="js/marked.min.js"'></script><script src=/js/mode.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-D8CVQKS51G"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D8CVQKS51G")</script></head><body><nav class=custom-navbars><div class=custom-container><a href=/ class="custom-logo custom-hide-on-large"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" class=custom-logo_nav>
<span class=custom-text-isp>ISP</span>
</a><button class=navbar-toggler aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class=custom-navbar-collapse><ul class=custom-navbar-nav><li class="custom-nav-item custom-desktop-only"><a class=custom-nav-link href=/>ISP</a></li><li class=custom-nav-item><a class=custom-nav-link href=/people/>People</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/research/philosophy/>Research</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/research/machine_learning/>Machine learning</a></li><li><a class=custom-dropdown-item href=/research/visual_neuroscience/>Visual science</a></li><li><a class=custom-dropdown-item href=/research/visual_brain/>Image processing</a></li><li><a class=custom-dropdown-item href=/research/earth_science/>Earth science</a></li><li><a class=custom-dropdown-item href=/research/social_science>Social science</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/projects/>Projects</a></li><li class=custom-nav-item><a class=custom-nav-link href=/facilities/>Facilities</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/publications/journals/>Publications</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/publications/journals/>Journals</a></li><li><a class=custom-dropdown-item href=/publications/conferences/>Conferences</a></li><li><a class=custom-dropdown-item href=/publications/books/>Books</a></li><li><a class=custom-dropdown-item href=/publications/talks/>Talks</a></li><li><a class=custom-dropdown-item href=/publications/theses/>Theses</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/code/>Code</a></li><li class=custom-nav-item><a class=custom-nav-link href=/data/>Data</a></li><li class=custom-nav-item><a class=custom-nav-link href=/seminars/>Seminars</a></li><li class=custom-nav-item><a class=custom-nav-link href=/courses/>Courses</a></li><li class=custom-nav-item><a class=custom-nav-link href=/collaborators/>Collaborators</a></li><li class=custom-nav-item><a class=custom-nav-link href=/news/>News</a></li><li class=custom-nav-item><a class=custom-nav-link href=/contact/>Contact</a></li></ul></div></div></nav><main><div class=container><div class=content-container><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Advances in Dimensionality Reduction</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://github.com/nmank/DRCourse2025 target=_blank rel="noopener noreferrer"><img src=/images/courses/advances_course.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 10 hours</p><p><strong>Instructors:</strong> N. Mankovich</p><p class=text-justify>This course provides an overview of linear dimensionality reduction techniques and offers hands-on experience with NumPy and scikit-learn. It also explores the world of nonlinear dimensionality reduction, revealing hidden patterns in complex data.
<a href=https://docenciavirtual.uv.es/series/68342a963f3220ec441416b4>Video sessions</a></p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Atmospheric Radiative Transfer Models</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://isp.uv.es/slides/ATR_Course.pdf target=_blank rel="noopener noreferrer"><img src=/images/courses/atmospheric_radiative.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 3 hours</p><p><strong>Instructors:</strong> J. Vicent</p><p class=text-justify>Atmospheric Radiative Transfer Models (RTM) are computer codes that describe the physical interaction of light with atmospheric constituents, helping us to understand the radiation processes occurring in the Earth&rsquo;s atmosphere. These models are widely used in Earth Observation scientific and technological applications, from retrieval of atmospheric parameters, to processing satellite data and numerical weather forecasting.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Causality Course</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://docenciavirtual.uv.es/series/67eb96b33f3220604f3c6d13 target=_blank rel="noopener noreferrer"><img src=/images/courses/causality_course.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 45 hours</p><p><strong>Instructors:</strong> G. Varando, E. Díaz Salas and V. Sitokonstantinou</p><p class=text-justify>Introduction to causal inference methods, robust prediction techniques, and causal discovery methods. Familiarize with the vocabulary, definitions and basic concepts of causality, and understand the fundamentals behind basic methodologies in causal inference and causal discovery.
<a href=https://docenciavirtual.uv.es/series/67eb96b33f3220604f3c6d13>Video sessions</a></p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Color Vision and Colorimetry</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/Color_Vision.zip target=_blank rel="noopener noreferrer"><img src=/images/courses/color.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 30 hours</p><p><strong>Instructors:</strong> J. Malo</p><p class=text-justify>Color is a 5-dimensional perception that is not only related to the spectrum coming from an object, but also strongly related to its spatio-temporal context. It is a powerful feature that allows humans to make reliable inferences about objects that would be nice to understand and mimic in artificial vision. In this course, we derive the linear CIE tristimulus theory from its experimental color matching foundations. We derive the relations between spectrum and tristimulus vectors through the color matching functions, the chromatic coordinates, chromatic purity and luminance. Phenomenology of color discrimination and adaptation reveals the limitations of the linear description and sets the foundations of color appearance models. In addition, we link the above perceptual representations of color with the conventional representation of color in computers.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Explainability in AI systems</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://github.com/OscarPellicer/extra-attributions target=_blank rel="noopener noreferrer"><img src=/images/courses/explainability_course.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 3 hours</p><p><strong>Instructors:</strong> O. Pellicer</p><p class=text-justify>Introduction to Explainable AI: covering broadly Explainable AI (XAI) from definitions and concepts to cutting-edge methods and evaluations.
<a href=https://github.com/OscarPellicer/extra-attributions/blob/main/XAI_Course_2025_OJPV.pdf>Slides</a></p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Google Earth Engine Introduction</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://web.archive.org/web/20210413131146/https://isp.uv.es/courses/gee_course/ target=_blank rel="noopener noreferrer"><img src=/images/courses/gee_screenshot.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Instructors:</strong> Emma Izquierdo & Jordi Muñoz-Marí</p><p class=text-justify>A short introduction to Google Earth Engine.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Human Vision: Facts, Mechanistic Models, and Principled Theories</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/visual_percept.pptx target=_blank rel="noopener noreferrer"><img src=/images/courses/human.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 30 hours</p><p><strong>Instructors:</strong> J. Malo</p><p class=text-justify>In this course, I introduce the facts on color vision from radiometry and photometry, the vision of spatio-temporal textures, the models of mechanisms and circuits that (kind of) reproduce these facts, and the statistical elements of theories that explain the facts.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Hybrid Modeling</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://colab.research.google.com/github/KaiHCohrs/meditwin-hybrid-modeling-tutorial/blob/main/Part_1_Physics_Informed_Neural_Networks_for_Inverse_Modeling.ipynb target=_blank rel="noopener noreferrer"><img src=/images/courses/hybridmodeling_course.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 3 hours</p><p><strong>Instructors:</strong> K. Cohrs</p><p class=text-justify>Introduction to hybrid modelling and its particular challenges on small and large scales. Learn about the different flavors and dimensions in which physical knowledge can be integrated with machine learning.
<a href=https://colab.research.google.com/github/KaiHCohrs/meditwin-hybrid-modeling-tutorial/blob/main/Part_1_Physics_Informed_Neural_Networks_for_Inverse_Modeling.ipynb>Tutorial 1</a>
<a href=https://colab.research.google.com/github/KaiHCohrs/meditwin-hybrid-modeling-tutorial/blob/main/Part_2_Semi_parametric_Hybrid_Modeling.ipynb>Tutorial 2</a></p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Hyperspectral Image Processing</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/esa_course.zip target=_blank rel="noopener noreferrer"><img src=/images/courses/hyper.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 60 hours</p><p><strong>Instructors:</strong> G. Camps-Valls</p><p class=text-justify>We introduce the main concepts of hyperspectral image processing. We start by a soft introduction to hyperspectral image processing, the standard processing chain, and the current challenges in the field. Then we analyze the current state of the art in several topics: feature extraction, supervised classification, unmixing and abundance estimation, and retrieval of biophysical parameters. All the methods and techniques studied are reviewed both theoretically and through MATLAB exercises.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Information Theory for Visual Communication</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/Info_theory_for_Neurosci_RBIG_infomax_DN_SPCA_PPA_DDR.zip target=_blank rel="noopener noreferrer"><img src=/images/courses/Info_Theory2.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 30 hours</p><p><strong>Instructors:</strong> J. Malo</p><p class=text-justify>In this course, I introduce the elements of information theory required to understand why Uniformization or Gaussianization of density functions and noise in the system are key for the transmission of visual information. This knowledge is the basis of our long-standing agenda on developing invertible transforms for uniformization (SPCA, PPA, DRR) and Gaussianization (RBIG), and our research to calibrate neural noise in the visual system and Divisive Normalization models.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Kernel Methods in Machine Learning</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/kernel_course.zip target=_blank rel="noopener noreferrer"><img src=/images/courses/sskpls.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 30 hours</p><p><strong>Instructors:</strong> G. Camps-Valls</p><p class=text-justify>Two fundamental operations in Machine Learning such as regression and classification involve drawing nonlinear boundaries or functions through a set of (labeled or unlabeled) training samples. These boundaries or functions at certain (test) samples can be deduced from the similarities between the test sample and the training samples. These similarities can be encoded in Kernels, and the representer theorem can be used to obtain expressions for the functions at any test sample. In this course, we will also review the application of the kernelization of scalar products (e.g., as in the covariance matrix) to obtain nonlinear generalizations of classical feature extraction methods.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Machine Learning and Signal Processing for Remote Sensing Data Analysis (IGARSS'14 tutorial)</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/tutorial_igarss15.tar.gz target=_blank rel="noopener noreferrer"><img src=/images/courses/remote_sensing.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Instructors:</strong> G. Camps-Valls and D. Tuia</p><p class=text-justify>In this tutorial, we will present the remote sensing image processing chain, and take the attendants on a tour of different strategies for feature extraction, classification, unmixing, retrieval, and pattern analysis for data understanding. On the one hand, we will present powerful methodologies for remote sensing data classification: extracting knowledge from data, including interactive approaches via active learning, classifiers that encode prior knowledge and invariances, semi-supervised learning that exploits the information of unlabeled data, and domain adaptation to compensate for shifts in the ever-changing data distributions. On the other hand, we will pay attention to recent advances in bio-geophysical parameter estimation that incorporate heteroscedasticity, online adaptation, and problem understanding. From there, we will take a leap towards the more challenging step of understanding the geoscience problems from data by reviewing the latest advances in (directed) graphical models, structure learning, and empirical causal inference. Beyond theory, we will also present results of recent studies illustrating all the covered issues. Finally, we will provide code to the attendees to try the different methodologies and provide a solid ground for their future experimentations.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Probabilities and Uncertainties</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://docenciavirtual.uv.es/series/682af4853f32202c9b5fd7f6 target=_blank rel="noopener noreferrer"><img src=/images/courses/probabilities_course.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 24 hours</p><p><strong>Instructors:</strong> G. Varando, H. Durand and K. Cohrs</p><p class=text-justify>Introduction to the concepts of probability and uncertainty, with some examples on how to work, estimate and eventually communicate with them. Learn classical statistical inference (frequentist and Bayesian) and advanced techniques for high-dimensional data and ML.
<a href=https://docenciavirtual.uv.es/series/682af4853f32202c9b5fd7f6>Video sessions</a></p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Remote Sensing for Water Quality</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href="https://www.youtube.com/watch?v=d67aO2z06dI" target=_blank rel="noopener noreferrer"><img src=/images/courses/EO_AnnaB_2023.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Instructors:</strong> Anna B. Ruescas</p><p class=text-justify>Anna B. Ruescas leads this session on remote sensing for water quality, as part of the 2023 ESA Earth Observation Advanced Training Course at the Wroclaw University of Environmental and Life Sciences.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Representation of Spatial Information</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/Represent_Spatial_Information.zip target=_blank rel="noopener noreferrer"><img src=/images/courses/base.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 30 hours</p><p><strong>Instructors:</strong> J. Malo</p><p class=text-justify>Statistical regularities in photographic images imply that certain representations of spatial information are better than others in terms of coding efficiency. In this course, we present the information theory concepts (entropy, multi-information, correlation and negentropy) for unsupervised feature extraction or dictionary learning required in image coding. Redundancy in images and sequences is reviewed, and basic techniques for compact information representation are introduced such as vector quantization, predictive coding, and transform coding. Application of these concepts in images is the basis of DCT and Wavelet representations, which are the core of JPEG and JPEG2000.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Satellite-based Tools for Investigating Aquatic Ecosystems</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href="https://www.youtube.com/watch?v=pknYqAAtxRE" target=_blank rel="noopener noreferrer"><img src=/images/courses/annaB_SNAP23.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Instructors:</strong> Anna B. Ruescas</p><p class=text-justify>Anna B. Ruescas participates in this session on the use of Sentinel Constellation SNAP Tools, as part of the 2023 Satellite-based Tools for Investigating Aquatic Ecosystems Training at the Trevor Platt Science Foundation.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Statistical Signal Processing</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/ps_2014.pdf target=_blank rel="noopener noreferrer"><img src=/images/courses/signal_theme.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 60 hours</p><p><strong>Instructors:</strong> G. Camps-Valls</p><p class=text-justify>Material for a master course on (statistical) signal processing. I cover the essential background for engineers and physicists interested in signal processing: Probability and random variables, discrete time random processes, spectral estimation, signal decomposition and transforms, and an introduction to information theory.</p></h5></div></div></div></div><div class=panel-item><div class=panel-header><h4 class=panel-title><b>Texture and Motion in the Visual Cortex</b></h4></div><div class=panel-body><div class="panel-content row"><div class="panel-image col-md-2"><a href=https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/courses/Color_Vision.zip target=_blank rel="noopener noreferrer"><img src=/images/courses/mt_theoret_sensit.webp alt=.webp></a></div><div class=panel-description><h5><p><strong>Course Duration:</strong> 40 hours</p><p><strong>Instructors:</strong> J. Malo</p><p class=text-justify>Neurons in V1 and MT cortex play a determinant role in the analysis of the shape of objects, their spatial texture, and the estimation of retinal motion. In this course, we describe the basic psychophysical and physiological phenomena related to low-level spatio-temporal vision: the contrast sensitivity functions, masking, adaptation, and aftereffects. These facts are mediated by the context-dependent nonlinearities of the response of neurons with specific receptive fields. We analyze the geometric properties of the standard model of V1 and their consequences in image discrimination. We introduce the concept of optical flow, its properties, and how this description of motion can be estimated from the 3D wavelet sensors in V1 and the aggregated sensors in MT.</p></h5></div></div></div></div><p></p></div></div></main><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script></body></html>