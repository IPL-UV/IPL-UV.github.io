<!DOCTYPE html>

<html lang="en"><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
<meta content="" name="description"/>
<meta content="" name="author"/>
<link href="/images/adicionales/favicon.ico" rel="icon"/>
<title>ISP - Software: VistaModels</title>
<!-- Bootstrap core CSS -->
<link href="./infoDN_files/bootstrap.min.css" rel="stylesheet"/>
<!-- Bootstrap theme -->
<link href="./infoDN_files/bootstrap-theme.min.css" rel="stylesheet"/>
<!-- Custom styles for this template -->
<!-- <link href="theme.css" rel="stylesheet"> -->
<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
<!-- Local styles -->
<link href="./infoDN_files/styles.css" rel="stylesheet"/>
</head>
<body role="document" style="padding-top: 50px;">
<div class="row" id="Top">
<hr/>
</div>
<div class="container">
<div class="row"> <!------------------------------ TITLE --------------------------------------->
<div class="col-md-2">
</div>
<div class="col-md-8" style="width: 52%; text-align: center; margin-top: 0%; margin-left: 0%; margin-right: auto;">
<h2><span class="label label-info" style="font-style: italic;">Spatio-Chromatic Information available from different Neural Layers</span></h2>
<h2><span class="label label-info" style="font-style: italic;">J. Malo, Journal of Mathematical Neuroscience 2020</span></h2>
</div>
<div class="col-md-2">
</div>
</div>
<div class="row"> <!--------------------------------------- PICTURE - ABSTRACT + INDEX - PICTURE --------------------------------------------->
<!--------------------------------------- IZQUIERDA --------------------------------------------->
<!--------------------------------------- IZQUIERDA --------------------------------------------->
<!--------------------------------------- IZQUIERDA --------------------------------------------->
<div class="col-md-3">
<!---
              <div class="container" style="width: 120%;text-align: left; margin-top: -5%; margin-left: -30%; margin-right: auto;">
              <img alt="Jesus" class="img-responsive" src="VistaModels1.JPG">
              <p align="justify"><strong>Mechanistic Models:</strong> <small>Following Hubel-Wiesel and McCulloch-Pitts, our models are cascades of two basic elements: (a) a linear transform (not necessarily convolutional set of receptive fields), and (b) a nonlinear saturation (either divisive or subtractive) describing the interactions between the linear units. We have played with different versions of such elements. For the linear part we explored center-surround units, local-DCTs, Orthonormal Wavelets, Overcomplete Wavelets and Laplacian Pyramids. For the nonlinear part played with different adaptive nonlinearities such as the Divisive Normalization and the subtractive Wilson-Cowan equations. See [<a href="https://arxiv.org/abs/1711.00526">PLoS 2018</a>] for a comprehensive account of the maths, and
              [<a href="https://arxiv.org/abs/1804.05964">ArXiV 2018</a>] for the equivalence between the considered nonlinear models. These models have been tuned to reproduce basic psychophysics such as contrast response curves and subjective image distortion.</small></p><br><br><br><br><br>
              </div>
        ------------>
</div>
<!--------------------------------------- CENTRO --------------------------------------------->
<!--------------------------------------- CENTRO --------------------------------------------->
<div class="col-md-6" style="width: 50%;text-align: left; margin-top: 0%; margin-left: -1%; margin-right: auto;">
<p align="justify">The image representations along the retina-cortex pathway are analyzed in terms of their ability to capture information about the visual scenes. The considered series of representations includes: (1) the LMS retinal images, (2) their von-Kries adapted version, (3) the opponent images at LGN, (4) their nonlinear version after Weber-like saturation, (5) the cortical local-frequency representation filtered by achromatic and chromatic CSFs, and (6) the cortical representation after divisive normalization.
            <br/>
            Assuming a single-step transform from the retinal input to each of these representations, and sensors of the same Signal-to-Noise quality in each representation, our estimations of transmitted information show that:
            (a) progressively deeper representations are better in terms of the amount of captured information,
            (b) the transmitted information up to the cortical representation follows the probability of natural scenes over the chromatic and achromatic dimensions of the stimulus space,
            (c) the contribution of spatial transforms to capture visual information is substantially greater (67%) than the contribution of chromatic transforms (33%), and
            (d) nonlinearities of the responses contribute substantially to the transmitted information (about 28%) but less than the linear transforms (72%).
            <br/>
            The parameters of the model have psychophysical origin and they were not statistically optimized in any way.
            The information estimates were computed using our <a href="./RBIG4IT.htm">Gaussianization transform</a> (Laparra et al. IEEE TNN 11) over our <a href="../../../data/calibrated_color_image/subpages/data_color.html">database of colorimetrically-calibrated images</a> (Laparra et al. Neur.Comp. 12), but equivalent results
            are obtained using other estimates (e.g. offset corrected Kozachenko-Leonenko [Marin et al. IEEE PAMI 13]) or other databases (e.g. Foster et al [Vis.Res.15,16]).
            </p><br/>
<div class="list-group">
<a class="list-group-item" href="./infoDN.html#download">
<h4 class="list-group-item-heading" style="color:rgb(255,50,50)"><strong>Download Data and Code!</strong></h4>
</a>
<a class="list-group-item" href="./infoDN.html#references">
<h4 class="list-group-item-heading" style="color:rgb(0,150,200)"><strong>Citation and References</strong></h4>
</a>
</div>
</div>
<!--------------------------------------- DERECHA --------------------------------------------->
<!--------------------------------------- DERECHA --------------------------------------------->
<div class="col-md-3">
</div>
</div>
<!-- %%%%%%%%%%%%%%%%%%%%% CUANDO PASE EL CHAPARRON VUELVE A INTRODUCIR EL NIVEL <h2> EN VERDE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%% CUANDO PASE EL CHAPARRON VUELVE A INTRODUCIR EL NIVEL <h2> EN VERDE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%% CUANDO PASE EL CHAPARRON VUELVE A INTRODUCIR EL NIVEL <h2> EN VERDE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<!-- %%%%%%%%%%%%%%%%%%%%% CUANDO PASE EL CHAPARRON VUELVE A INTRODUCIR EL NIVEL <h2> EN VERDE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<div class="row">
<div class="col-md-3">
<!-- %%%%%%%%%%%%%%%%%%%%% Nadie a la izquierda %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
</div>
<div class="col-md-6" style="width: 60%;text-align: left; margin-left: -10%; margin-right: auto;">
<!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% EMPIRICAL MODELS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<hr id="download"/><br/><br/>
<a href="./infoDN.html#Top"><small>Back to top</small></a>
<h2><span class="label label-danger">Download Data and Code!</span></h2>
<ul>
<li> <strong><span style="color:rgb(255,0,0)">Data and Code</span> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/infoDivisiveNormalization.zip"> infoDivisiveNormalization.zip (17GB) </a> </strong> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/infoDivisiveNormalization.zip"><img alt="mat" src="/images/adicionales/matlab_ico.gif" style="border: 0px solid ; width: 21px; height: 20px;"/></a>
</li></ul>
<hr id="references"/><br/>
<a href="./infoDN.html#Top"><small>Back to top</small></a>
<h2><span class="label label-success">Citation and References</span></h2>
<p align="justify"><strong style="color:rgb(0,160,0)">PAPER: </strong></p>
<strong>J. Malo.<br/> <a href="https://arxiv.org/abs/1910.01559">Spatio-Chromatic Information available from different Neural Layers via Gaussianization</a> <br/>J. Mathematical Neuroscience (2020)</strong> https://doi.org/10.1186/s13408-020-00095-8 <br/> https://arxiv.org/abs/1910.01559 <a href="https://rdcu.be/caFYZ"><img alt="mat" src="/images/adicionales/pdf16x16.gif" style="border: 0px solid ;width: 16px; height: 16px;"/></a><br/><br/>
<p align="justify"><strong style="color:rgb(0,160,0)">Related papers: </strong></p>
       A. Gómez-Villa, M. Bertalmío and J. Malo,<br/> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/infoWC_JNP19.pdf">Visual information Flow in Wilson Cowan Networks.</a> J. Neurophysiol. 123 (6): 2249-2268 (2020) https://doi.org/10.1152/jn.00487.2019 <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/infoWC_JNP19.pdf"><img alt="mat" src="/images/adicionales/pdf16x16.gif" style="border: 0px solid ; width: 16px; height: 16px;"/></a>
<a href="./infoWilsonCowan.html">Web site</a><br/><br/>


      J. Malo.<br/> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Entropy_conf_2020.pdf">Information Flow in Color Appearance Neural Networks</a> arXiv: Quantitative Biology, Neurons and Cognition https://arxiv.org/abs/1912.12093 (2019) <a href="https://arxiv.org/abs/1912.12093"><img alt="mat" src="/images/adicionales/pdf16x16.gif" style="border: 0px solid ; width: 16px; height: 16px;"/></a><br/><br/>
<p align="justify"><strong style="color:rgb(0,160,0)">Project Notebook: </strong></p>
       J. Malo and Q. Li,<br/> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/NOTES_info_flow_psycho_models.pdf">Visual information Flow in Psychophysical-Physiological networks.</a> Notebook (as of July 2021)<br/>
<a href="https://docs.google.com/document/d/14LvHeix6zE92e-T4w7e9ZmBqS6uVd4uOJ22N6-NFCc0/edit">Evolving Google Notebook</a><br/><br/>
<br/><br/><br/><br/><br/>
<div class="col-md-3">
<!-- %%%%%%%%%%%%%%%%%%%%% Nadie a la derecha %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
</div>
</div>
</div><!-- /.container -->
<!-- Bootstrap core JavaScript
    ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="./infoDN_files/jquery-1.12.4.min.js"></script>
<script src="./infoDN_files/bootstrap.min.js"></script>
</div></body></html>