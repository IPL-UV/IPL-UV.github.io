<!doctype html><html lang=en-us dir=ltr><head><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin=anonymous referrerpolicy=no-referrer><link rel="shortcut icon" href=http://isp.uv.es/favicon.ico type=image/x-icon><link rel=stylesheet href=/style/style.css></head></head><body><nav class="navbar navbar-expand-lg bg-body-tertiary fixed-top"><div class=container-fluid><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarTogglerDemo01 aria-controls=navbarTogglerDemo01 aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarTogglerDemo01><ul class="navbar-nav mx-auto mb-lg-0"><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/>ISP</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/people/>People</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle active a" href=/research/ role=button data-bs-toggle=dropdown aria-expanded=false>Research</a><ul class=dropdown-menu><li><a class="dropdown-item a" href=/research/machine_learning/>Machine learning</a></li><li><a class="dropdown-item a" href=/research/visual_neuroscience/>Visual neuroscience</a></li><li><a class="dropdown-item a" href=/research/visual_brain/>Visual brain</a></li><li><a class="dropdown-item a" href=/research/earth_science/>Earth science</a></li><li><a class="dropdown-item a" href=/research/social_science>Social science</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/projects/>Projects</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/facilities/>Facilities</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle active a" href=/publications/ role=button data-bs-toggle=dropdown aria-expanded=false>Publications</a><ul class=dropdown-menu><li><a class="dropdown-item a" href=/publications/journals/>Journals</a></li><li><a class="dropdown-item a" href=/publications/conferences/>Conferences</a></li><li><a class="dropdown-item a" href=/publications/books/>Books</a></li><li><a class="dropdown-item a" href=/publications/talks/>Talks</a></li><li><a class="dropdown-item a" href=/publications/technical_reports/>Technical Reports</a></li><li><a class="dropdown-item a" href=/publications/theses/>Theses</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/code/>Code</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/data/>Data</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/seminars/>Seminars</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/courses/>Courses</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/collaborators/>Collaborators</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/news/>News</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link active a" aria-current=page href=/contact/>Contact</a></li></ul></div></div></nav><style>.navbar{--bs-navbar-padding-y:0rem !important;background-color:#222!important}.a{color:#949494!important}.a:hover{color:#fff!important}.navbar-nav .dropdown:hover .dropdown-menu{display:block}.navbar-nav .dropdown-menu:hover{display:block}.dropdown-menu{margin-top:7px}.navbar-toggler-icon{background-image:url("data:image/svg+xml,%3csvg viewBox='0 0 30 30' xmlns='http://www.w3.org/2000/svg'%3e%3cpath stroke='white' stroke-width='2' stroke-linecap='round' stroke-miterlimit='10' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e")}.navbar-toggler{border:none}.navbar-toggler:focus{outline:none}.nav-item-highlight{padding:.4rem}.nav-item-highlight:hover{background-color:#2d70aa!important}.dropdown-menu{background-color:#fff!important;color:#000!important}.dropdown-item:hover{background-color:#2d70aa!important;color:#fff!important}.navbar-nav li.nav-item .nav-link,.dropdown-menu .dropdown-item{transition:color .3s,background-color .3s}.navbar-toggler:focus{box-shadow:none!important}</style><script>document.querySelectorAll(".dropdown-toggle").forEach(e=>{e.removeAttribute("data-bs-toggle")})</script><script>window.onload=function(){const e=window.devicePixelRatio,t=document.querySelector(".navbar-collapse");e>=1.25&&t.classList.add("show")}</script><main><div class=container><h1 id=machine-learning>Machine learning</h1><p><br></br></p><h2 id=motivation>Motivation</h2><p><strong>Machines may extract knowledge from measurements by analyzing the statistical properties of the acquired signals.</strong> The aim is to capture the structures in the experimental data. Our contributions to machine learning include algorithms for automatic classification (recognition) of objects, robust regression tools for multidimensional data, density estimation algorithms, and feature extraction and selection. We study the principled design of learning algorithms, specially neural networks and kernel methods. <strong>Methods are designed for general purposes but also specific to the application, most of them related to image processing, computer vision tasks and Earth science data analysis, but also non-structured data in social sciences.</strong></p><h2 id=an-ai-agenda>An AI agenda</h2><p><strong>The main research hypothesis of our research agenda is that current AI models are limited to tackle fitting problems only, and do not have a clear notion of space, time and causal relations.</strong> We need to aboard the more ambitious questions of understanding through machine learning, going beyond mere model fitting. This goal needs to develop (i) targeted ML that respects data characteristics, (ii) hybrid physics-aware ML that incorporates domain knowledge and inductive priors, and more importantly (3) moving from fitting to understanding through AI models that are explainable and grasp causal relations from observational data.</p><p><img src=img/philosophy_balls.webp style=width:800px;display:block;margin:auto></img><br></p><p><strong>In order to advance in the previous AI agenda, we base our research in 3 fundamental research pillars:</strong></p><ul><li><strong>Pillar 1. Targeted AI.</strong> We developed advanced model inversion that account for the particular data characteristics (nonstationariety, non-Gaussianity, non-linearity), specifically designed to deal with (un)structured data, and focus on modeling and understanding a system through data-driven characterization of system&rsquo;s behaviour (memory, bifurcation, stability).</li><li><strong>Pillar 2. Physics-aware modeling, inductive biases and domain knowledge in machine learning.</strong> Our activities here encompass developing algorithms that live in the Physics and machine learning interplay: both through encoding (hybrid machine learning models) and decoding (discovery principles and physical laws from data).</li><li><strong>Pillar 3. Explainable AI and Causality.</strong> Scientific consistency, reliability, and explainability of obtained results are of paramount importance in complex systems. A prerequisite to achieve those is to design ML models that cannot be challenged, or whose inner functioning can be visualized, queried or interpreted. We aim to achieve transparency, interpretability and explainability of models to achieve a wider adoption and confidence by domain scientists. Yet, ML model interpretability is not enough because model development already assumes a causal relation, the real far-end goal of learning with machines.</li></ul><h2 id=challenges-and-approaches>Challenges and approaches</h2><p><strong>The group has a relatively long tradition in machine learning, particularly focused on the study and development of neural networks and kernel machines.</strong> Recently, the fields of manifold, semisupervised and active learning have captured our attention. The study of the intrinsic coordinates and representations where data in general, and images in particular, live is interesting for many applications. Regression and classification methods must be modified to deal with changes in data/image statistics efficiently. <strong>In many signal and image processing problems, such as change detection or multitemporal data classification, adaptation is a must. We currently model shifts, twists and wrappings of image distributions by designing semisupervised learning methods. The fields of manifold alignment and domain adaptation has also important information-theoretic implications which we analyzed through kernel entropy component analyis, multivariate Gaussianization transforms and extensions of principal curves and surfaces. And yes, deep learning is of interest to us; what has the networked learned? and why?</strong> Follow our works in <a href=papers.html>Papers</a>.</p><p>Purely supervised methods work very well in static environments and when representative experimental data are observed. If this does not happen, algorithms may fail because data structured has not been accurately captured and modeled. We are also interested in complementary fields that arise under such circumstances: <strong>active learning</strong>, which tries to select the most informative samples to improve algorithm&rsquo;s performance, and semisupervised learning, which is focused on exploiting the wealth of unlabeled data to improve performance. Semisupervised learning typically resorts to modeling data distributions whose characteristics are then imposed to the signal model. This is a very challenging problem that is directly related to <strong>density estimation</strong> (since one ultimately seeks for a proper model of the marginal data density) and <strong>manifold learning</strong> (since the intrinsic data coordinates need to be found for data characterization).</p><p>While supervised learning is already equipped with an efficient toolbox of methods, unsupervised learning (clustering) is far from being a solved problem. The goal here is to identify and characterize clusters that truly represent data structure (e.g. identifying the independent components). Meaningful data representations (or efficient feature extraction) and accurate <strong>probability density function (PDF) estimations</strong> are the key to solve a variety of Image and Signal processing problems, as well as to <strong>understand the behavior of the visual brain from a statistical point of view</strong>. We focus on looking for efficient non-linear transforms for data representation: note that feature extraction is just a form of non-linear sensor design. Our research has followed different alternative directions.</p><p>Modeling input data, however, does not ensure that the model will adapt to changing environments. Imagine the same scene under different illuminations or an exchange rate time series under different economical situations. These specific problems are known under different names: <strong>transfer learning, domain adaptation, and adaptive learning</strong>. The field is very active nowadays, especially because incredibly huge amounts of data streams are being acquired (satellite images, internet videos, photos, etc) and need to be analyzed. We tackle these problems with kernel methods, trying to accommodate data shifts in the notion of similarity, or by defining proper signal models in reproducing kernel Hilbert spaces.</p><p><strong>Sparsity as a form of compacting information was studied in both deep architectures and kernel machines.</strong> In all these settings, we are particularly interested in <strong>encoding prior knowledge and invariances</strong> in the models: signal and noise properties, spatial-temporal constraints, amd robustness to illumination changes, just to name a few. Dealing with invariances and priors inmediately call for <strong>regularization and Bayesian inference</strong>. While pure discriminative approaches have been developed in our group, in recent years we have payed attention to the field of Bayesian nonparametric models as a proper framework to encode such beliefs. We are active in kernel design for <strong>Gaussian processes regression and model inversion, and in designing efficient sampling schemes with modern Markov Chain Montecarlo strategies</strong>.</p><h3 id=related-projects>Related projects</h3><div class=content-container style=font-size:1.1em;text-align:justify;line-height:1.1><table class="table table-hover"><tr><th style=width:10%><img src=/isp/images/research/h2020.jpg height=50 width=80></th><th style=width:90%><a href=https://xaida.eu>XAIDA: Extreme Events - Artificial Intelligence for Detection and Attribution</a><br>EU H2020, UV PI: Gustau Camps-Valls, 2021-2025</th></tr><tr><th style=width:10%><img src=/isp/images/research/h2020.jpg height=50 width=80></th><th style=width:90%><a href=https://deepcube-h2020.eu>DeepCube: Explainable AI pipelines for big Copernicus data, UV PI: Gustau
Camps-Valls</a><br>EU H2020, 2021-2024</th></tr><tr><th style=width:10%><img src=/isp/images/research/h2020.jpg height=50 width=80></th><th style=width:90%><a href=https://www.elise-ai.eu/>ELISE: European Learning And Intelligent Systems Excellence</a><br>ICT-48, Universitat de Val√®ncia (UVEG) is a Participant partner, UV PI: Gustau Camps-Valls, 2020-2022</th></tr><tr><th style=width:10%><img src=/isp/images/research/erc.png height=70 width=80></th><th style=width:90%><a href=https://www.usmile-erc.eu/>USMILE: Understanding and Modeling the Earth System with Machine
Learning</a><br>ERC Synergy Grant, PIs: V. Eyring, M. Reichstein, G. Camps-Valls, P. Gentine, 2020-2026</th></tr><tr><th style=width:10%><img src=/isp/images/research/aida.png height=50 width=80></th><th style=width:90%><a href=https://www.i-aida.org/>i-AIDA: International AI Doctoral Academy</a><br>ICT-48 alliance and network of excellence in AI, G. Camps-Valls, 01/01/22</th></tr></table><br><br></div></div></main></body><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous></script></html>