<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><link rel="shortcut icon" href=/images/isp_ico.webp type=image/x-icon><link href=https://fonts.cdnfonts.com/css/twentieth-century-for-kenmore rel=stylesheet><link rel=stylesheet href=/style/style.css><link rel=stylesheet href=/style/bootstrap-cosmo.min.css><link rel=stylesheet href=/style/bootstrap-theme.css><link rel=stylesheet href=/style/bootstrap.css><link rel=stylesheet href=/style/bootstrap.min.css><link rel=stylesheet href=/style/bootswatch.min.css><script src=/js/mode.js></script><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-D8CVQKS51G"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D8CVQKS51G")</script></head><body><nav class=custom-navbars><div class=custom-container><a href=/ class="custom-logo custom-hide-on-large"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" class=custom-logo_nav>
<span class=custom-text-isp>ISP</span>
</a><button class=navbar-toggler aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class=custom-navbar-collapse><ul class=custom-navbar-nav><li class="custom-nav-item custom-desktop-only"><a class=custom-nav-link href=/>ISP</a></li><li class=custom-nav-item><a class=custom-nav-link href=/people/>People</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/research/philosophy/>Research</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/research/philosophy/>Philosophy</a></li><li><a class=custom-dropdown-item href=/research/machine_learning/>Machine learning</a></li><li><a class=custom-dropdown-item href=/research/visual_neuroscience/>Visual science</a></li><li><a class=custom-dropdown-item href=/research/visual_brain/>Image processing</a></li><li><a class=custom-dropdown-item href=/research/earth_science/>Earth science</a></li><li><a class=custom-dropdown-item href=/research/social_science>Social science</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/projects/>Projects</a></li><li class=custom-nav-item><a class=custom-nav-link href=/facilities/>Facilities</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/publications/journals/>Publications</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/publications/journals/>Journals</a></li><li><a class=custom-dropdown-item href=/publications/conferences/>Conferences</a></li><li><a class=custom-dropdown-item href=/publications/books/>Books</a></li><li><a class=custom-dropdown-item href=/publications/talks/>Talks</a></li><li><a class=custom-dropdown-item href=/publications/theses/>Theses</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/code/>Code</a></li><li class=custom-nav-item><a class=custom-nav-link href=/data/>Data</a></li><li class=custom-nav-item><a class=custom-nav-link href=/seminars/>Seminars</a></li><li class=custom-nav-item><a class=custom-nav-link href=/courses/>Courses</a></li><li class=custom-nav-item><a class=custom-nav-link href=/collaborators/>Collaborators</a></li><li class=custom-nav-item><a class=custom-nav-link href=/news/>News</a></li><li class=custom-nav-item><a class=custom-nav-link href=/contact/>Contact</a></li></ul></div></div></nav><main><div class=container><div class=container><div class=row><div class=col-md-3></div><div class=col-md-6><p><center><h1><span class="label label-info">First words ex-cathedra</span></h1></center></p><br><p style=color:#0096c8 align=center><big><big><strong><span style=font-style:italic>Jes&uacutes Malo</span></strong></big></big><br><span style=font-style:italic>San Francisco, Starbucks at 390 Stockton St.<br>February 2015</p><br></div><div class=col-md-3></div></div><div class=row><div class=col-md-1></div><div class=col-md-2><div class=container style=width:100%;text-align:center;margin-left:0%;margin-right:auto><div class=row><div class=col-md-12 style=width:150%;text-align:right;margin-left:-80%;margin-right:auto><img alt=Jesus style=height:144px;width:120px src=images/images_ex/jesus.jpg><br><br><p style=color:#0096c8><left><big><strong><span style=font-style:italic>Contact Info:</span></strong></big></left></p><p><left>jesus dot malo at uv dot es</left></p><p><left>ISP: +34 963 544 099</left></p><p><left>Optics Dept: +34 963 544 041</left></p></div></div></div></div><div class=col-md-6><p align=justify>Circa 2015, applications for full professorship in Spanish universities (cathedra) involved writing an essay to describe your career and personal views on science. Here is what I wrote to get the condition of <span style=font-style:italic>Accredited University Professor</span>from the official National Evaluation Agency...<br>Now (after the positive outcome in july 2015) I upload the version with uncensored pictures, full text, and over 150 hyperlinks!. These are my first words ex-cathedra (even though my salary, as well as the salary of over 2500 colleagues in the same situation, will remain the same for a while unless we do <a href=#Constraints><span style=font-style:italic>something</span></a>):</p><div class=col-md-12 style=width:105%;text-align:left;margin-left:-2%;margin-right:auto><div class=list-group><a href=#Cool class=list-group-item><h4 class=list-group-item-heading style=color:#0096c8>Why a <span style=font-style:italic>physicist</span> would ever care about Human Vision?</h4><p class=list-group-item-text>Human vision is <span style=font-style:italic>cool</span></p></a><a href=#Sinatra class=list-group-item><h4 class=list-group-item-heading style=color:#0096c8>Chronological summary of my career:</h4><p class=list-group-item-text>While <span style=font-style:italic>Khun</span> and <span style=font-style:italic>Marx</span> were kind of wrong, <span style=font-style:italic>Sinatra</span> was right: <span style=font-style:italic>I did it my way</span>.</p></a><a href=#Research class=list-group-item><h4 class=list-group-item-heading style=color:#0096c8>My research contributions:</h4><p class=list-group-item-text>Colored noise in vision sciences and some thoughts on the h-index</p></a><a href=#Teaching class=list-group-item><h4 class=list-group-item-heading style=color:#0096c8>My teaching activity:</h4><p class=list-group-item-text>Why and optometrist (or engineer) would ever care about Maths (or Science)?</p></a><a href=#Constraints class=list-group-item><h4 class=list-group-item-heading style=color:#0096c8>Economic constraints of science in Spain:</h4><p class=list-group-item-text id=Cool>Why positive evaluations for professorship do not imply actual positions here?</p></a></div></div></div><div class=col-md-3></div></div><div class=row><div class=col-md-10><p><h2><span class="label label-success">1. Why a <span style=font-style:italic>physicist</span> would ever care about Human Vision?</span></h2></p></div><div class=col-md-2><br><h4><span class="label label-link"><a href=#Top>Back to top</a></span></h4></div></div><div class=row><div class=col-md-2></div><div class=col-md-8><br><p style=color:#00a000><big><big><strong>Think again: human vision is cool!</strong></big></big></p><p align=justify>The leit-motif of my research and teaching activity is the study of <span style=font-style:italic>visual information processing in the human brain</span>. This is a <span style=font-style:italic>biological</span> and <span style=font-style:italic>subjective</span> problem: not very appealing adjectives for a <span style=font-style:italic>big-bang theory guy</span>.
Nevertheless, the aspects of this problem that may be of interest for physicists determined the direction of my scientific career.<br><br>Despite the overuse of the word <span style=font-style:italic>multidisciplinary</span>, you have to consider that <span style=font-style:italic>Visual Perception</span> is a truly multidisciplinary problem. On the one hand, the input signal certainly involves <span style=font-style:italic>plain Physics </span>such as light emission and scattering in every-day scenes (<span style=font-style:italic>classical Radiometry</span>) and image formation in biological systems (<span style=font-style:italic>classical Physiological Optics</span>). However, on the other hand, the analysis of such input signal is a problem for </span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><span style=font-style:italic>Neuroscience</span></span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>: examples of the latter include the study of (natural) neural networks for image understanding.&nbsp;<span style=font-style:italic>Human Vision</span> is not at all limited to the laws of image formation, that basically date back to Newton <span style=font-style:italic>classical</span> <span style=font-style:italic>Optics</span>, but also include the formulation of laws that determine the organization of the sensors that make sense of these signals. And this is a quite different issue!. Regarding this analysis part, a <span style=font-style:italic>theory</span> that explains the visual cortex phenomena requires concepts coming from <span style=font-style:italic>Statistics</span> and <span style=font-style:italic>Information Theory</span>, or in nowadays jargon,&nbsp;<span style=font-style:italic>Machine Learning</span>.
A particularly interesting feature of this problem is the fact that, as opposed to other science problems, the relation between <span style=font-style:italic>maths</span> and <span style=font-style:italic>application</span> (here <span style=font-style:italic>Maths</span> and <span style=font-style:italic>Neuroscience</span>) is not one-directional: in this case the system to be understood is
actually a computing machine that may also inspire original mathematical approaches.
Finally, the models coming from <span style=font-style:italic>Theoretical Neuroscience</span> may be applied in <span style=font-style:italic>Electrical Engineering</span> and <span style=font-style:italic>Computer Science</span>.<br><br>From a personal (and hence arguable) point of view, the <span style=font-style:italic>Human Vision</span> problem is interesting for a physicist not for the aspects related to classical <span style=font-style:italic>Optics</span> (fundamentally solved long ago), but for the study of the visual brain. <span style=font-style:italic>Vision is not in the (well known) eye of the beholder, but in his/her (highly unknown) brain</span>. The visual brain is a <span style=font-style:italic>natural system</span> with <span style=font-style:italic>complex dynamics</span> (the jargon physicists love), quantitative theories for partial explanations are very recent, and many of them are still under discussion. The study of <span style=font-style:italic>Vision</span> combines experiments, mathematical theories and technological applications, and this combination is the core of how the physicists
approach the problems. It doesn't matter that the experimental methods come from the <span style=font-style:italic>Psychology</span>, the <span style=font-style:italic>Optometry</span> or the <span style=font-style:italic>Neurophysiology</span> (all of them use the so called <span style=font-style:italic>Psycho-Physics</span>) or that the applications are in <span style=font-style:italic>Image Processing</span> and <span style=font-style:italic>Computer Vision</span>: the study of the <span style=font-style:italic>Human Visual System</span> is certainly quite appropriate for a physicist.<br><br>The fascination for the surprising behavior of the visual system is what determined my scientific exploration: over the last 20 years I made some contributions (or <a href=#Noise>managed to introduce some colored noise</a> ;-) in most of the disciplines cited above.</p><table style=width:100%;text-align:left;margin-left:auto;margin-right:auto border=0 cellpadding=10 cellspacing=5><tbody><tr><td style=text-align:justify;vertical-align:top;width:302px><strong><span style=font-weight:700;color:#00a000>Motion illusions and Entropy: &nbsp;</span></strong><small>an example of this surprising behavior is the <span style=font-style:italic>Static Motion Aftereffect</span> (or the perception of reverse motion after prolonged exposure to a slowly moving pattern -see video-). Physicists like explanations from first principles (the so called <span style=font-style:italic>laws</span>), and this illusion can be understood according to a <span style=font-style:italic>law</span> based on communication theory. Sensors that maximize information transmission from sequences happen to have similar frequency tuning to motion sensitive neurons in V1 cortex. For the same efficiency reason, their response is nonlinear, and&nbsp;attenuates in the presence of high contrast moving patterns. Exposure to such patterns induces an operation regime that leads to the illusion while the system readapts to the new situation. <span style=font-weight:700>Optimal Information Transmission seems to be a<span style=font-style:italic> law </span>of Human Vision</span>. <a href=http://isp.uv.es/after_effects>[Find out more...]</a> It took me 20 years to <span style=font-style:italic>fully</span> understand that sentence.</small><br></td><td style=vertical-align:center;text-align:right;width:405px><iframe src=//www.youtube.com/embed/0G0rXqvwR0Q allowfullscreen frameborder=0 height=315 width=420></iframe><br><small><span style=font-style:italic>Video: look at the fixation cross and wait till motion stops</span></small></td></tr></tbody></table><br><p align=justify><strong><span style=font-weight:700;color:#00a000>More on the link between <span style=font-style:italic>Physics</span>, <span style=font-style:italic>Neuroscience</span>, and <span style=font-style:italic>Statistics</span>:&nbsp;</span></strong><small>if you are not already convinced of the relation (since you only listen to <a href=https://en.wikipedia.org/wiki/Argument_from_authority>authority arguments</a> ;-) I have something for you. The <span style=font-style:italic>New York University</span> (<a href=https://en.wikipedia.org/wiki/List_of_Nobel_laureates_by_university_affiliation#New_York_University>36 Nobel Laureates, wikipedia dixit</a> ;-) organizes its resources in this way: the <span style=font-style:italic>Physics Department</span> and the <span style=font-style:italic>Center for Neural Science</span> are in the very same building (both doors in the picture below lead to the&nbsp;same hall, and <span style=font-style:italic>physiology</span> and <span style=font-style:italic>theoretical physics</span> labs are interleaved). Moreover, the <span style=font-style:italic>Courant Institute of Mathematics</span>, famous for its research in <span style=font-style:italic>Statistical Learning</span> is exactly at the other side of the&nbsp;street (Washington Place).</small></p><img src=images/images_ex/AA_new_york_university.JPG class=img-responsive alt=NYUPhysicsNeuroscience></div><div class=col-md-2></div></div><hr id=Sinatra><br><div class=row><div class=col-md-10><p><h2><span class="label label-success">2. Chronological summary of my career:</span></h2></p></div><div class=col-md-2><br><h4><span class="label label-link"><a href=#Top>Back to top</a></span></h4></div></div><div class=row><div class=col-md-2></div><div class=col-md-7><br><p style=color:#00a000><big><big><strong>While Khun and Marx were kind of wrong, Sinatra was right:<br><span style=font-style:italic>I did it my way!</span></strong></big></big></p><p align=justify>Selecting a multidisciplinary problem implies having wide range of collaborators over the years. The topics and the collaborators to address them are the parts of the scientific career that one can actually choose.
<a href=https://en.wikipedia.org/wiki/Thomas_Kuhn><span style=font-style:italic>Thomas Kuhn</span></a> (or even <a href=https://en.wikipedia.org/wiki/Karl_Marx><span style=font-style:italic>Karl Marx</span></a>) would certainly say that economic constraints sometimes impose their own choices. In my case, even though <span style=font-style:italic>money</span> sometimes determined the order in which I visited different aspects of the problem (e.g. <span style=font-style:italic>applications</span> before <span style=font-style:italic>foundations</span>),<span style=font-style:italic> </span>economic constraints didn't imply modifications in the selected direction since I was fortunate enough to get steady funds along these two decades (more details on economic constraints below).<br>Constraints are usually harder in the teaching part since it is determined by the duties of the department where you happen to develop your research. Nevertheless, with some dedication, this part can also be modulated. Similarly to the research side (where I started at the <span style=font-style:italic>Optics Department</span> in the <span style=font-style:italic>Physics School</span>, but then I looked for collaborators in <span style=font-style:italic>Maths</span>, <span style=font-style:italic>Electrical Engineering</span> and <span style=font-style:italic>Computer Science</span>), in the teaching side I decided to give lectures in PhD and Master programs out of my department (beyond the department-related duties).
This was a way to convey the knowledge acquired in research activities to a broader audience.<br><br>Below is the list of multidisciplinary collaborators I found (or looked for) over the time. Note that in the formative years and right after getting my first permanent position, I focused on <span style=font-style:italic>applications</span> (e.g. image coding) to maximize funding probabilities. More recently, particularly after my second Spanish NSF Project as PI, I turned to the fundamental issues (the theory and the consideration of a higher abstraction level, as for instance in the current Explora Project -my 4th as PI-), yet still paying attention to technology transfer:<br><ul><li><p align=justify>I started my PhD thanks to the funds of the <a href=http://www.acuvueprofessional.com/fellowship-grants>European Vistakon Research Award</a> (Johnson & Johnson) obtained in 1994. My advisor was <a href=http://www.uv.es/artigas/>Jose Mar&iacutea Artigas</a> at the Optics Department, but in order to formalize the psychophysics done with <a href=https://es.wikipedia.org/wiki/%C3%81lvaro_Pons>A. Pons</a>, <a href=http://www.uv.es/capilla/>P. Capilla</a>, and <a href=https://www.researchgate.net/profile/Maria_Jose_Luque>M.J. Luque</a>, I decided to look for help in the computational issues at the Computer Science Dept. (with <a href=http://www.uv.es/ferri/>F. Ferri</a> as co-advisor).&nbsp;</p></li></ul><ul><li><p align=justify>The <a href=http://www.cies.org>Fulbright postdoc</a> I got for the period 2000-2001 allowed me to work with world-class researches in <span style=font-style:italic>Vision Science</span>, both from the experimental perspective (<a href=http://vision.arc.nasa.gov/personnel/watson/watson.html>Beau Watson</a> at the <span style=font-style:italic>NASA Ames Research Center</span>) and the theoretical perspective (<a href=http://www.cns.nyu.edu/%7Eeero/>Eero Simoncelli</a> at the <span style=font-style:italic>Center for Neural Science</span> and <span style=font-style:italic>Courant Institute of Mathematics</span> at the <span style=font-style:italic>NYU</span>). I already knew about <span style=font-style:italic>divisive normalization</span> [<a href=http://www.carandinilab.net/Carandini-1994-science.pdf>Carandini94</a>, <a href="https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-14-9-2379">Watson97</a>, <a href=http://www.sciencedirect.com/science/article/pii/S0042698997001831>Simoncelli98</a>], but there I better understood its relation with unsupervised learning [<a href=http://www.nature.com/nature/journal/v381/n6583/abs/381607a0.html>Olshausen96</a>, <a href=http://www.cns.nyu.edu/pub/lcv/schwartz01-reprint.pdf>Schwartz01</a>]. These were the inspiration for a lot of later work.</p></li></ul><ul><li><p align=justify>When I came back from the US and I got my permanent position, I started my period as PI in public-funded projects with <a href=http://www.io.csic.es/PagsPers/JPortilla/>J. Portilla</a> (<span style=font-style:italic>CSIC Optics Institute</span>) working on image coding and restoration. Due to my participation in PhD programs of Applied Mathematics and Computer Science,&nbsp; I advised the PhDs of <a href=http://www3.uji.es/%7Eepifanio/>I. Epifanio</a> and <a href=http://www.uv.es/%7Ejgutierr/index_en.html>J. Guti&eacuterrez</a>, now faculty staff in different universities. Moreover, I looked for collaborators at the <span style=font-style:italic>Electrical Engineering Department</span> (<a href=http://www.uv.es/gcamps/>G. Camps</a>, <a href=http://www.uv.es/jordi/>J. Mu&ntildeoz</a> and <a href=http://www.uv.es/%7Echovago/>L. G&oacutemez</a>) to set the <a href=http://isp.uv.es><span style=font-style:italic>Image and Signal Processing Group</span></a> where I lead the activities related to <a href=http://isp.uv.es/neuro.html><span style=font-style:italic>Vision Science</span></a> and <a href=http://isp.uv.es/improc.html><span style=font-style:italic>Image Processing</span></a>. In this period, as a result of my activity as PI of different regional and national projects I contacted with groups from national and international universities (e.g. the <span style=font-style:italic>Computer Vision Center of UAB</span> -<a href=http://www.cvc.uab.cat/%7Exotazu/>X. Otazu</a>-, the<span style=font-style:italic> Electrical Eng. Dept. of UAB</span> -<a href="http://deic.uab.es/personal/membres.php?idioma=2&amp;id=18">J. Serra</a>-, or the Mathematics and Statistics Dept. of <span style=font-style:italic>Helsinki University</span> with <a href=http://www.cs.helsinki.fi/u/ahyvarin/>A. Hyvarinen</a> and <a href=https://sites.google.com/site/michaelgutmann/>M. Gutmann</a>).</p></li></ul><ul><li><p align=justify>Currently, particularly after my 3rd advised PhD (<a href=http://www.uv.es/lapeva/>V. Laparra</a>, currently PostDoc at <span style=font-style:italic>NYU</span>), and my second stay in the US at Stanford and <span style=font-style:italic>NYU</span> (now as <span style=font-style:italic>Senior Visiting Researcher</span> in 2013), I am more interested in&nbsp;<span style=font-style:italic>Theoretical Visual Neuroscience</span>. As a result, I contacted Prof. <a href=http://thevisualanalogylab.wix.com/valab>L. Mart&iacutenez Oter</a><a href=http://thevisualanalogylab.wix.com/valab>o</a> (<span style=font-style:italic>CSIC Neuroscience Institute</span>) to be co-PI of a recently funded national project on modeling cortical circuits for neural response inversion. His experimental know-how and wider neuroscience perspective will also be critical in another national project involving fMRI for neuroaesthetics I am PI of.
On top of these theoretical activities, following our industrial patent in 2008, I am also conducting technology transfer through two applied projects I am PI of: one funded by the regional goverment to cooperate with<span style=font-style:italic> <a href=http://www.analog.com/en/index.html>Analog Devices</a></span><a href=http://www.analog.com/en/index.html> Inc.</a>, and the other funded by <a href=http://www.davalorsalud.com/><span style=font-style:italic>Davalor Salud</span></a>, a company devoted to the automated evaluation of visual function. Moreover, <a href=https://portal.upf.edu/web/etic/entry/-/-/15515/409/marcelo-jos%C3%A9-bertalmio>M. Bertalmio</a>'s group at <span style=font-style:italic>Univ. Pompeu Fabra</span> is helping me to measure multi-stage vision models for digital movies using his ERC funds.</p></li></ul><ul><li><p align=justify>An illustration of the multidisciplinarity is the wide range of my editorial services. Beyond the regular reviewing activities in 17 JCR journals (including <a href=http://www.mitpressjournals.org/loi/neco><span style=font-style:italic>Neural Comp.</span></a>, <a href=https://www.osapublishing.org/josaa/home.cfm><span style=font-style:italic>JOSA</span></a>,<span style=font-style:italic> <a href=http://cis.ieee.org/ieee-transactions-on-neural-networks-and-learning-systems.html>IEEE Trans.Neur.Net.</a></span>,<span style=font-style:italic> <a href=http://www.jmlr.org/>JMLR</a></span>, <span style=font-style:italic><a href=http://www.signalprocessingsociety.org/publications/periodicals/jstsp/>IEEE J.Sel.Top.Sig.Proc.</a>,</span> <a href=http://www.journals.elsevier.com/computers-and-mathematics-with-applications/><span style=font-style:italic>Comp.& Math.Appl.</span></a>, <a href=http://www.grss-ieee.org/publications/transactions/><span style=font-style:italic>IEEE Trans.Geosci.Rem.Sens.</span></a>, <a href=http://www.journals.elsevier.com/image-and-vision-computing/><span style=font-style:italic>Im.&amp;Vis.Comp.</span></a>, or <a href=http://iopscience.iop.org/2040-8986/><span style=font-style:italic>J. Opt.</span></a>) and in major conferences (including <a href=https://nips.cc/>NIPS</a>, <a href=http://e-nns.org/>ICANN</a>, <a href=http://dblp1.uni-trier.de/db/conf/sspr/index.html>IAPR-SSPR</a>&nbsp;or <a href=http://www.ieee.org/conferences_events/index.html>IEEE ICIP</a>), I was Associate Editor of the <a href=http://www.signalprocessingsociety.org/publications/periodicals/image-processing/>IEEE Transactions on Image Processing</a> (IF=3.11, 1st quartile JCR) in the period 2009-2013, and currently I am Academic Editor of <a href=http://www.plosone.org/>PLoS ONE</a> (IF = 3.55, 1st quartile JCR) for the period 2014-2017, in both cases dealing with manuscripts in the intersection of<span style=font-style:italic> Human Vision</span> and<span style=font-style:italic> Machine Learning</span>.</p></li></ul><p align=justify>As summary, I find that, despite the troubles of a truly multidisciplinary topic, the path has been (kind of) coherent and successful. At this point I have to thank <span style=font-weight:700>Prof. Jose Mar&iacutea Artigas</span> (see below) for his lectures on <span style=font-weight:700;font-style:italic>Physics of Vision</span>:
a small course for the physics students which (unfortunately!) is no longer available in my university. In those lessons he told us about <span style=font-style:italic;font-weight:700>something completely different</span>. As fresh and educative as&nbsp;the <a href="https://www.youtube.com/watch?v=FGK8IC-bGnU"><span style=font-style:italic>Monty Python</span></a> for physics students.<br></p><table style=width:100%;text-align:left;margin-left:auto;margin-right:auto border=0 cellpadding=2 cellspacing=2><tbody><tr><td style=vertical-align:middle;text-align:left;width:70%><img class=img-responsive alt=PhysicalAncestors src=images/images_ex/family.JPG></td><td style=vertical-align:middle;text-align:left;width:2%><img class=img-responsive alt=P src=images/images_ex/white_rectangle.JPG></td><td style=text-align:right;width:23.65%><img class=img-responsive alt=AcademicAncestor src=images/images_ex/JoseMaria.jpg></td></tr><tr align=justify><td colspan=3 rowspan=1 style=width:100%><strong><span style=font-weight:700;color:#00a000>Physical ancestors (left): </span></strong><small>my parents Consuelo L&oacutepez (left) and Gaspar Malo (the man at the right), and my uncle and aunt (Manuel and Remedios). They could hardly read, however, they had a distinct preference for rational versus religious explanations of facts.</small>
<strong><span style=font-weight:700;color:#00a000>Scientific ancestor (right): </span></strong><small>Prof. Jose Mar&iacutea Artigas (here with granddaughter) could hardly operate a computer, however, after his stay at Cambridge in the eighties, he told a generation of physics students about <a href=https://en.wikipedia.org/wiki/Horace_Barlow>Horace Barlow</a> and <a href=http://www.jstor.org/stable/770136>Fergus Campbell</a>. Similarly to his friend <a href=http://redwood.psych.cornell.edu/people/david.html>David Field</a>, Jose Mar&iacutea used basically no math, but he transmitted the right concepts for those who wanted to listen. <span style=font-style:italic>It is not reading this <a href=http://global.britannica.com/science/vision-physiology>Encyclopaedia</a> or the <a href=https://en.wikipedia.org/wiki/Vision_science>other</a>, not even operating <a href=https://en.wikipedia.org/wiki/MATLAB>this</a> or <a href=https://en.wikipedia.org/wiki/MATHLAB>that</a> computer!.</span> I thank my ancestors the original way of thinking and the freedom they gave me to do it <span style=font-style:italic>my way</span>.</small></td></tr></tbody></table></div><div class=col-md-3><br><div align=center><p style=width:99%><img src=images/images_ex/jopt_cover.JPG class=img-responsive alt=JOptCover></p></div><p align=justify><small>Cover of Journal of Optics Vol. 25(3), 1994, made out of pictures from my first paper!. In the 90s simulations using 2D vision models working on actual images were unusual and easily deserved the cover of the journal (IF = 0.4, not a big deal but good enough for my first paper coming from a student lab ;-).</small></p><br><div align=center><p style=width:99%><img src=images/images_ex/PremioVistakon.JPG class=img-responsive alt=JOptCover></p></div><p align=justify><small>The Vistakon European Research Award I got in 1994 (together with other stuff in my bookshelf). Its money is what made me stay in the academia when I was about to leave!.</small></p><br><div align=center><p style=width:99%><img src=images/images_ex/neural_cover.JPG class=img-responsive alt=NeuralComputationCover></p></div><p align=justify><small>Cover of Neural Computation Vol. 22(12), 2010, made out of pictures from papers by Field & Chichilinsky (background) and Malo & Laparra (foreground). Theirs (in pink) is an illustration of the retina structure and ours (in gray) is an example of the probability of the response of a linear V1 cell given the response of another V1 cell.</small></p><div align=center><p style=width:100%><img src=images/images_ex/journals.JPG class=img-responsive alt="The IEEE"></p></div><p align=justify><small>I was invited to be Associate Editor of the Transactions on Image Processing by the Editor in Chief, Thrasos Pappas, and the Editorial Board of the Journal in 2009. However, it was mandatory to become an IEEE member (and pay) in advance. That is the IEEE view of <span style=font-style:italic>the business</span>. I quit the IEEE as soon as I finished my 5-year period as Associate Editor. Now I shifted to <span style=font-style:italic>open access</span> journals: I was invited to be Academic Editor of PLoS ONE (Public Library of Science) in 2014.</small></p><br></div></div><hr id=Research><br><div class=row><div class=col-md-10><p><h2><span class="label label-success">3. My research contributions:</span></h2></p></div><div class=col-md-2><br><h4><span class="label label-link"><a href=#Top>Back to top</a></span></h4></div></div><div class=row><div class=col-md-2></div><div class=col-md-8><br><p style=color:#00a000><big><big><strong>Colored noise in vision sciences and some thoughts on the h-index</strong></big></big></p><p align=justify>Here I put my&nbsp;contributions (up to 2015) in context by organizing them according to the <span style=font-style:italic>experimental</span>,<span style=font-style:italic> theoretical</span> and <span style=font-style:italic>application</span> categorization suggested in the introduction.</p><div style=margin-left:15%;width:70%;text-align:left;font-style:italic><ul><li><a href=#experiments><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><span style=font-weight:700>Experiments</span> in vision science</span></a></li><li style=margin-left:0;width:546px><a href=#empirical><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>Theory: <span style=font-weight:700>empirical models</span> in vision science</span></a></li><li style=width:585px><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><a href=#principled>Theory: <span style=font-weight:700>principled models</span> in vision science</a> (computational visual neuroscience)</span></li><li><a href=#learning><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>Theory: <span style=font-weight:700>statistical learning</span></span></a></li><li style=font-weight:700><a href=#applications><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>Applications in image processing</span></a></li><li style=font-weight:700><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><a href=#preliminary><span style=font-weight:400>Preliminary conclusions</span></a></span></li><li style=font-weight:700><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><a href=#Noise><span style=font-weight:400>Impact of the above: <span style=font-weight:700>h-index or just colored noise?</span></span><br></span></a></li></ul></div><hr id=experiments><br><p align=justify><h3><span class="label label-warning">Experiments in Vision Science (7 JCR publications)</span></h3></p><p align=justify>I made experimental contributions in three aspects: <span style=font-style:italic>Physiological Optics, Psychophysics</span> and <span style=font-style:italic>Image Statistics</span>. (i) In the field of <strong>Physiological Optics</strong>, we measured the optical transfer function of the lens+cornea system in-vivo [<a href=http://isp.uv.es/papers/OPH97.PS.gz>Opth.Phys.Opt.97</a>]. This work received the European Vistakon Research Award 94'. (ii) In <strong>Psychophysics</strong>, we proposed simplified methods to measure the Contrast Sensitivity Function in all the frequency domain [<a href=http://isp.uv.es/papers/JOPT94.PS.gz>J.Opt.94</a>], and a fast and accurate method to measure the parameters of multi-stage linear+nonlinear vision models [<a href=http://isp.uv.es/papers/malo15a-reprint.pdf>Proc.SPIE15</a>]. Finally, (iii) in <strong>Image Statistics</strong> we gathered spatially and spectrally calibrated image samples to determine the properties of these signals and their variation under changes in illumination, contrast and motion [<a href=http://isp.uv.es/papers/ivc99.ps.gz>Im.Vis.Comp.00</a>, <a href=http://isp.uv.es/papers/Neco_accepted_2012.pdf>Neur.Comp.12</a>, <a href=http://isp.uv.es/papers/manuscr_TGRS_2012_00431.pdf>IEEE-TGRS14</a>, <a href=http://isp.uv.es/papers/Gutmann_PLOS_ONE_2014.pdf>PLoS-ONE14</a>, <a href=http://isp.uv.es/papers/rem_sens_im_proc_12_ch02.pdf>Rem.Sens.Im.Proc.11</a>, <a href=http://isp.uv.es/after_effects>Front.Neurosci.15</a>].</p><table style=text-align:left;margin-left:auto;margin-right:auto;width:100% border=0 cellpadding=2 cellspacing=2><tbody><tr><td style=width:47%><img class=img-responsive alt=DoblePaso src=images/images_ex/experiment1.JPG></td><td style=width:26%><img class=img-responsive alt=IllumD src=images/images_ex/method1.JPG></td><td style=text-align:left;width:26%><img class=img-responsive alt=IllumA src=images/images_ex/method2.JPG></td></tr><tr align=justify><td colspan=3 rowspan=1><strong><span style=font-weight:700;color:#00a000>Illustrative experimental equipment:</span></strong>
<small><span style=font-style:italic>Left:</span> double-pass setting for the measurement of the Modulation Transfer Function of the human eye [<a href=http://isp.uv.es/papers/OPH97.PS.gz>Opth.Phys.Opt.97</a>]. <span style=font-style:italic>Right:</span> Spectrally calibrated light sources, image colorimeter and spectroradiometer to gather accurate color image statistics, see the available <a href=http://isp.uv.es/data_color.htm>color image database</a> [<a href=http://isp.uv.es/papers/Neco_accepted_2012.pdf>Neur.Comp.12</a>,
<a href=http://isp.uv.es/papers/Gutmann_PLOS_ONE_2014.pdf>PLoS-ONE14</a>], and <a href=http://isp.uv.es/after_effects/>texture and motion datasets</a> [<a href=http://isp.uv.es/after_effects>Front.Neurosci.15</a>], with samples ready to be processed.</small></td></tr></tbody></table><hr id=empirical><br><p align=justify><h3><span class="label label-warning">Theory: empirical models in Vision Science (8 JCR publications)</span></h3></p><p align=justify>We proposed mathematical descriptions of different visual dimensions: <span style=font-style:italic>Texture</span>, <span style=font-style:italic>Color</span>, and <span style=font-style:italic>Motion</span>. (i) we used wavelet representations to propose nonstationary <strong>Texture Vision</strong> models [<a href=http://isp.uv.es/papers/JMO97.PS.gz>J.Mod.Opt.97</a>, <a href=http://isp.uv.es/papers/msc_jmalo.pdf>MScThesis95</a>], (ii) we developed <strong>Color Vision</strong> models with illumination invariance that allow the reproduction of chromatic anomalies, adaptation and aftereffects [<a href=http://isp.uv.es/papers/VISRES97.PS.gz>Vis.Res.97</a>,
<a href=http://isp.uv.es/papers/JOPT96.PS.gz>J.Opt.96</a>, <a href=http://isp.uv.es/papers/JOPT98.PS.gz>J. Opt.98</a>, <a href=http://isp.uv.es/papers/josa_04.pdf>JOSA04</a>, <a href=http://isp.uv.es/papers/Neco_accepted_2012.pdf>Neur.Comp.12</a></span>], and (iii) <strong>Motion Vision</strong> models [<a href=http://isp.uv.es/papers/Malo_Alheteia_08.pdf>Alheteia08</a>] that focus the optical flow computation in perceptually relevant moving regions [<a href=http://isp.uv.es/papers/vss_poster.eps>J.Vis.01</a>, <a href=http://isp.uv.es/papers/Redundancy_Reduction_Malo_99.pdf>PhDThesis99</a>], and explain the <span style=font-style:italic>static motion aftereffect</span> [</span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><a href=http://isp.uv.es/after_effects>Front.Neurosci.15</a>]. All these psychophysical and physiological models have a parallel <span style=font-style:italic>linear+nonlinear</span> structure where <strong>receptive fields</strong> and <strong>surround-dependent normalization</strong> play an important role.<div class=container style=width:120%;text-align:left;margin-left:-8%;margin-right:auto><div class=row><div class=col-md-6><p align=justify><strong><span style=color:#00a000>Empirical motion model at work:</span></strong>
<small>Waving hands sequence recorded at my lab (just a remake of the original movie from <a href=http://vision.arc.nasa.gov/publications/ModelHumanVisualMotion.pdf>Watson & Ahumada</a>), linear filter model of MT neurons as an aggregate of spatio-temporal wavelet-like filters (bottom left) tuned to certain speed for optical flow computation (example at bottom right for a later frame).
<span style=font-style:italic>Note that our remake improved the original by including a striped costume for Fourier-obsessed freaks!</span></small></p><img class=img-responsive alt src=images/images_ex/motion.JPG></div><div class=col-md-6><img class=img-responsive alt src=images/images_ex/dicromat.jpg><p align=justify><strong><span style=color:#00a000>See how it feels to be color blind!:&nbsp;</span></strong>
<small>We proposed a way to simulate the perception of color blinds (here with Picasso's <a href=https://en.wikipedia.org/wiki/Dora_Maar>Dora Maar</a>). As you see, dichromats are not color blind at all: <span style=font-style:italic>they simply see different colors</span>. Moreover, this simulation can be used to discriminate between color theories just by asking your dichromat friend which image is more similar to him.</small></p></div></div></div><p align=center><small>See additional code for <a href=http://isp.uv.es/soft_visioncolor.htm><span style=font-style:italic>Texture</span>, <span style=font-style:italic>Color</span> and <span style=font-style:italic>Motion</span> perception</small></a></p><hr id=principled><br><p align=justify><h3><span class="label label-warning">Theory: principled models in Vision Science (12 JCR publications)</span></h3></p><p align=justify>This category refers to the proposition of organization laws of sensory systems that explain the empirical phenomena. These principles show that neural function has been adapted to (or is determined by) the statistics of visual stimuli. In this regard, (i) we worked on the <strong>derivation of the linear properties</strong> of the sensors, and we found that their spatio-chromatic sensitivity, the way the receptive fields change, and their phase properties, come from optimal solutions to the adaptation problem under noise constraints and manifold matching [<a href=http://isp.uv.es/papers/Gutmann_PLOS_ONE_2014.pdf>PLoS-ONE14</a>, <a href=http://isp.uv.es/papers/AdaptVQ_ieeetgars_2012.pdf>IEEE-TGRS13</a>], from statistical independence requirements [<a href=http://www.uv.es/vista/vistavalencia/papers/ICANN_2011_v7.pdf>LNCS11</a>, <a href=http://isp.uv.es/papers/SlidesNeuroImageMeeting11.pdf>NeuroImag.Meeting11</a>], and from optimal estimation of object reflectance [<a href=http://isp.uv.es/papers/manuscr_TGRS_2012_00431.pdf>IEEE TGRS14</a>].
(ii) We also worked on the <strong>derivation of the non-linear behavior</strong> for a variety of visual sensors (chromatic, texture, and motion sensors). We found that in all cases the nonlinearities are related to optimal information transmission (entropy maximization) and/or to error minimization in noisy systems (optimal vector quantization).
We studied this relation in the classical <span style=font-style:italic>statistics-to-perception</span> direction (deriving the nonlinearity from the regularities in the scene)
[<a href=http://isp.uv.es/papers/V1_from_non_linear_ICA.pdf>Network06</a>, <a href=http://isp.uv.es/papers/Neco_accepted_2012.pdf>Neur.Comp.12</a>, <a href=http://isp.uv.es/after_effects>Front.Neurosci.15</a>], as well as in the (more novel) <span style=font-style:italic>perception-to-statistics</span> direction, i.e. by looking at the statistical effect of perceptually motivated nonlinearities [<a href=http://isp.uv.es/papers/JOPT95.PS.gz>J.Opt.95</a>, <a href=http://isp.uv.es/papers/ivc99.ps.gz>Im.Vis.Comp.00</a>, <a href=http://isp.uv.es/papers/spr00.ps>LNCS00</a>, <a href=http://isp.uv.es/papers/patt_rec03.pdf>Patt.Recog.03</a>, <a href=http://isp.uv.es/papers/Malo_Laparra_Neural_10b.pdf>Neur.Comp.10</a>, <a href=http://isp.uv.es/papers/LNAI10_malo_laparra.pdf>LNCS10</a>, <a href=http://isp.uv.es/papers/SlidesNeuroImageMeeting11.pdf>NeuroImag.Meeting11</a>].<table style=width:75%;text-align:left;margin-left:auto;margin-right:auto border=0 cellpadding=2 cellspacing=2><tbody><tr align=justify><td colspan=2 rowspan=1><strong><span style=color:#00a000>Illustrative organization principle: </strong><small>Optimal adaptation and information transmission with noise constraints (Higher Order Canonical Correlation) predicts shifts in oscillatory responses of gabor-like opponent spatio-chromatic receptive fields when adapted to visual scenes under different illumination (similarly to V1 neurons). See code <a href=http://isp.uv.es/HOCCA>here</a>.</small></td></tr><tr align=center><td colspan=2 rowspan=1><img class=img-responsive alt=a src=images/images_ex/estimulac.JPG></td></tr><tr><td style=text-align:right><img class=img-responsive alt=a src=images/images_ex/resp1.JPG></td><td style=text-align:justify><img class=img-responsive alt=a src=images/images_ex/resp2.JPG></td></tr></tbody></table><hr id=learning><br><p align=justify><h3><span class="label label-warning">Theory: Statistical Learning (7 JCR publications)</span></h3></p><p align=justify>In theoretical neuroscience the derivation of properties of biological sensors from the regularities visual scenes requires novel tools for statistical learning. In this field, we developed new techniques for <strong>unsupervised manifold learning</strong>, <strong>feature extraction</strong> (or symmetry detection in datasets), <strong>dimensionality reduction</strong>, <strong>probability density estimation</strong>, <strong>multi-information estimation</strong>, <strong>distance learning</strong>, and automatic <strong>adaptation</strong> from optimal dataset matching. Given my interest in applicability in Vision Science problems, I focused on techniques that can be explicitly represented in the image domain to be compared with receptive fields of visual neurons, as opposed to the usual practice in the<span style=font-style:italic> Machine Learning</span> community. Techniques include Rotation-based Iterative Gaussianization -RBIG- [<a href=http://isp.uv.es/papers/Laparra11.pdf>IEEE TNN 11</a>], Sequential Principal Curves Analysis -SPCA- [<a href=http://isp.uv.es/papers/V1_from_non_linear_ICA.pdf>Network06</a>, <a href=http://isp.uv.es/papers/Neco_accepted_2012.pdf>Neur.Comp.12</a>, <a href=http://isp.uv.es/after_effects>Front. Neurosci.15</a>], Principal
Polynomial Analysis -PPA- [<a href=http://isp.uv.es/papers/IJNS_Laparra14_accepted_v5.pdf>Int.J.Neur.Syst.14</a>], Dimensionality Reduction based on Regression -DRR- [<a href=http://isp.uv.es/papers/drr_jstsp2014_final.pdf>IEEE JSTSP15</a>], and Graph Matching for Adaptation [<a href=http://isp.uv.es/papers/AdaptVQ_ieeetgars_2012.pdf>IEEE TGRS13</a>].<p align=justify style=width:90%;margin-left:5%><span style=color:#00a000><strong>Illustrative learning technique:</strong></span><small> data induced metric and identified features using nonlinear feature extraction (in this case, the Principal Polynomial Analysis, PPA). The scatter plot (at the top) shows the training set, the 2nd row shows the features (curves in black) and the discrimination ellipsoids (in yellow) in different representation domains: the original domain (left), the data-unfolded domain after PPA (center), and the whitened PPA domain (right). Principal Polynomial Analysis looks for the intrinsic curvilinear coordinates generalizing the linear directions of PCA (principal polynomials instead of eigen directions). Similarly to Mahalanobis distance when using PCA, the Jacobian of PPA can be used to define data dependent measures. Similarly to what is done in (linear) Independent Component Analysis, the Jacobian of PPA can be used to identify intrinsic features in the input domain.
As opposed to the linear counterparts, metric and features are local.
Different sets of local features (local basis vectors) in the input domain (3rd row) or in the PPA-transformed domain (4th row) can be obtained from the Jacobian or the jacobian-related metric matrix. See available code for this and other feature extraction techniques <a href=http://isp.uv.es/soft_feature.html>here</a>.</small></p><table style=width:110%;text-align:left;margin-left:-5%;margin-right:auto border=0 cellpadding=2 cellspacing=2><tbody><tr align=center><td colspan=2 rowspan=1><img class=img-responsive alt=a src=images/images_ex/data_metric.JPG></td></tr><tr><td style=text-align:right;width:66.6%><img class=img-responsive alt=a src=images/images_ex/features_1.JPG></td><td style=text-align:justify;width:35%><img class=img-responsive alt=a src=images/images_ex/features_2.JPG></td></tr></tbody></table><hr id=applications><br><p align=justify><h3><span class="label label-warning">Applications: Image Processing (24 JCR publications + 1 patent)</span></h3></p><p align=justify>We proposed original image processing techniques using both perception models and image statistics including (i) improvements of JPEG standard for <strong>image coding</strong> through nonlinear texture vision models
[<a href=http://isp.uv.es/papers/ELECT95.PS.gz>Electr.Lett.95</a>, <a href=http://isp.uv.es/papers/ELECT99.PS.gz>Electr.Lett.99</a>, <a href=http://isp.uv.es/papers/Gomez-Perez05_IEEETNN.pdf>IEEE TNN05</a>, <a href=http://www.uv.es/vista/vistavalencia/papers/manuscript4.pdf>IEEE TIP06a</a>, <a href=http://isp.uv.es/papers/Camps-Valls08_JMLR.pdf>JMLR08</a>, <a href=http://isp.uv.es/papers/2012b_Gutierrez_RPTSP_12c.PDF>RPSP12</a>, <a href=http://isp.uv.es/papers/patente_v5_jesus.pdf>Patent08</a>], (ii) improvements of MPEG standard for <strong>video coding</strong> with new perceptual quantization scheme and new motion estimation focused on perceptually relevant <strong>optical flow</strong> [<a href=http://isp.uv.es/papers/LNCS97.PS.gz>LNCS97</a>, <a href=http://isp.uv.es/papers/ELECT98.PS.gz>Electr.Lett.98</a>,
<a href=http://isp.uv.es/papers/elect00.ps>Electr.Lett.00a</a>, <a href=http://isp.uv.es/papers/seg_ade2.ps>Electr.Lett.00b</a>, <a href=http://www.uv.es/vista/vistavalencia/papers/ieeeoct01.pdf>IEEE TIP01</a>, <a href=http://isp.uv.es/papers/Redundancy_Reduction_Malo_99.pdf>Redund.Reduct.99</a>], (iii)
new <strong>image restoration</strong> techniques based on nonlinear contrast perception models and the image statistics in local frequency domains [<a href=http://www.uv.es/vista/vistavalencia/papers/manuscript_TIP_00864_2004_R2.pdf>IEEE TIP 06b</a>, <a href=http://www.jmlr.org/papers/volume11/laparra10a/laparra10a.pdf>JMLR10</a>]; (iv) new approaches to <strong>color constancy</strong> either based on relative chromatic descriptors [<a href=http://isp.uv.es/papers/VISRES97.PS.gz>Vis.Res.97</a>,
<a href=http://isp.uv.es/papers/JOPT96.PS.gz>J.Opt.96</a>], statistically-based chromatic adaptation models [<a href=http://isp.uv.es/papers/Neco_accepted_2012.pdf>Neur.Comp.12</a>,
<a href=http://isp.uv.es/papers/Gutmann_PLOS_ONE_2014.pdf>PLoS-ONE14</a>], or Bayesian estimation of surface reflectance [<a href=http://isp.uv.es/papers/manuscr_TGRS_2012_00431.pdf>IEEE-TGRS14</a>]; (v) new subjective <strong>image and video distortion measures</strong> using nonlinear perception models [<a href=http://isp.uv.es/papers/IVC97.PS.gz>Im.Vis.Comp.97</a>, <a href=http://www.uv.es/vista/vistavalencia/papers/displays_99.pdf>Disp.99</a>, <a href=http://www.uv.es/vista/vistavalencia/papers/icip02.pdf>IEEE ICIP02</a>, <a href=http://www.uv.es/vista/vistavalencia/papers/Laparra_JOSA_10.pdf>JOSA10</a>, <a href=http://isp.uv.es/papers/malo15a-reprint.pdf>Proc.SPIE15</a>]; and (vi) <strong>image classification</strong> and <strong>knowledge extraction</strong> (or regression) based on our feature extraction techniques [<a href=http://isp.uv.es/papers/Laparra11.pdf>IEEE-TNN11</a>, <a href=http://isp.uv.es/papers/AdaptVQ_ieeetgars_2012.pdf>IEEE-TGRS13</a>,<a href=http://isp.uv.es/papers/IJNS_Laparra14_accepted_v5.pdf>Int.J.Neur.Syst.14</a>, <a href=http://isp.uv.es/papers/drr_jstsp2014_final.pdf>IEEE-JSTSP15</a>]. See code for image and video processing applications <a href=http://isp.uv.es/soft_imvideo.html>here</a>.</p><div class=container style=width:140%;text-align:left;margin-left:-22%;margin-right:auto><div class=row><div class=col-md-6><img class=img-responsive alt src=images/images_ex/im_coding.JPG><p align=justify><strong><span style=color:#00a000>Image Coding:</span></strong>
<small>using nonlinear perceptual image representations is critical to improve JPEG (see the gain in visual quality at 1 bit/pix). Measuring subjective
distortion (the numbers at the bottom) is another vision-related problem we addressed (see below).</small></p><br><br><div class=container style=width:115%;text-align:right;margin-left:-10%;margin-right:auto><div class=row><div class=col-md-12 style=width:100%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/ruidos_great.JPG></div></div></div><p align=justify><strong><span style=color:#00a000>Image Restoration:</span></strong>
<small>regularization functionals based on nonlinear perception models and signal smoothing according to image statistics in the wavelet domain help in image
restoration.</small></p><br><br><div class=container style=width:115%;text-align:left;margin-left:-10%;margin-right:auto><div class=row><div class=col-md-12 style=width:100%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/metrics.JPG></div></div></div><p align=justify><strong><span style=color:#00a000>Subjective image/video distortion metrics:</span></strong>
<small>Observer's opinion (ground truth in the vertical axis) is better correlated with our Euclidean distance in nonlinear perceptual domains (right) than with the widely
used Structural Similarity Index (left).</small></p></div><div class=col-md-6><img class=img-responsive alt src=images/images_ex/video_coding.JPG><p align=justify><strong><span style=color:#00a000>Video Coding:&nbsp;</span></strong>
<small>improved bit allocation according to nonlinear perception model (right vs left) is critical to improve MPEG video coding with regard to improved
optical flow computation (bottom vs top).</small></p><div class=container style=width:110%;text-align:left;margin-left:-2%;margin-right:auto><div class=row><div class=col-md-6 style=width:50%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/flor1.JPG></div><div class=col-md-6 style=width:50%;text-align:left;margin-left:-5%;margin-right:auto><img class=img-responsive alt src=images/images_ex/flor2.JPG></div></div></div><p align=justify><strong><span style=color:#00a000>Color Constancy and White Balance:&nbsp;</span></strong>
<small>these <span style=font-style:italic>adaptation</span> problems reduce to manifold matching in different illumination conditions. We proposed linear and nonlinear solutions to this geometric problem.</small></p><div class=container style=width:110%;text-align:left;margin-left:-2%;margin-right:auto><div class=row><div class=col-md-6 style=width:50%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/clasi1.JPG></div><div class=col-md-6 style=width:50%;text-align:left;margin-left:-5%;margin-right:auto><img class=img-responsive alt src=images/images_ex/clasi2.JPG></div></div></div><p align=justify><strong><span style=color:#00a000>Image classification:&nbsp;</span></strong>
<small>Classifiers based on flexible features adapted to the data (such as RBIG, SPCA, PPA, DRR) are robust to changes in acquisition conditions (adaptivity implies no&nbsp;retraining is needed).</small></p></div></div></div><hr id=preliminary><br><p align=justify><h3><span class="label label-warning">Preliminary Conclusions</span></h3></p><p align=justify>I call these <span style=font-style:italic>preliminary</span>
since I plan to keep on working for another 20 years, but I find them
pretty robust. Actually, you may&nbsp;think they are quite obvious and not very original:</p><br><table style=text-align:left;margin-left:auto;margin-right:auto;width:100% border=0 cellpadding=2 cellspacing=2><tbody><tr><td style=text-align:justify><ul><li><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><span style=font-weight:700>The visual brain is astonishingly well adapted to the natural visual world.</span> This sentence shouldnt be surprising for any teenager that heard about <a href=https://en.wikipedia.org/wiki/Charles_Darwin>Charles Darwin</a>. The cool thing in that conclusion was preparing <a href=http://isp.uv.es/data_color.htm>accurate image data</a>, developing the appropriate <a href=http://isp.uv.es/soft_feature.html>mathematical tools</a> to derive the behavior described by <a href=http://isp.uv.es/soft_visioncolor.html>computational models</a> as seen in <a href=http://isp.uv.es/after_effects/>psychophysical illustrations</a>. By putting all this together in a <a href=http://isp.uv.es/code/imvideo/KeCoDe/single_piece.html>single piece of code</a> you realize that the statement is true.</span></li></ul></td><td style=text-align:right;width:109px><img style=width:96px;height:105px alt src=images/images_ex/darwin_square.JPG></td></tr><tr><td style=text-align:justify><ul><li><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><span style=font-weight:700>Appropriate
(mathematical) formulation of&nbsp;visual phenomena is the only way to understand the problem and to derive applications.</span> This statement is not very original either, given the famous <a href=https://en.wikipedia.org/wiki/Galileo_Galilei#Scientific_methods>Galileo Galiei</a>
quote [<span style=font-style:italic>the book of nature is written in mathematical language</span>]. However, in this multidisciplinary world, a special effort
has to be done to translate physiological facts into models that work on, lets say, actual video sequences. By doing so, you transcend the specific
details of a set of experiments, and think about all the additional problems faced (and solved) by the visual brain. Numerical simulations are useful to put a specific physiological behavior in perspective. Moreover, well formulated models allow to explore new experimental questions through the appropriate stimuli.
Not to speak about the straightforward use in image processing and computer vision...</span></li></ul></td><td style=text-align:right;width:109px><img style=width:96px;height:116px alt src=images/images_ex/Galileo_edited.jpg></td></tr><tr><td style=text-align:justify><ul><li><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><span style=font-weight:700>Nonlinear techniques are fancy, but it is amazing the percentage of reality that we can explain with linear models.</span> Another old-fashion statement for <a href=https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#History>eigenvector</a> lovers. Besides, linear algebra is easy!. For instance, a simple
rotation (the Principal Component Analysis of </span><a href=https://en.wikipedia.org/wiki/Karl_Pearson><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>Karl Pearson</span></a><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>) applied to small patches of natural sequences, explains the major features of the receptive fields
of LGN-V1 visual neurons. This includes opponent <span style=font-style:italic>color</span> coding, neurons tuned to <span style=font-style:italic>spatial texture</span>, and <span style=font-style:italic>motion</span> sensitive neurons. Different kinds of simple affine transforms (linear
scaling and translations) explain basic sensitivity to color, texture and motion as well as the basic trends of adaptation. Amazing!</span></li></ul></td><td style=text-align:right;width:109px><img style=width:98px;height:121px alt src=images/images_ex/Pearson2.JPG></td></tr><tr><td style=text-align:justify><ul><li><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><span style=font-weight:700>We roughly understand low level visual information processing in the brain. However, there is still a long way to understand how we derive abstract
concepts from low level primitives.</span> Not a surprising statement either if you saw the appropriate documentary or heard about <a href=http://rstb.royalsocietypublishing.org/content/370/1666/20140383>David Marr</a>. Despite of all the knowledge about&nbsp;<span style=font-style:italic>color</span>, <span style=font-style:italic>spatial texture</span>, <span style=font-style:italic>motion</span> and&nbsp;<span style=font-style:italic>depth</span>
information processing in LGN, V1 and MT. Little is known about how these pieces are put together in other parts of the brain (e.g. IT).&nbsp;What are the organization laws of these higher abstraction mechanisms?. What about their relations to language?. What about&nbsp;our ability to synthesize images (draw) from a written
description?.</span></li></ul></td><td style=text-align:right;width:109px><img style=width:98px;height:116px alt src=images/images_ex/Marr2.JPG></td></tr></tbody></table><p align=justify>An educated teenager that heard about Darwin, Galileo,&nbsp;Pearson, and Marr (<span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif;font-style:italic lang=EN-US>evolution,&nbsp;mathematical modeling,&nbsp;eigenvectors, decorrelation </span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>and</span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif;font-style:italic lang=EN-US>&nbsp;vision</span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>) could be disappointed by the simplicity of these conclusions. However, note that my claims can be louder now than 20 years ago because of the time spent in accumulating evidences (and writing this <a href=http://isp.uv.es/code/imvideo/KeCoDe/single_piece.html>piece of code</a>).
I hope that the next 20 years are fruitful enough to make these conclusions stronger or (even better!) to change some of them.</p></span><hr id=Noise><br><p align=justify><h3><span class="label label-warning">Impact of <span style=font-style:italic>Colored Noise</span> in science libraries</span></h3></p><p align=justify>As I told Eero Simoncelli once, while few people make a big impact on the scientific community, what others (including myself) do can be seen as injecting colored noise in the science libraries and the internet. Nevertheless, as argued below, that is not a major problem, but even something worth funding.</p><p align=justify><h3><span class="label label-warning">Some thoughts on <a href=https://en.wikipedia.org/wiki/Journal_Citation_Reports>JCR publications</a> and the <a href=https://en.wikipedia.org/wiki/H-index>h-index</a></span></h3></p><p align=justify>For ordinary (not-Nobel-laureate) people, research is mainly a personal learning experience. Such process starts with some <span style=font-style:italic>childish initial curiosity</span> and ends with <span style=font-style:italic>refereed publication</span>. It involves putting the question in context, saying something coherent
about it, and convincing critical reviewers about the accuracy of such statement (no matter it is ground-breaking or not). Given the quality control imposed by peer review (particularly in high impact journals) the <span style=font-style:italic>publishing-in-fine-journals</span> exercise is one of the most comprehensive learning procedures ever developed. Even though the publications of the average scientist remain unknown or never make a <span style=font-style:italic>global</span> difference (i.e. low h-index), the rigor of the learning process in JCR-journals ensures this person has the deepest understanding of the issues. And this has a <span style=font-style:italic>local</span> impact in the dissemination of knowledge to others, either (local) students or (local) industries. A cohort of average scientists well trained through
the publication process&nbsp;have to be there, ready to understand, confirm, disseminate and apply what (the few) original scientist happen to discover. In my view, that is the justification of devoting public money to fund average scientific research (or random colored noise generation ;-). Note that <span style=color:#00a000;font-weight:700>samples from colored noise do not distribute as a sphere, but <span style=font-style:italic>collectively</span> they point to a certain direction, hopefully the right one!.</span></p><p align=justify>For those of you who do not share this personal learning view, and love rankings better, here is the impact of my research (by july 2015, i.e. automatically outdated) according to my <a href="https://scholar.google.es/citations?user=0pgrklEAAAAJ&amp;hl=es&amp;oi=ao"><span style=font-style:italic>Google Scholar&nbsp;profile</span></a>, my <span style=font-style:italic>Hirsch index</span> was 19, the total number of citations to my work was 876, so I was the 3rd most-cited scientist in the world in the (<span style=font-style:italic>Google Scholar ;-</span>) category of<span style=font-style:italic> <a href="https://scholar.google.es/citations?view_op=search_authors&amp;hl=es&amp;mauthors=label:image_statistics">Image Statistics</a></span>, the 28-th one in <a href="https://scholar.google.es/citations?view_op=search_authors&amp;hl=es&amp;mauthors=label:human_vision"><span style=font-style:italic>Human Vision</span></a>, the 87-th in <a href="https://scholar.google.es/citations?view_op=search_authors&amp;hl=es&amp;mauthors=label:visual_perception"><span style=font-style:italic>Visual Perception</span></a>, and the 263-th in <a href="https://scholar.google.es/citations?view_op=search_authors&amp;hl=es&amp;mauthors=label:vision"><span style=font-style:italic>Vision</span></a>. </span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>So what?</span></p><p align=justify>To me, the undeniable peak of my scientific career happened when a mild morning of february&nbsp;<span style=font-style:italic>2001</span>, I left my office at the <span style=font-style:italic>NASA Ames Research Center</span> and drove my Toyota through the rocket wind tunnels to attend a talk at a nearby town in Sillicon Valley on the vision abilities of <a href=https://en.wikipedia.org/wiki/HAL_9000>HAL-9000</a>, the famous computer of Stanley Kubrick's <span style=font-style:italic>2001 A Space Odyssey</span></span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>.&nbsp;</span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>The combination of NASA, 2001, and&nbsp;HAL-9000 together really <span style=font-style:italic></span>felt like <span style=font-style:italic>big science</span>. Particularly compared to my spanish postdoc salary and housing prices of the <a href=https://en.wikipedia.org/wiki/Dot-com_bubble>dot-com bubble</a>. Since that glorious morning I felt like <a href=https://en.wikipedia.org/wiki/Space_Odyssey#Characters>Dr. Dave Bowman</a> for a second, everything else has been a steady decline.<span style=font-style:italic></span></span><table style=width:100%;text-align:left;margin-left:auto;margin-right:auto border=0 cellpadding=2 cellspacing=2><tbody><tr><td><img class=img-responsive alt=m src=images/images_ex/NASA.JPG></td></tr><tr align=justify><td><strong><span style=color:#00a000>HAL at SPIE Human Vision and Electronic Imaging 2001: </strong></span><small>Dr. <a href=http://web.media.mit.edu/%7Epicard/index.php>Rosalind Picard</a> actually hold the HAL-9000 eye in front of us in her <a href=http://vismod.media.mit.edu/tech-reports/TR-532.pdf>invited talk</a> at the conference (eye at the bottom right). She temporarily got it under&nbsp;Metro Goldwyn Mayer permission. Unfortunately Dr. Bowman (top right) was not attending the conference. Nevertheless, LittleHAL (my machine at NASA, bottom-left) showed no <span style=font-style:italic>"Computer Malfunction"</span> message while I attended the talk. However, not all my current students get the HAL-9000 story... more on this communication challenge in the <span style=font-style:italic>teaching section</span> below.</small></td></tr></tbody></table><br><p align=justify><strong><span style=color:#00a000>Bayesian events by 2001:</strong></span> <small>the scientific achievement preferred by my students is the fact that, being a theoretician, Bayes theory didn't stopped me from doing some experimental measures (pictures). I was at Time Cafe enjoying this preprint <a href=http://www.psych.nyu.edu/maloney/>Larry Maloney</a> had told me about some days before. Nevertheless, people was grouping at the other side of Lafayette str. <span style=font-style:italic>looking at something</span>. I came back to the office to get my camera. It was NYU, september the 11th 2001, about 9:30 AM. <a href=http://www.uv.es/jmalo/personal/las_torres/las_torres.html>See the measurements here</a>.</small></p><div class=container style=width:108%;text-align:center;margin-left:-4%;margin-right:auto><div class=row><div class=col-md-12 style=width:100%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/sept_11_NY.JPG></div></div></div></div><div class=col-md-2></div></div><hr id=Teaching><br><div class=row><div class=col-md-10><p><h2><span class="label label-success">4. My teaching activities: <span style=font-style:italic>like Richard Dawkins in a Republican Convention</span></span></h2></p></div><div class=col-md-2><br><h4><span class="label label-link"><a href=#Top>Back to top</a></span></h4></div></div><div class=row><div class=col-md-2></div><div class=col-md-8><br><p style=color:#00a000><big><big><strong>Why an optometrist (or engineer) would ever care about Maths (or Science)?</strong></big></big></p><p align=justify>My teaching activity at the university spans over 19 years (only one less than my research activity). This means that I had to teach while
obtaining my PhD. This undesirable situation happened since at that time (mid 90s) getting a PhD grant was restricted to students of professors having public funds (which was not the case of my advisor). Therefore, I stayed at the university only because (i) I won the European Vistakon Research Award (which I used to pay my PhD research
for one year), and (ii) a new degree on Optometry and Vision Science was established at my university and it generated several openings for junior assistant professors.<br><br>The quality of my teaching over these two decades has been rated by my students according to the regulations in my university (in a scale of 5) as 3.6 &plusmn 0.3, i.e. they gave me a positive rating with a small variance over the years.<br><br>My teaching activity has been modulated by (1) my interest in Vision Science, and (2) by having most of my docent duties associated to the Degree and Master on Optometry and Vision Science. The correspondence between these two factors has been positive since it gave coherence to the research and teaching activities. However, the problem with Optometry students is that they imagine themselves as<span style=font-style:italic> Medical Doctors</span> (and you know that <a href=http://www.cebm.net/>Evidence-Based Medicine is a recent field!</a>). As a result, these students are not quite prepared for the practice of quantitative
science (is there any non-quantitative science anyway?). This problem represented, (i) a challenge to convey the quantitative message to students with non-quantitative interests, and (ii) an incentive to diversify my teaching activity looking for students not scared by scalar products. The challenge posed by the non-quantitative students
lead to the development of Matlab tools such as <a href=http://isp.uv.es/code/visioncolor/colorlab.html>COLORLAB</a>, <a href=http://isp.uv.es/code/visioncolor/Basic_Video.html>BasicVideoTools</a>, and <a href=http://isp.uv.es/code/visioncolor/virtual_labs.html>VirtualNeuroLabs</a>, and new docent methodologies [<a href=http://isp.uv.es/papers/proyecto_docente_ch3_2002.pdf>ProyDocente02</a>] to convey the <span style=font-style:italic>quantitative credo</span> to students afraid of Maths. In this quantitative effort I found a lot of help and support from <a href=https://www.researchgate.net/profile/Maria_Jose_Luque>M.J. Luque</a> and <a href=http://www.uv.es/capilla/>P. Capilla</a> (respectively ;-) Sometimes I really feel as hopeless as <a href=https://en.wikipedia.org/wiki/Richard_Dawkins><span style=font-style:italic>Richard Dawkins</span></a> at a Republican convention. But having a lot of fun, though!. On second thoughts, my Optometry undergrads are not that bad: deficient education is always a problem of the teachers, not the students. Please excuse the trivial comparison with the <a href=https://en.wikipedia.org/wiki/Creationism#Scientific_criticism>creationists</a>!.</p></span></td></tr></tbody></table><div class=container style=width:130%;text-align:center;margin-left:-15%;margin-right:auto><div class=row><div class=col-md-12 style=width:100%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/alumnii.JPG></div></div></div><p style=text-align:justify><strong><span style=color:#00a000>Pictures taken by the students of Color Science: </span></strong><a href=images/images_ex/edit_rakel.m>one of the exercises</a> in those lectures consisted of representing the color of their pictures in CIE XYZ and editing the hue, chroma and lightness in CIE Lab or alternative color appearance models using <a href=http://isp.uv.es/code/visioncolor/colorlab.html>COLORLAB</a>.<br></small><div class=container style=width:130%;text-align:center;margin-left:-15%;margin-right:auto><div class=row><div class=col-md-12 style=width:100%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/rakel.JPG><br></div></div></div><p style=text-align:justify>In order to diversify the audience, I also lectured in PhD and Master programs with Excellence distinction out of my Optics department, as
for instance at the Applied Maths and Computer Science departments of my university, at the Institute of Applied Ophtalmo-Biology (Univ. Valladolid), and at the Institut de Rob&ogravetica i Inform&agravetica Industrial (UPC). You can find slides, lecture notes and computer&nbsp;<a href=http://isp.uv.es/courses.html>material for PhD courses here</a>.</span><br><br>Finally, I have to mention my best (or more patient) students: those who dared to be advised by me in their PhD years: <strong>Irene Epifanio</strong>, <strong>Juan Guti&eacuterrez</strong>, and <strong>Valero Laparra</strong>. They got doctorate degrees with a number of JCR publications, best PhD and Master Thesis awards in PhD programs with European Excellence distinction, <span style=font-style:italic>etc</span>... Nevertheless, the best is what I learned from them: <span style=font-weight:700;font-style:italic;color:#ff0a00>thank you all, it was a lot of fun!.</p><div class=container style=width:120%;text-align:center;margin-left:-17%;margin-right:auto><div class=row><div class=col-md-12 style=width:100%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/doctores.JPG><br></div></div></div><p style=text-align:justify><strong><span style=color:#00a000>PhD students and colleagues: </span></strong><span style=font-style:italic;font-weight:700>Dr. Irene Epifanio </span>(top left) walking the red carpet to receive the best-thesis award in Physics and Maths 2003 from the President of the Generaliat Valenciana
[<a href=http://isp.uv.es/papers/tesis_irene.pdf>IrenePhD03</a>] (co-advised by <a href=http://www.uv.es/ayala/>Guillermo Ayala</a>).
<span style=font-weight:700;font-style:italic>Dr. Juan Guti&eacuterrez</span> (right) at the black board explaining <span style=font-style:italic>image statistics</span> (top) and Bayesian inference in image wavelet domains (bottom). Note the "tru&ntildeo matem&eacutetico" ommited in the derivationFinally, I have to mention my best (or more patient) students: those who dared to be advised by me in their PhD years: <strong>Irene Epifanio</strong>, <strong>Juan Guti&eacuterrez</strong>, and <strong>Valero Laparra</strong>. They got doctorate degrees with a number of JCR publications, best PhD and Master Thesis awards in PhD programs with European Excellence distinction, <span style=font-style:italic>etc</span>... Nevertheless, the best is what I learned from them: <span style=font-weight:700;font-style:italic;color:#ff0a00>thank you all, it was a lot of fun!.</p><div class=container style=width:120%;text-align:center;margin-left:-17%;margin-right:auto><div class=row><div class=col-md-12 style=width:100%;text-align:right;margin-left:0%;margin-right:auto><img class=img-responsive alt src=images/images_ex/doctores.JPG><br></div></div></div><p style=text-align:justify><strong><span style=color:#00a000>PhD students and colleagues: </span></strong><span style=font-style:italic;font-weight:700>Dr. Irene Epifanio </span>(top left) walking the red carpet to receive the best-thesis award in Physics and Maths 2003 from the President of the Generaliat Valenciana [<a href=http://isp.uv.es/papers/tesis_irene.pdf>IrenePhD03</a>] (co-advised by <a href=http://www.uv.es/ayala/>Guillermo Ayala</a>).<span style=font-weight:700;font-style:italic>Dr. Juan Guti&eacuterrez</span> (right) at the black board explaining <span style=font-style:italic>image statistics</span> (top) and Bayesian inference in image wavelet domains (bottom). Note the "tru&ntildeo matem&eacutetico" ommited in the derivation [<a href=http://isp.uv.es/papers/Tesis_JuanGutierrez.zip>JuanPhD05</a>] (co-advised by <a href=http://www.uv.es/ferri/>Paco Ferri</a>). <span style=font-weight:700;font-style:italic>Dr. Valero Laparra</span>&nbsp;and I (bottom left) at the Keops pyramid having a nonlinear feature extraction ecstasy after our visit to the smoking room at the <span style=font-style:italic>Max Plank Biological Cybernetics Institute</span> invited by <a href=http://bethgelab.org/>M. Bethge</a> (middle left) [<a href=http://isp.uv.es/papers/Thesis_Valero_Laparra.pdf>ValeroPhD11</a>] (co-advised by <a href=http://www.uv.es/gcamps/>Gustau Camps</a>).</p></div><div class=col-md-2></div></div><hr id=Constraints><br><div class=row><div class=col-md-10><p><h2><span class="label label-success">5. Economic constraints of science in Spain:</span></h2></p><br><br><p style=color:#00a000;margin-left:9%><big><big><strong>Why a positive evaluation for professorship does not imply an actual position in Spain?</strong></big></big></p></div><div class=col-md-2><br><h4><span class="label label-link"><a href=#Top>Back to top</a></span></h4></div></div><div class=row><div class=col-md-2></div><div class=col-md-8><div class=container style=width:140%;text-align:left;margin-left:-16%;margin-right:auto><div class=row><div class=col-md-7><p style=text-align:justify>Saying that <span style=font-style:italic>"I did it my way despite the economic constraints"</span> was an obvious literary license (for the evaluation committee). The truth is that my generation has been extremely lucky since Spain experienced an unprecedented window of opportunities for young
scientists in the late 90s and early 2000s. In this <span style=font-style:italic>short</span> time window the economic effort started in the 80s (after we got
democracy) to build a European-like science system, led to a mature public research system in the 90s (private sector didn't go that fast). Favorable economic environment in the 90s and European funds steadily fueled this system and average scientific production in Spain achieved world-class level for the first time in history. In
this&nbsp;situation it is easier to <span style=font-style:italic>do it your way</span>. It is fair to acknowledge that scientific freedom is a by product of favorable conditions.<br><br>May be <span style=font-style:italic>Marx wasn't that wrong after all</span>. Particularly considering how the situation has changed since the 2008
crisis. <span style=font-weight:700>Sadly, the favorable time window may be closing in Spain (and in other places in southern Europe).</span></span>
<span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>Conservative governments in Spain </span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>do not see basic reseach as an investment for the future, but&nbsp;</span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US></span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>as <a href=http://www.nature.com/news/spain-cuts-science-ministry-in-government-changeover-1.9725>a luxury you can disregard (Nature, dec. 2011)</a>.<br><br>This short-sighted policy affects both to young and senior scientists. Massive budget cuts reduce the possibility to get PhD students, and those who finally complete their PhD have small chances here. Postdocs are scarce and, for some years now, new&nbsp;associate professor positions are extremely rare.&nbsp;In the same vein, no new full professor position has been created&nbsp;since&nbsp;2011, and retirement-related positions are only covered at a 50% rate</span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>.</span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US> Before the crisis, the official <span style=font-style:italic>Accreditation for University Professor</span> </span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>(<a href=http://www.aneca.es/Programas/ACADEMIA>after a thorough independent review</a>) used to be equivalent to getting an <span style=font-style:italic>actual Professorship</span> since there were no major funding problems. Now those days are over. The careers of accredited scholars (otherwise professors) are indefinitely truncated.</span>&nbsp;<br><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US></span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><br>An association of <span style=font-style:italic>Accredited University Professors</span> (<a href=http://acreditadosacatedra.blogspot.com.es/>website in Spanish</a>) was created to&nbsp;demand solutions for this unfair&nbsp;blocked-career situation (see <a href=http://isp.uv.es/The_Manifest.pdf>the manifest in English</a>). Major worker unions <a href=http://www.fe.ccoo.es/ensenanza/Inicio:891082--CCOO_pide_desatascar_el_conflicto_que_paraliza_la_carrera_del_profesorado_universitario>CCOO</a> and <a href=http://www.ugt.upv.es/2015/07/13/carta-de-apoyo-a-la-coordinadora-nacional-de-profesores-titulares/>UGT</a> support our demands. As in&nbsp;scientific research (see </span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><a href=http://isp.uv.es/jesus_long_bio/ex_cathedra.html#Noise>the colored noise concept</a></span><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US>) it is the collective action&nbsp;what defines the direction to go. <a href="https://docs.google.com/forms/d/1CAI0r2Yx872ApZRWLzvcPyVA_gpnYBl9H2nlupGSAq4/viewform?c=0&amp;w=1">Please sign up!</a><br></span></p></div><div class=col-md-5><div style=text-align:justify;width:82%;margin-left:0%><strong><span style=color:#00a000>Spaniards at Cambridge: </span></strong><small><a href=http://www.zoo.cam.ac.uk/directory/francisco-hernandez-heras>Francisco J. Hernandez</a> physicist at the Zoology Dept. of Cambridge Univ. (right) telling us (Gustau Camps, center, and Jes&uacutes Malo, left) about his ideas to <a href=http://blogs.nature.com/news/2012/01/spanish-researchers-petition-for-taxpayer-donations.html>improve science funding in Spain (Nature, jan. 2012)</a>, as we entered the Trinity College (picture taken by Valero Laparra).</small><br><span style=font-size:11pt;line-height:115%;font-family:arial,sans-serif lang=EN-US><br><img class=img-responsive alt src=images/images_ex/scientist_at_cambridge.JPG><br><br></div></div></div></div><div class=col-md-2></div></div></div><script src=js/jquery-1.12.4.min.js></script><script src=js/bootstrap.min.js></script></div></main></body><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script></html>