<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<title>RBIG4IT</title>
<meta content="OpenOffice.org 3.2  (Win32)" name="GENERATOR"/>
<meta content="0;0" name="CREATED"/>
<meta content="20100401;9554100" name="CHANGED"/>
<meta content="FrontPage.Editor.Document" name="ProgId"/>
<meta content="es" http-equiv="Content-Language"/>
<style>
      		.texto {
        	font-family: Arial;
      		}
    	</style>
</head>
<body class="texto" dir="LTR" lang="es-ES" style='font-family="Arial"'>
<table border="0" cellpadding="2" cellspacing="0" style="margin: 0px auto; background-color:#FFFFFF;" width="1180">
<colgroup><col width="94"/>
<col width="1079"/>
</colgroup><tbody><tr>
<td bgcolor="#ccccff" class="texto" colspan="2" width="1176">
<p><font size="6"><b>RBIG4IT</b></font></p>
</td>
</tr>
<tr>
<td width="94">
<p><font size="3"><b>Paper</b></font></p>
</td>
<td width="1079">
<p><font size="2"><i>"<meta content="es" http-equiv="Content-Language"/></i></font><font size="3"><i><b>Information Theory Measures via Multidimensional Gaussianization</b></i></font><font size="2"><i>"</i></font><font size="2"><b><br/></b></font><font size="2"><i>
			Valero Laparra, Emmanuel Johnson, Gustau Camps-Valls, Raul Santos-Rodr�guez, Jes�s Malo
</i></font><font size="2"><br/>
2020</font>
<font size="2"><br/>
ArXiv <a href="https://arxiv.org/abs/2010.03807">https://arxiv.org/abs/2010.03807 </a></font>
</p>
</td>
</tr>
<tr>
<td bgcolor="#ccccff" colspan="2" width="1176">
<p><br/>
</p>
</td>
</tr>
<tr>
<td width="94">
<p><font size="3"><b>Abstract</b></font></p>
</td>
<td width="1079">
<p align="JUSTIFY"><font size="2">Information theory is an outstanding framework to measure uncertainty, dependence and relevance in data and systems. It
has several desirable properties for real world applications: it naturally deals with multivariate data, it can handle heterogeneous data
types, and the measures can be interpreted in physical units. However, it has not been adopted by a wider audience because obtaining
information from multidimensional data is a challenging problem due to the curse of dimensionality. Here we propose an indirect way of
computing information based on a multivariate Gaussianization transform. Our proposal mitigates the difficulty of multivariate density
estimation by reducing it to a composition of tractable (marginal) operations and simple linear transformations, which can be interpreted
as a particular deep neural network. We introduce specific Gaussianization-based methodologies to estimate total correlation, entropy,
mutual information and Kullback-Leibler divergence. We compare them to recent estimators showing the accuracy on synthetic data
generated from different multivariate distributions. We made the tools and datasets publicly available to provide a test-bed to analyze
future methodologies. Results show that our proposal is superior to previous estimators particularly in high-dimensional scenarios; and
that it leads to interesting insights in neuroscience, geoscience, computer vision, and machine learning. </font></p>
</td>
</tr>
<tr>
<td bgcolor="#ccccff" colspan="2" width="1176">
<p><br/>
</p>
</td>
</tr>
<tr>
<td width="94">
<p><font size="3"><b>Software</b></font></p>
</td>
<td width="1079">
<p align="LEFT"><span style="text-decoration: none"><font size="2"><b>
<b><a href="https://github.com/IPL-UV/rbig"><img alt="colab" src="/images/adicionales/github.gif" style="width: 20px; height: 20px;"/> <img alt="colab" src="/images/adicionales/favicon.webp" style="width: 20px; height: 20px;"/>  RBIG Python toolbox</a></b></b></font></span><font size="2"><b><br/>
			Includes tools to compute Information Theory measures used in the current paper [RBIG4IT2020] <br/> <br/>
<b><a href="https://colab.research.google.com/github/IPL-UV/rbig/blob/master/notebooks/information_theory_colab.ipynb"><img alt="colab" src="/images/adicionales/colab_favicon_256px.webp" style="width: 20px; height: 20px;"/> Demo in Google Colab</a></b><br/>
<br/><br/><br/>
<b><a href="https://github.com/IPL-UV/rbig_matlab"><img alt="colab" src="/images/adicionales/github.gif" style="width: 20px; height: 20px;"/><img alt="colab" src="/images/adicionales/matlab-4px.webp" style="width: 20px; height: 20px;"/> RBIG Matlab toolbox </a></b><br/> 
			Includes tools to compute Information Theory measures and scripts to generate the synthetic data for the experiments in the current paper [RBIG4IT2020]<br/> <br/>
</b></font></p></td>
</tr>
<tr>
<td bgcolor="#ccccff" colspan="2" width="1176">
<p><br/>
</p>
</td>
</tr>
<tr>
<td width="94">
<p><font size="2"><b>Paper Summary</b></font></p>
</td>
<td width="1079">
<ul>
<li><p style="margin-bottom: 0cm"><font size="2">The measures that can be computed using RBIG defined in this paper are the ones in the following figure + the Kulback-Leibler divergence. The main point is that RBIG allows to get acurated estimations of these measures even in multidimensional datasets. <br/>
<br/>
<img alt="matlab" src="/images/adicionales/fig_1.webp" style="width: 400px;"/>
</font></p><font size="2">
</font></li></ul><font size="2">
</font></td>
</tr>
<tr>
<td bgcolor="#ccccff" colspan="2" width="1176">
<p><br/>
</p>
</td>
</tr>
<tr>
<td width="94">
<p><font size="2"><b>Extended results</b></font></p>
</td>
<td width="1079">
		Here extra results for the paper are shown. Mainly figures for results on synthetic data that would taken too much space in the original paper.
	</td></tr>
<tr>
<td width="94">
<p><font size="2"><b>Total Correlation</b></font></p>
</td>
<td width="1079">
<ul>
<li><p style="margin-bottom: 0cm"><font size="2"><b>Results for Total Correlation. </b><br/>
<br/>
<img alt="matlab" src="/images/adicionales/Table_T.webp" style="width: 400px;"/>
<br/> <br/>
		FIGURE: Total correlation estimation results in relative mean absolute error. Results for different distributions are given: Gaussian, uniform
and the Student PDFs ( μ = 3, 5, 20 for each row respectively). Each column correspond to an experiment of a particular number of
dimensions D . Mean and standard deviation are given for five trials.
<br/>
<img alt="matlab" src="/images/adicionales/Figure_T.webp" style="width: 800px;"/>
</font></p><font size="2">
</font></li></ul><font size="2">
</font></td></tr>
<tr>
<td width="94">
<p><font size="2"><b>Entropy</b></font></p>
</td>
<td width="1079">
<ul>
<li><p style="margin-bottom: 0cm"><font size="2"><b>Results for Entropy.</b> <br/>
<br/>
<img alt="matlab" src="/images/adicionales/Table_H.webp" style="width: 400px;"/>
<br/>
<img alt="matlab" src="/images/adicionales/Figure_H.webp" style="width: 800px;"/>
</font></p><font size="2">
</font></li></ul><font size="2">
</font></td>
</tr>
<tr>
<td width="94">
<p><font size="2"><b>KLD</b></font></p>
</td>
<td width="1079">
<ul>
<li><p style="margin-bottom: 0cm"><font size="2"><b>Results for KLD. </b><br/>
<br/>
<img alt="matlab" src="/images/adicionales/Table_KL.webp" style="width: 400px;"/>
<br/>
<img alt="matlab" src="/images/adicionales/Figure_KL1.webp" style="width: 800px;"/>
</font></p><font size="2">
</font></li></ul><font size="2">
</font></td>
</tr>
<tr>
<td width="94">
<p><font size="2"><b>mutual information</b></font></p>
</td>
<td width="1079">
<ul>
<li><p style="margin-bottom: 0cm"><font size="2"><b>Results for mutual information. </b><br/>
<br/>
<img alt="matlab" src="/images/adicionales/Table_I.webp" style="width: 400px;"/>
<br/>
<img alt="matlab" src="/images/adicionales/Figure_MI.webp" style="width: 800px;"/>
</font></p><font size="2">
</font></li></ul><font size="2">
</font></td>
</tr>
<tr>
<td bgcolor="#ccccff" colspan="2" width="1176">
<p><br/>
</p>
</td>
</tr>
<tr>
<td width="94">
<p><font size="2"><b>References</b></font></p>
</td>
<td width="1079">
<p><font size="2">
<b>[RBIG4IT2020]</b>: "Information Theory Measures via Multidimensional Gaussianization". V. Laparra, E. Johnson, G. Camps-Valls, R. Santos-Rodriguez, J. Malo.<br/>
<b>[TNN2011]</b>: "Iterative Gaussianization: from ICA to Random Rotations". V. Laparra, G. Camps &amp; J. Malo. IEEE Transactions on Neural Networks. <br/>
</font></p>
</td>
</tr>
<tr>
<td bgcolor="#ccccff" colspan="2" width="1176">
<p><br/>
</p>
</td>
</tr>
<tr>
<td width="94">
<p><font size="2"><b>Copyright &amp; Disclaimer</b></font></p>
</td>
<td width="1079">
<p align="JUSTIFY"><font size="2">The programs are granted free of
			charge for research and education purposes only. Scientific
			results produced using the software provided shall acknowledge the
			use of the RBIG implementation provided by us. If you plan to use
			it for non-scientific purposes, don't hesitate to contact
			us.<br/><br/>Because the programs are licensed free of charge, there
			is no warranty for the program, to the extent permitted by
			applicable law. except when otherwise stated in writing the
			copyright holders and/or other parties provide the program "as
			is" without warranty of any kind, either expressed or
			implied, including, but not limited to, the implied warranties of
			merchantability and fitness for a particular purpose. the entire
			risk as to the quality and performance of the program is with you.
			should the program prove defective, you assume the cost of all
			necessary servicing, repair or correction.<br/><br/>In no event
			unless required by applicable law or agreed to in writing will any
			copyright holder, or any other party who may modify and/or
			redistribute the program, be liable to you for damages, including
			any general, special, incidental or consequential damages arising
			out of the use or inability to use the program (including but not
			limited to loss of data or data being rendered inaccurate or
			losses sustained by you or third parties or a failure of the
			program to operate with any other programs), even if such holder
			or other party has been advised of the possibility of such
			damages. </font>
</p>
</td>
</tr>
</tbody></table>
<p><br/><br/>
</p>
</body></html>