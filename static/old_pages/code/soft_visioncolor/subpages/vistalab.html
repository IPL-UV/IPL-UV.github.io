<!DOCTYPE html>

<!-- saved from url=(0048)./vistalab.html -->
<html lang="en"><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
<meta content="" name="description"/>
<meta content="" name="author"/>
<link href="/images/adicionales/favicon.ico" rel="icon"/>
<title>ISP - Software: VistaLab</title>
<!-- Bootstrap core CSS -->
<link href="./vistalab_files/bootstrap.min.css" rel="stylesheet"/>
<!-- Bootstrap theme -->
<link href="./vistalab_files/bootstrap-theme.min.css" rel="stylesheet"/>
<!-- Custom styles for this template -->
<!-- <link href="theme.css" rel="stylesheet"> -->
<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
<!-- Local styles -->
<link href="./vistalab_files/styles.css" rel="stylesheet"/>
</head>
<body role="document" style="padding-top: 50px;">
<div class="row" id="Top">
<hr/>
</div>
<div class="container">
<div class="row"> <!------------------------------ TITLE --------------------------------------->
<div class="col-md-2">
</div>
<div class="col-md-6">
<p><left></left></p><h1><span class="label label-info">VistaLab: </span></h1><p></p>
<p><left></left></p><h2><span class="label label-info"><span style="font-style: italic;">The Matlab toolbox for linear spatio-temporal Vision Models</span></span></h2><p></p><br/>
<p align="center" style="color:rgb(0,150,200)"><big><strong><span style="font-style: italic;">Jesús Malo  &amp;  Juan Gutiérrez</span></strong><br/>
                        jesus.malo@uv.es<br/>
<!---------------  <a href="paper/Plos_Orient_maps_iteration2.pdf"> </a> ------------------->
                        (c) Universitat de València 1996 - 2018</big><br/><br/>
</p></div>
<div class="col-md-3">
</div>
</div>
<div class="row"> <!--------------------------------------- PICTURE - ABSTRACT - INDEX --------------------------------------------->
<div class="col-md-2">
<div class="container" style="width: 145%;text-align: left; margin-top: -20%; margin-left: -40%; margin-right: auto;">
<!-------------
              <img alt="Jesus" class="img-responsive" src="sequence_noise.gif">
              ---------------->
<img alt="Jesus" class="img-responsive" src="./vistalab_files/noise.gif"/>
<p align="justify"><small>Accurate control of texture and speed was crucial both to (a) test our first perceptually weighted optical flow
              algorithms [<a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/seg_ade2.ps">Electr. Lett. 00</a>, <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/ieeeoct01.pdf">IEEE Trans.Im.Proc. 01</a>],
              and (b) generate stimuli for controlled motion aftereffects [<a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/LaparraMalo15.pdf"> Front. Human Neurosci. 15</a>].</small></p><br/><br/><br/><br/><br/>
</div>
</div>
<div class="col-md-6">
<p align="justify"> <strong>VistaLab</strong> is a Matlab toolbox that provides the linear building-blocks to create spatio-temporal vision models and the tools to control the spatio-temporal properties of video sequences. These building-blocks include the spatio-temporal receptive fields of LGN, V1 and MT cells, and the spatial and spatio-temporal Contrast Sensitivity Functions. Additionally, <strong>VistaLab</strong> allows accurate spatio-temporal sampling, spatio-temporal Fourier domain visualization, and generation of video sequences of controlled texture and speed. Sequence generation includes noise and random dots sequences (with controlled spectrum and optical flow), and tools to synthesize animations of rigid bodies of Lambertian reflectance evolving in newtonian force fields. These sequences have controlled 3D motion and known 2D optical flow.<br/>

            The perception tools and video synthesis tools in <strong>VistaLab</strong> enable accurate illustrations of the visibility of achromatic spatio-temporal patterns given the control of the energy, the frequency content (texture and speed), and the context in which they are seen. Rough approximations of the visibility can be computed from the linear filters included in <strong>VistaLab</strong>.<br/>

            The standard tools in <strong>VistaLab</strong> (and in <a href="./colorlab.html"><strong>ColorLab</strong></a>) are the necessary building blocks to develop more sophisticated vision models included in the dedicated site <a href="./vistamodels.html"><strong>VistaModels</strong></a>.</p><br/>
<!---------------------- NO INCLUIDO EN VistaLab
            <p align="justify">These linear building blocks have to be combined with appropriate adaptation nonlinearities, but these (more complicated) nonlinear blocks are addressed in a separate toolbox,
             <a href="./colorlab.html"> <strong>VistaModels</strong></a> <br>
            Luminance calibration is not included in <strong>VistaLab</strong>. Nevertheless, once the sequence is computed, color calibration is easily achievable using the companion
            software <a href="./colorlab.html"> <strong>COLORLAB</strong></a>
            </p><br>
            --------------------->
<div class="col-md-12" style="width: 100%;text-align: left; margin-left: -2%; margin-right: auto;">
<div class="list-group">
<a class="list-group-item" href="./vistalab.html#download">
<h4 class="list-group-item-heading" style="color:rgb(255,50,50)"><strong>Download Code!</strong></h4>
</a>
<a class="list-group-item" href="./vistalab.html#LGN">
<h4 class="list-group-item-heading" style="color:rgb(0,150,200)"><strong>Some VistaLab capabilities:</strong><br/><br/>
                       * Retina and Lateral Geniculate Nucleus (LGN)</h4>
<ul>
<li>Spatio-temporal receptive fields &amp; bandpass</li>
<li>Neural responses to movies</li>
</ul>
</a>
<a class="list-group-item" href="./vistalab.html#V1">
<h4 class="list-group-item-heading" style="color:rgb(0,150,200)">* Primary Visual Cortex (V1)</h4>
<ul>
<li>Spatio-temporal receptive fields &amp; bandpass</li>
<li>Neural responses to movies</li>
</ul>
</a>
<a class="list-group-item" href="./vistalab.html#MT">
<h4 class="list-group-item-heading" style="color:rgb(0,150,200)">* Middle-Temporal (MT) region</h4>
<ul>
<li>Spatio-temporal receptive fields &amp; bandpass</li>
<li>Neural responses to movies</li>
</ul>
</a>
<a class="list-group-item" href="./vistalab.html#csfs">
<h4 class="list-group-item-heading" style="color:rgb(0,150,200)">* Spatio-temporal Contrast Sensitivities</h4>
<ul>
<li>Spatial Standard Observer: achromatic and chromatic</li>
<li>Statio-temporal CSF: with and without saccade control</li>
<li>Speed sensitivity with object tracking</li>
</ul>
</a>
<a class="list-group-item" href="./vistalab.html#movies">
<h4 class="list-group-item-heading" style="color:rgb(0,150,200)">* Controlled spatio-temporal patterns</h4>
</a>
<a class="list-group-item" href="./vistalab.html#extensions">
<h4 class="list-group-item-heading" style="color:rgb(0,150,200)"><strong>Extensions of VistaLab:</strong></h4>
<ul>
<li style="color:rgb(0,150,200)"><strong>Motion Estimation:</strong> <span style="color:rgb(0,0,0)">perceptually weighted Optical Flow</span></li>
<li style="color:rgb(0,150,200)"><strong>Nonlinear Neural Interactions:</strong> <span style="color:rgb(0,0,0)">Divisive Normalization</span></li>
</ul>
</a>
<!------------
               <a href="#nonlinearities" class="list-group-item">
                        <h4 class="list-group-item-heading" style="color:rgb(0,150,200)">Extensions of <strong>VistaLab</strong></h4>
                        <p align="justify"> VistaLab provides basic spatio-temporal functions and the linear building-blocks of vision models. However,
                        nonlinear interactions between the linear sensors are addressed in the separate toolbox <a href="./colorlab.html"> <strong>VistaModels</strong></a>.
                        Luminance calibration is not included in <strong>VistaLab</strong>. Nevertheless, once the sequence is computed, color calibration is easily achievable using the companion software <a href="./colorlab.html"> <strong>COLORLAB</strong></a>


                        Warning!: while VistaLab leads to calibrated sequences in spatial texture and speed (when displayed in trustable video players -e.g. matlab implay and VLC video player-), the examples below are not quantitatively correct because they rely on animated gifs for the internet and observation distance is not controlled.
                       </p>
                 </a>
                ----------------->
<a class="list-group-item" href="./vistalab.html#download">
<h4 class="list-group-item-heading" style="color:rgb(255,50,50)"><strong>Download Code!</strong></h4>
</a>
<a class="list-group-item" href="./vistalab.html#references">
<h4 class="list-group-item-heading" style="color:rgb(0,150,200)"><strong>Citation and References</strong></h4>
</a>
</div>
</div>
</div>
<div class="col-md-3"> <!--------- esta columna esta preparada para meter 2 columnas -con el container y los co-md-6 pero al final la columna derecha esta sin usar y el tama�o esta a lo cerdo- -------->
<div class="container" style="width: 120%;text-align: left; margin-left: 30%; margin-right: auto;">
<div class="row">
<div class="col-md-6">
<div class="container" style="width: 130%;text-align: right; margin-left: -15%; margin-right: auto;">
<div class="row">
<div class="col-md-12" style="width: 110%;text-align: right; margin-top: -15%; margin-left: 10%; margin-right: auto;">
<div class="col-md-12" style="width: 250%;text-align: right; margin-left: -55%; margin-right: auto;">
<!-------------
                                              <img class="img-responsive" alt="" src="FT_sequence_noise.gif" />
                                              ---------------->
<img alt="" class="img-responsive" src="./vistalab_files/TF_noise.gif"/>
<p ;style="margin-top: -0%;text-align: left; margin-left: 15%" align="justify"><small>Two views of the 3D Fourier transform of the sequence at the left (the ft=0 plane is highlighted in blue). Note how the modification of texture and speed in the sequence implies different energy distributions in the Fourier domain. Accurate control of texture and speed of movies allows to saturate certain sensors and induce stronger aftereffcts. This is because the description of motion aftereffects [<a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/LaparraMalo15.pdf">Front. Human Neurosci. 15</a>] requires models of V1 sensors in the spatio-temporal Fourier domain with frequency-dependent cross-inhibition. </small>.</p><br/>
</div>

</div>
</div>
</div>
</div>
</div>
<div class="col-md-6">
</div>
</div>
</div>
</div>
</div>
<!-- %%%%%%%%%%%%%%%%%%%%% CUANDO PASE EL CHAPARRON VUELVE A INTRODUCIR EL NIVEL <h2> EN VERDE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<div class="row">
<div class="col-md-3">
</div>
<div class="col-md-6">
<!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LGN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<hr id="LGN"/><br/><br/>
<a href="./vistalab.html#Top"><small>Back to top</small></a>
<p align="justify"></p><h2><span class="label label-success">Retina and Lateral Geniculate Nucleus (LGN)</span></h2><p></p>
<p align="justify">Most of the Retinal Ganglion Cells and cells in the LGN can be modelled with center-surround receptive fields with monophasic or biphasic temporal response. VistaLab comes with a configurable implemenation of such receptive fields according to the general expressions in [Cai, Freeman, DeAngelis, J. Neurophysiol. 97]. Using these units it is easy to generate artificial retinas with arbitrary sampling [Martinez-Garcia et al. 16, Martinez-Garcia et al. 17].<br/>
               The examples below show (a) the receptive field of a representative neuron in the spatiotemporal and in the 3D Fourier domain, and (b) the response of a population of such neurons to a natural movie assuming uniform retinal sampling and spatial invariance of the receptive field. VistaLab allows explicit implementation of each sensor response using the scalar product by the corresponding receptive field to get rid of the uniform sampling and the convolution assumptions.</p>
<br/>
<div class="container" style="width: 180%;text-align: left; margin-left: -30%; margin-right: auto;">
<div class="row">
<div class="col-md-3">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Pulsating on-center LGN neuron:</span></strong>
<small>Receptive field (or impulse response) in the spatiotemporal domain, where white stands for excitation and black stands for inhibition.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/RF_LGN.gif"/>
</div>
<div class="col-md-4">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Temporal variation of spatial response:</span></strong>
<small>Center-surround excitation at the stimulus onset is followed by reversed sign response when stimulation vanishes.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/RF_LGN2.gif"/>
</div>
<div class="col-md-3">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Frequency selectivity:</span></strong>
<small>Band pass of this kind of neurons in the spatio-temporal Fourier domain. This is the Fourier transform of the receptive field at the left.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/sens_LGN.JPG"/>
</div>
</div>
</div>
<p align="center"><small>See Vistalab CODE to develop these examples <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/demo_cells.m"><span style="font-style: italic;">demo_cells.m</span></a></small></p>
<br/>
<div class="container" style="width: 120%;text-align: left; margin-left: 15%; margin-right: auto;">
<div class="row">
<div class="col-md-6">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Response of some LGN population to a natural stimulus:</span></strong>
<small>Assuming a spatially invariant population of LGN cells like the one depicted above uniformly covering the visual field, we can compute the response to a natural movie using plain convolution or product in the Fourier domain.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/response_LGN.gif"/>
</div>
</div>
</div>
<br/>
<div class="container" style="width: 180%;text-align: left; margin-left: -0%; margin-right: auto;">
<div class="row">
<div class="col-md-3">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Spectrum of the original sequence:</span></strong>
<small>each branch of the X represents an object moving with constant speed (i.e. comes from one of the waving hands)</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/spect1.JPG"/>
</div>
<div class="col-md-3">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Spectrum of the response:</span></strong>
<small>response was computed in the Fourier domain as the aplication of the band-pass filter function of this specific LGN population to the original spectrum.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/spect3.JPG"/>
</div>
</div>
</div>
<!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% V1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<hr id="V1"/><br/><br/>
<a href="./vistalab.html#Top"><small>Back to top</small></a>
<p align="justify"></p><h2><span class="label label-success">Primary Visual Cortex (V1)</span></h2><p></p>
<p align="justify">Simple cells in the V1 cortex can be modelled with Gabor-like receptive fields tuned to certain spatial and temporal frequencies. VistaLab comes with a configurable implemenation of such receptive fields according to the general expressions in [Daugman JOSA A 89, Simoncelli &amp; Heeger Vis. Res. 98]. Using these units it is easy to generate artificial cortex with arbitrary sampling [Martinez-Garcia et al. 17].<br/>
               The examples below show six representative neurons tuned to the same spatial frequencies (7 cpd) but different temporal frequencies 2, 7, and 10 Hz, both positive and negative.
               Eventhough there is no conclusive tuning to two-dimensional speed due to the aperture problem [Heeger JOSA 87], <span style="font-style: italic;">in the direction perpendicular to the grating</span>, these are tuned to 0.3, 1 and 1.5 degrees/sec respectively (both positive and negative).
               Figures show: (a) the receptive fields in the spatiotemporal and in the 3D Fourier domain, and (b) the response of a population of such neurons to a natural movie assuming uniform retinal sampling and spatial invariance of the receptive field. VistaLab allows explicit implementation of each sensor response using the scalar product by the corresponding receptive field to get rid of the uniform sampling and the convolution assumptions.</p>
<br/>
<div class="container" style="width: 180%;text-align: left; margin-left: -30%; margin-right: auto;">
<div class="row">
<div class="col-md-4">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Pulsating V1 neurons:</span></strong>
<small>Receptive fields (or impulse response) in the spatiotemporal domain, where white stands for excitation and black stands for inhibition. In this figure there are 2*3 replications of a 1 degree visual field. Each replication shows the receptive field of a neuron tuned to the (same) central location but different spatio-temporal frequency.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/RF_V1.gif"/>
<p align="center"><small>See Vistalab CODE to develop these examples <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/demo_cells.m"><span style="font-style: italic;">demo_cells.m</span></a></small></p>
</div>
<div class="col-md-7">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Temporal variation of spatial responses:</span></strong>
<small>In a surface of sensors of the corresponding kind, Gabor-like excitation/inhibition at the stimulus onset turns into travelling a wave that vanishes afterwards.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/RF_V12.gif"/>
</div>
</div>
</div>
<br/>
<div class="container" style="width: 180%;text-align: left; margin-left: -0%; margin-right: auto;">
<div class="row">
<div class="col-md-6">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Frequency selectivity:</span></strong>
<small>Band pass of the six considered neurons. This is the Fourier transform of the receptive fields shown above.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/sens_V1.JPG"/>
</div>
</div>
</div>
<br/>
<div class="container" style="width: 180%;text-align: left; margin-left: -0%; margin-right: auto;">
<div class="row">
<div class="col-md-6">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Response of the six V1 populations to a natural stimulus:</span></strong>
<small>Assuming a spatially invariant populations of V1 cells like the ones depicted above uniformly covering the visual field, we can compute their responses to a natural movie using plain convolution or product in the Fourier domain. In the figure we show the original stimulus and the six corresponding sets of responses.
                     Note how the different populations respond to qualitatively different features of the stimulus (hand going up/down, static objects of the right frequency), and note how the cells tuned to too high speed do not respond.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/response_V1.gif"/>
</div>
</div>
</div>
<!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% MT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<hr id="MT"/><br/><br/>
<a href="./vistalab.html#Top"><small>Back to top</small></a>
<p align="justify"></p><h2><span class="label label-success">Middle Temporal (MT) region</span></h2><p></p>
<p align="justify">Cells in the MT cortex receive projections from V1 cells aligned in a plane in the spatio-temporal Fourier domain. Therefore, they are narrow-band in speed tuning. VistaLab comes with a configurable implemenation of such receptive fields according to the general expressions in [Simoncelli &amp; Heeger Vis. Res. 98]. Using these units and a spatio-temporal window it is easy to generate artificial MT cortex with arbitrary sampling [Martinez-Garcia et al. 17].<br/>
               The examples below shows six representative sets of neurons tuned to tuned to speeds of 0.3, 1 and 1.5 degrees/sec respectively (both positive and negative).
               In this case while
               Figures show: (a) the receptive fields in 3D Fourier domain, the kind of features these cells are optimally tuned to, and (b) the response of a population of such neurons to a natural movie assuming uniform retinal sampling and spatial invariance of the receptive field. VistaLab allows explicit implementation of each sensor response using the scalar product by the corresponding receptive field to get rid of the uniform sampling and the convolution assumptions.</p>
<br/>
<br/>
<div class="container" style="width: 180%;text-align: left; margin-left: -0%; margin-right: auto;">
<div class="row">
<div class="col-md-6">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Frequency selectivity in MT:</span></strong>
<small>Band pass of the six considered kinds of neurons. These are the sum of narrow-band V1-like filters shown above. Only filters aligned according to well-defined speed planes are combined in each MT cell.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/sens_MT.JPG"/>
</div>
</div>
</div>
<div class="container" style="width: 180%;text-align: left; margin-left: -30%; margin-right: auto;">
<div class="row">
<div class="col-md-4">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Optimal patterns for MT neurons:</span></strong>
<small>These patterns were computed by injecting noise only in the band where the different cells are sensitive. Each replication shows the corresponding pattern (showing no specific spatial frequency content) but a markedly different speed.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/RF_MT.gif"/>
<p align="center"><small>See Vistalab CODE to develop these examples <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/demo_cells.m"><span style="font-style: italic;">demo_cells.m</span></a></small></p>
</div>
<div class="col-md-7">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Temporal variation of spatial responses:</span></strong>
<small>In surfaces of sensors of the considered kinds, the patterns at the left lead to noisy travelling waves.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/RF_MT2.gif"/>
</div>
</div>
</div>
<br/>
<div class="container" style="width: 180%;text-align: left; margin-left: -0%; margin-right: auto;">
<div class="row">
<div class="col-md-6">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Response of the six MT populations to a natural stimulus:</span></strong>
<small>Assuming a spatially invariant populations of MT cells like the ones depicted above uniformly covering the visual field, we can compute their responses to a natural movie using plain convolution or product in the Fourier domain. In the figure we show the original stimulus and the six corresponding sets of responses (where white means excitation, black means inhibition, and gray means spontaneous/basal response).
                     Note how the different populations respond to qualitatively different features of the stimulus (hand going up/down, static objects of the right frequency), and note how the cells tuned to too high speed do not respond.</small></p>
<img alt="" class="img-responsive" src="./vistalab_files/response_MT.gif"/>
</div>
</div>
</div>
<!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% CSF %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<hr id="csfs"/><br/><br/>
<a href="./vistalab.html#Top"><small>Back to top</small></a>
<p align="justify"></p><h2><span class="label label-success">Spatio-temporal Contrast Sensitivities</span></h2><p></p>
<p align="justify">VistaLab comes with different Contrast Sensitivity Functions (CSFs): (a) the spatial-achromatic CSF from the OSA Standard Spatial Observer
               [<a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/icip02.pdf">Watson &amp; Malo IEEE ICIP 02</a>], (b) the spatial-chromatic, Red-Green
               and Yellow-Blue CSFs of K. Mullen [Vis. Res. 85], with approrpiate scaling [<a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/2012b_Gutierrez_RPTSP_12c.PDF">Gutierrez et al. 12</a>], and (c) the achromatic spatio-temporal CSFs of D. Kelly [JOSA 79], and S. Daly (with object tracking speed compensation) [SPIE 98].</p>
<table border="0" cellpadding="2" cellspacing="2" style="width: 90%; text-align: left; margin-left: auto; margin-right: auto;">
<tbody>
<tr align="justify">
<td colspan="2" rowspan="1">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Spatial-only Achromatic and Chromatic CSFs: </span></strong><small>The achromatic CSF of the Standard Spatial Observer includes the oblique effect. The chromatic CSFs are assumed to be isotropic.</small></p></td></tr>
<tr align="center"><td colspan="2" rowspan="1">
<img alt="a" class="img-responsive" src="./vistalab_files/csfs.JPG"/>
</td>
</tr>
</tbody></table><table border="0" cellpadding="2" cellspacing="2" style="width: 90%; text-align: left; margin-left: auto; margin-right: auto;">
<tbody>
<tr align="justify">
<td colspan="2" rowspan="1">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Spatial-only CSFs on a natural image: </span></strong><small>VistaLab applied together with COLORLAB allows accurate application of the spatial CSFs. In this example the natural image was first represented in CIE XYZ values. Then, it was transformed to a sensible linear Y, RG, YB representation [Ingling&amp;Tsou, Vis. Res. 79], and then, each CSF was applied to the corresponding chromatic channel. The result was expressed in digital values to be shown in regular diaplays.</small></p></td></tr>
<tr align="center"><td colspan="2" rowspan="1">
<img alt="a" class="img-responsive" src="./vistalab_files/applyCSF.JPG"/>
</td>
</tr>
</tbody></table><table border="0" cellpadding="2" cellspacing="2" style="width: 90%; text-align: left; margin-left: auto; margin-right: auto;">
<tbody>
<tr align="justify">
<td colspan="2" rowspan="1">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Spatio-temporal CSF (with saccade compensation):</span></strong><small>in the motion-compensated case sensitivity to stationary patterns decreases a lot (note the reduction of the CSF at ft=0). Below you can see three different representations of this function.</small></p></td></tr>
<tr align="center"><td colspan="2" rowspan="1">
<img alt="a" class="img-responsive" src="./vistalab_files/csf_st.JPG"/>
</td>
</tr>
</tbody></table><table border="0" cellpadding="2" cellspacing="2" style="width: 65%; text-align: left; margin-left: auto; margin-right: auto;">
<tbody>
<tr align="justify">
<td colspan="2" rowspan="1">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Natural movie filtered by spatio-temporal CSF.</span></strong></p></td></tr>
<tr align="center"><td colspan="2" rowspan="1">
<img alt="a" class="img-responsive" src="./vistalab_files/response_CSF.gif"/>
</td>
</tr>
</tbody></table><hr id="movies"/><br/><br/><a href="./vistalab.html#Top"><small>Back to top</small></a><p align="justify"></p><h2><span class="label label-success">Controlled spatio-temporal stimuli</span></h2><p></p><p align="justify">The movies below illustrate the abilities of VistaLab for accurate motion control. <strong>First row:</strong> includes sequences of the motion of a lambertian rigid body evolving in a gravitatory field with inelastic restrictions recorded from different points of view, this example allows arbitrary locations of the illumination and camera. In this case the actual motion in 3D world and the optical flow (motion in the retinal plane) are known. <strong>Second row:</strong> includes an example of random dots moving according to arbitrary optical flow fields. <strong>Third row:</strong> shows how static pictures can be animated using spatially uniform flows of arbitrary speed leading to interesting shape-from-motion effects in the case of noise patterns. <strong>Fourth row:</strong> shows different movies of the same periodic pattern moving at progressively increasing speeds. Aliasing introduces speed reversal at the expected place, as demonstrated by the Fourier diagrams below.</p><table border="0" cellpadding="2" cellspacing="2" style="width: 120%; text-align: left; margin-left: -10%; margin-right: auto;">
<tbody>
<tr align="justify">
<td colspan="2" rowspan="1">
</td></tr><tr align="center"><td colspan="2" rowspan="1">
<img alt="a" class="img-responsive" src="./vistalab_files/gema1.gif"/>
</td>
</tr>
<!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% MOVIES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
</tbody></table><table border="0" cellpadding="2" cellspacing="2" style="width: 95%; text-align: -30%; margin-left: auto; margin-right: auto;">
<tbody>
<tr align="left"><td colspan="2" rowspan="1">
<img alt="a" class="img-responsive" src="./vistalab_files/aliasing.JPG"/>
<p align="justify"><strong><span style="color:rgb(0,160,0)">Speed reversal in the Fourier domain:</span></strong><small>
               In the periodic pattern sequences all the sinusoidal components were computed to travel to the right with the same speed. However, in the last (high speed) case, the high frequency pattern seems to go backwards. Aliasing suffered by this component in this case is easy to understand in the Fourier domain. According to the optical flow equation in the Fourier domain [Watson &amp; Ahumada, JOSA A 85], when the speed increases (in our case from left to right) so it does the inclination of all the sinusoidal components of the sequence in the fx, ft plane.
               For low speeds all the components are aligned. However, when the speed is too high, the high frequency components have temporal frequencies over the Nyquist limit. This implies an apparent inclination for those frequencies which is totally oposed to the rest of the components, and hence, speed reversal. NOTE: the spatial extent of the discrete domain is 2 deg, and the frame rate is 20 Hz, the spatial frequency of the high frequency component is 10 cpd, and the actual speed in the last case should be 1.5 deg/sec.</small></p>
</td>
</tr>
</tbody>
</table>
<!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% EXTENSIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -->
<hr id="extensions"/><br/><br/>
<a href="./vistalab.html#Top"><small>Back to top</small></a>
<p align="justify"></p><h2><span class="label label-success">Extensions of VistaLab</span></h2><p></p>
<p align="justify">VistaLab only addresses the linear part of the neural mechanisms that mediate the preattentive perception of spatio-temporal patterns. However, it doesnt combine these mechanisms to compute <strong>motion (optical flow)</strong>, it doesnt include the <strong>nonlinear interactions</strong> between the linear mechanisms, and it doesnt include <strong>color</strong>.<br/>
               These issues can be addressed with other toolboxes, namely <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/VistaVideoCoding.zip">VistaVideoCoding</a>, <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/BioMultiLayer_L_NL_color.zip">BioMultiLayer_L_NL_color in VistaModels</a>, and <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Colorlab.zip">Colorlab</a>.</p>
<p align="justify"></p><h3><span class="label label-warning">Perceptually meaningful motion fields</span></h3><p></p>
<br/><hr id="download"/><br/><br/><a href="./vistalab.html#Top"><small>Back to top</small></a><p align="justify"></p><h2><span class="label label-danger">Download VistaLab!</span></h2><p></p><ul>
<li> <strong><span style="color:rgb(255,0,0)">Updated Matlab Toolbox (VistaLab 4.0):</span> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Vistalab.zip"> Vistalab.zip (30MB) </a></strong><a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Vistalab.zip"> </a> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Vistalab.zip"><img alt="mat" src="./vistalab_files/matlab_ico.gif" style="border: 0px solid ; width: 21px; height: 20px;"/></a>
</li><li> <strong>Outdated toolbox  (VistaLab 1.0): <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/BasicVideoTools_code.zip"> BasicVideoTools_code.zip (15MB) </a></strong><a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/BasicVideoTools_code.zip"> </a> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/BasicVideoTools_code.zip"><img alt="mat" src="./vistalab_files/matlab_ico.gif" style="border: 0px solid ; width: 21px; height: 20px;"/></a> <br/> The first stand alone version of VistaLab was known as BasicVideoTools. This outdated version is included here only for compatibility with the code in the experiments of the motion-aftereffect <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2015.00557/full">Front. Human Neurosci. 15 paper</a>.
             </li><li> <strong><span style="color:rgb(255,0,0)">Extensions of VistaLab I: VistaVideoCoding</span> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/VistaVideoCoding.zip">VistaVideoCoding.zip (60MB) </a></strong><a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/VistaVideoCoding.zip"> </a> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/VistaVideoCoding.zip"><img alt="mat" src="./vistalab_files/matlab_ico.gif" style="border: 0px solid ; width: 21px; height: 20px;"/></a>
</li><li> <strong><span style="color:rgb(255,0,0)">Extensions of VistaLab II: VistaModels</span> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/BioMultiLayer_L_NL_color.zip">BioMultiLayer_L_NL_color.zip (40MB) </a></strong><a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/BioMultiLayer_L_NL_color.zip"> </a> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/BioMultiLayer_L_NL_color.zip"><img alt="mat" src="./vistalab_files/matlab_ico.gif" style="border: 0px solid ; width: 21px; height: 20px;"/></a>
</li><li> <strong><span style="color:rgb(255,0,0)">Extensions of VistaLab III: COLORLAB</span> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Colorlab.zip">Colorlab.zip (15MB) </a></strong><a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Colorlab.zip"> </a> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/Colorlab.zip"><img alt="mat" src="./vistalab_files/matlab_ico.gif" style="border: 0px solid ; width: 21px; height: 20px;"/></a>
</li></ul><hr id="references"/><br/><br/><a href="./vistalab.html#Top"><small>Back to top</small></a><p align="justify"></p><h2><span class="label label-success">Citation and References</span></h2><p></p><p align="justify">VistaLab is released free of charge for the scientific community: please cite us when using the software (both the web site and first journal paper that used VistaLab)<br/><br/>
</p><p align="justify"><strong><span style="color:rgb(0,160,0)">WEB: </span></strong></p><strong>J. Malo &amp; J. Gutierrez. <br/> VistaLab: the Matlab toolbox for Spatio-Temporal Vision. Univ. Valencia 1997<br/>
<a href="./vistalab.html">https://ipl-uv.github.io/code/visioncolor/vistalab.html</a></strong><p></p><br/><p align="justify"><strong><span style="color:rgb(0,160,0)">FIRST PAPER: </span></strong></p><strong> Malo, Gutiérrez, Epifanio, Ferri,<br/> <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/ELECT98.PS.gz">Perceptually weighted optical flow for motion-based  segmentation in MPEG-4 paradigm.</a> Electr. Lett. 36 (20):1693-1694 (2000)</strong><a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/ELECT98.PS.gz"><img alt="mat" src="./vistalab_files/pdf16x16.gif" style="border: 0px solid ; width: 16px; height: 16px;"/></a><br/><br/><p align="justify"><strong><span style="color:rgb(0,160,0)">Other papers: </span></strong></p>
       V. Laparra &amp; J. Malo.<br/><a href="https://www.frontiersin.org/articles/10.3389/fnhum.2015.00557/full">Visual aftereffects and sensory nonlinearities from a single statistical framework</a> Frontiers in Human Neuroscience 9:557 (2015) <a href="https://huggingface.co/datasets/isp-uv-es/Web_site_legacy/resolve/main/code/soft_visioncolor/LaparraMalo15.pdf"><img alt="mat" src="./vistalab_files/pdf16x16.gif" style="border: 0px solid ; width: 16px; height: 16px;"/></a><br/><br/><br/><br/><br/><br/><br/><div class="col-md-3">
</div><table border="0" cellpadding="2" cellspacing="2" style="width: 120%; text-align: left; margin-left: auto; margin-right: auto;">
<tbody>
<tr align="justify">
<td colspan="2" rowspan="1">
<p align="justify"><strong><span style="color:rgb(0,160,0)">Optical flow in VistaVideoCoding: </span></strong><small>this separate toolbox provides different motion estimation algorithms for MPEG-like video coders. We proposed improvements to multiscale flows based on perceptual criteria to increase the resolution of the motion estimate [Malo98, Malo00a, Malo00b, Malo01a, Malo01b].</small></p></td></tr>
<!-- /.container -->
<!-- Bootstrap core JavaScript
    ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="./vistalab_files/jquery-1.12.4.min.js"></script>
<script src="./vistalab_files/bootstrap.min.js"></script>
</tbody></table></div></div></body></html>