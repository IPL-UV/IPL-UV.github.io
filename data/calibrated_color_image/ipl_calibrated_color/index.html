<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous onerror='this.onerror=null,this.href="css/bootstrap.min.css"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer onerror='this.onerror=null,this.href="css/all.min.css"'><link rel="shortcut icon" href=/images/isp_ico.webp type=image/x-icon><link id=kenmore-font rel=stylesheet href=https://fonts.cdnfonts.com/css/twentieth-century-for-kenmore onerror='this.onerror=null,this.href="css/fonts/TwentiethCentury/fonts.css"'><link rel=stylesheet href=/css/style.css><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js onerror='this.onerror=null,this.src="js/marked.min.js"'></script><script src=/js/mode.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-D8CVQKS51G"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D8CVQKS51G")</script></head><body><nav class=custom-navbars><div class=custom-container><a href=/ class="custom-logo custom-hide-on-large"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" class=custom-logo_nav>
<span class=custom-text-isp>ISP</span>
</a><button class=navbar-toggler aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class=custom-navbar-collapse><ul class=custom-navbar-nav><li class="custom-nav-item custom-desktop-only"><a class=custom-nav-link href=/>ISP</a></li><li class=custom-nav-item><a class=custom-nav-link href=/people/>People</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/research/philosophy/>Research</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/research/philosophy/>Philosophy</a></li><li><a class=custom-dropdown-item href=/research/machine_learning/>Machine learning</a></li><li><a class=custom-dropdown-item href=/research/visual_neuroscience/>Visual science</a></li><li><a class=custom-dropdown-item href=/research/visual_brain/>Image processing</a></li><li><a class=custom-dropdown-item href=/research/earth_science/>Earth science</a></li><li><a class=custom-dropdown-item href=/research/social_science>Social science</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/projects/>Projects</a></li><li class=custom-nav-item><a class=custom-nav-link href=/facilities/>Facilities</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/publications/journals/>Publications</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/publications/journals/>Journals</a></li><li><a class=custom-dropdown-item href=/publications/conferences/>Conferences</a></li><li><a class=custom-dropdown-item href=/publications/books/>Books</a></li><li><a class=custom-dropdown-item href=/publications/talks/>Talks</a></li><li><a class=custom-dropdown-item href=/publications/theses/>Theses</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/code/>Code</a></li><li class=custom-nav-item><a class=custom-nav-link href=/data/>Data</a></li><li class=custom-nav-item><a class=custom-nav-link href=/seminars/>Seminars</a></li><li class=custom-nav-item><a class=custom-nav-link href=/courses/>Courses</a></li><li class=custom-nav-item><a class=custom-nav-link href=/collaborators/>Collaborators</a></li><li class=custom-nav-item><a class=custom-nav-link href=/news/>News</a></li><li class=custom-nav-item><a class=custom-nav-link href=/contact/>Contact</a></li></ul></div></div></nav><main><div class=container><div class=content-container><div class=grid-container id=grid-container><div class=grid-item><a href><img src=/images/data alt="IPL Calibrated Color Image Database"></a><div class=text><a href class=nameLink_a>IPL Calibrated Color Image Database</a><p><script>function superSize(e){e.style.height=e.contentWindow.document.body.scrollHeight+20+"px"}</script><div style="max-width:10000px;margin:0 auto"><iframe src=/pages/data_color.htm style=border:0 width=100% height=1000 referrerpolicy=same-origin seamless onload=superSize(this)></iframe></div></p></div></div><div class=grid-item><a href><img src=/images/data alt="IPL Calibrated Color Image Database"></a><div class=text><a href class=nameLink_a>IPL Calibrated Color Image Database</a><p><h1 id=table-of-contents>Table of Contents</h1><ul><li><a href=#about-the-color-image-database>About the Color Image Database</a></li><li><a href=#why-a-new-color-image-database>Why a New Color Image Database?</a></li><li><a href=#calibration-and-experimental-procedure>Calibration and Experimental Procedure</a></li><li><a href=#organization-of-the-database>Organization of the Database</a></li></ul><h1 id=about-the-color-image-database>About the Color Image Database</h1><p>The database consists of <strong>130 calibrated color images</strong> of <strong>natural objects</strong> under <strong>calibrated illuminations</strong>:</p><ul><li><strong>Calibrated images</strong>: images are given in CIE XYZ tristimulus values.</li><li><strong>Natural objects</strong>: imply complex textures, mutual illumination, and shadows, which induce non-linear effects in the tristimulus values.</li><li><strong>Calibrated illuminations</strong>: include diffuse CIE D65 and diffuse CIE A illuminant.</li></ul><p>The database is suitable for accurate studies on <strong>color image statistics</strong>, <strong>chromatic adaptation</strong> in natural environments, and <strong>color constancy</strong>.</p><h1 id=why-a-new-color-image-database>Why a New Color Image Database?</h1><p>This color image database was collected in the context of a <strong>chromatic adaptation study</strong> based on <strong>color statistics</strong>. The following facts are relevant:</p><ul><li>The proper way to describe the physical input to any (artificial or human) visual system involves either (i) absolute radiances, hyperspectral images, or (ii) absolute tristimulus images.</li><li>Even if the spectral reflectance of objects is known, the simple flat-Lambertian world assumption is not valid due to <strong>mutual illumination</strong>, <strong>shadows</strong>, and <strong>specular reflections</strong>.</li><li>Accurate results on chromatic adaptation, such as <strong>corresponding pairs</strong> data, require a continuous distribution of samples in the tristimulus space, which necessitates a wide enough ensemble of natural reflectances.</li></ul><p>Existing color databases have several limitations:</p><ul><li><strong>Uncalibrated data</strong> (digital counts from conventional cameras instead of radiances or tristimulus values).</li><li><strong>Spectroradiometric databases</strong> often do not include reflectance but estimate it using a white reference sample, and scenes may not be available under both CIE D65 and CIE A illuminants.</li><li>The above is also true for the available tristimulus image databases.</li></ul><p>Given these issues, this <strong>calibrated database</strong> includes a wide set of natural objects under a pair of calibrated illuminants.</p><h1 id=calibration-and-experimental-procedure>Calibration and Experimental Procedure</h1><p>The images were taken using a <strong>Macbeth Executive light chamber</strong> equipped with standard <strong>CIE D65</strong> and <strong>CIE A</strong> illuminants, and a calibrated image colorimeter <strong>Lumicam1300</strong>. Key details:</p><ul><li><strong>Exposure time</strong> for each filter (X, Y, Z) was adjusted to avoid over or under-exposure, ensuring optimal operating range for the camera.</li><li>Pictures with <strong>misregistered channels</strong> (due to motion) or scenes outside the camera&rsquo;s operating range were discarded.</li></ul><p>Accuracy was verified by capturing 10 hue pages of the <strong>Munsell Book of Color</strong> and comparing the measured <strong>CIE xy chromaticities</strong> with theoretical values computed from known reflectances. The accuracy of <strong>luminance</strong> was roughly within the limits provided by the manufacturer (~3%).</p><h1 id=organization-of-the-database>Organization of the Database</h1><p>The database includes <strong>65 different scenes of natural objects</strong> under two illuminants (<strong>130 images</strong>) plus <strong>10 scenes</strong> displaying different hue pages of the <strong>Munsell Book of Color</strong> (<strong>20 images</strong>). The image size is <strong>1000x1280 pixels</strong>. The images are classified as follows:</p><h2 id=download-the-complete-dataset-all-the-above-files>Download the complete dataset (all the above files):</h2><p>Images (MATLAB arrays of size <strong>1000x1280x3</strong>) are stored in a MATLAB structure in each of the corresponding <strong><code>.mat</code></strong> files above. Images in the structure are sorted according to the order in the pictures below. Chromatic diagrams with all the colors in each set are also shown below.</p></p></div></div></div><p>The databse consists of 130 calibrated colour images of natural objects under calibrated illuminations.</p></div></div></main><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script></body></html>