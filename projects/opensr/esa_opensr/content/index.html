<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous onerror='this.onerror=null,this.href="css/bootstrap.min.css"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer onerror='this.onerror=null,this.href="css/all.min.css"'><link rel="shortcut icon" href=/images/isp_ico.webp type=image/x-icon><link id=kenmore-font rel=stylesheet href=https://fonts.cdnfonts.com/css/twentieth-century-for-kenmore onerror='this.onerror=null,this.href="css/fonts/TwentiethCentury/fonts.css"'><link rel=stylesheet href=/css/style.css><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js onerror='this.onerror=null,this.src="js/marked.min.js"'></script><script src=/js/mode.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-D8CVQKS51G"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D8CVQKS51G")</script></head><body><nav class=custom-navbars><div class=custom-container><a href=/ class="custom-logo custom-hide-on-large"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" class=custom-logo_nav>
<span class=custom-text-isp>ISP</span>
</a><button class=navbar-toggler aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class=custom-navbar-collapse><ul class=custom-navbar-nav><li class="custom-nav-item custom-desktop-only"><a class=custom-nav-link href=/>ISP</a></li><li class=custom-nav-item><a class=custom-nav-link href=/people/>People</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/research/philosophy/>Research</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/research/machine_learning/>Machine learning</a></li><li><a class=custom-dropdown-item href=/research/visual_neuroscience/>Visual science</a></li><li><a class=custom-dropdown-item href=/research/visual_brain/>Image processing</a></li><li><a class=custom-dropdown-item href=/research/earth_science/>Earth science</a></li><li><a class=custom-dropdown-item href=/research/social_science>Social science</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/projects/>Projects</a></li><li class=custom-nav-item><a class=custom-nav-link href=/facilities/>Facilities</a></li><li class="custom-nav-item custom-dropdown"><a class="custom-nav-link custom-dropdown-toggle" href=/publications/journals/>Publications</a><ul class=custom-dropdown-menu><li><a class=custom-dropdown-item href=/publications/journals/>Journals</a></li><li><a class=custom-dropdown-item href=/publications/conferences/>Conferences</a></li><li><a class=custom-dropdown-item href=/publications/books/>Books</a></li><li><a class=custom-dropdown-item href=/publications/talks/>Talks</a></li><li><a class=custom-dropdown-item href=/publications/theses/>Theses</a></li></ul></li><li class=custom-nav-item><a class=custom-nav-link href=/code/>Code</a></li><li class=custom-nav-item><a class=custom-nav-link href=/data/>Data</a></li><li class=custom-nav-item><a class=custom-nav-link href=/seminars/>Seminars</a></li><li class=custom-nav-item><a class=custom-nav-link href=/courses/>Courses</a></li><li class=custom-nav-item><a class=custom-nav-link href=/collaborators/>Collaborators</a></li><li class=custom-nav-item><a class=custom-nav-link href=/news/>News</a></li><li class=custom-nav-item><a class=custom-nav-link href=/contact/>Contact</a></li></ul></div></div></nav><main><div class=container><div class="content-container grid-layout"><div class=box-single><h1>Towards Explainable AI: Application to Trustworthy Super-Resolution</h1></div><div class=box-content><p><p><strong>Keywords:</strong> artificial intelligence (AI), machine learning (ML), explainable AI (xAI), super-resolution (SR), remote sensing (RS), Earth observation (EO), Sentinel-2 (S2).</p><p>OpenSR is a research project funded by the European Space Agency (ESA) in the framework of the Artificial Intelligence for Earth Observation (AI4EO) initiative of ESA Î¦-lab. This activity will focus on AI-empowered Super Resolution techniques for Sentinel-2 and will be demonstrated through a suite of downstream applications.</p><p>OpenSR aims to bring robust, accountable, and scalable multi-spectral super-resolution techniques to the Earth Observation (EO) community for the ubiquitous L2 and L3 pre-processing of the Sentinel-2 (S2) products. Super-resolution (SR) is a nascent technology and the roadmap to maturity will require insights from many disciplines. We understand that super-resolution is not just about image generation, but also degradation: how much is lost in pixelation. To shift the public perception on the safety of SR-S2 products, we will provide uncertainty and quality metrics along with the SR products; establish and disseminate best practices through new methods and tools that will be open to everyone.</p><br><p align=center><img src=/images/projects/low_hr.webp width=80%></p><br><p>The project will push the boundaries of excellence science and technological development of SR in remote sensing, by creating a set of tools, platform, and guidelines:</p><ul><li>Tools of state-of-the-art SR, Explainable AI (xAI), saliency and information metrics.</li><li>An open WebGIS platform that goes beyond standard solutions by working directly on Analysis Ready Data stored in a datacube. The platform will bring SR S2 data at the fingertips of users, allow for interactive data exploration, analysis and combination of SR S2 and other data, and even on-the-fly execution of xAI models on S2 data. It will provide access to the data from a number of use cases illustrating different real-world problems and showcasing how applications benefit from the combined action of SR and xAI, and their limits.</li><li>A set of guidelines and best practices that summarize an accountable and reproducible SR pipeline for successful applications.</li></ul><h2 id=news>News</h2><ul><li><a href=https://eo4society.esa.int/projects/opensr/>ESA project Towards Explainable AI: Application to Trustworthy Super-Resolution</a></li><li><a href=https://eo4society.esa.int/projects/opensr/>The project activities started with the Kick-off meeting on May 18th, 2022</a></li><li><a href=https://lps22.eu/>Freddie Kalaitzis and Nicolas Longepe discussed about &ldquo;Demystifying Super Resolution in EO: Hype or Hope?&rdquo; at the ESA Living Planet Symposium (LPS2022)</a></li><li><a href=../../../../people/>Cesar Aybar and Simon Donike have joined the OpenSR team at the Image Processing Laboratory (ISP-UV)</a></li></ul><br><p align=center><img src=/images/projects/groups_2.webp width=50%></p></p></div></div></main><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script></body></html>