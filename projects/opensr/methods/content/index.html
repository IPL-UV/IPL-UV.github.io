<!doctype html><html lang=en-us dir=ltr><head><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ISP - Image and Signal Processing group</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin=anonymous referrerpolicy=no-referrer><link rel="shortcut icon" href=http://isp.uv.es/favicon.ico type=image/x-icon><link rel=stylesheet href=/style/style.css><script src=/js/mode.js></script><script src=https://cdn.jsdelivr.net/npm/marked/marked.min.js></script></head></head><nav class="navbar navbar-expand-lg bg-body-tertiary fixed-top"><div class=container-fluid><a href=/ class="d-lg-none d-flex align-items-center a_logonav"><img src=/images/isp_logo_sinfondo.webp alt="ISP Icon" height=30 class=logo_nav>
<span class="ms-2 text-isp">ISP</span>
</a><button class="navbar-toggler ms-auto" type=button data-bs-toggle=collapse data-bs-target=#navbarTogglerDemo01 aria-controls=navbarTogglerDemo01 aria-expanded=false aria-label="Toggle navigation" style=height:40px>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarTogglerDemo01><ul class="navbar-nav mx-auto mb-lg-0"><li class="nav-item px-2 nav-item-highlight d-none d-lg-block"><a class="nav-link a" aria-current=page href=/github/>ISP</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/people/>People</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle a" href=/github/research/ id=navbarDropdownResearch role=button aria-expanded=false>Research</a><ul class=dropdown-menu aria-labelledby=navbarDropdownResearch><li><a class="dropdown-item a" href=/github/research/machine_learning/>Machine learning</a></li><li><a class="dropdown-item a" href=/github/research/visual_neuroscience/>Visual neuroscience</a></li><li><a class="dropdown-item a" href=/github/research/visual_brain/>Visual brain</a></li><li><a class="dropdown-item a" href=/github/research/earth_science/>Earth science</a></li><li><a class="dropdown-item a" href=/github/research/social_science>Social science</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/projects/>Projects</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/facilities/>Facilities</a></li><li class="nav-item dropdown px-2 nav-item-highlight"><a class="nav-link dropdown-toggle a" href=/github/publications/journals/ id=navbarDropdownPublications role=button aria-expanded=false>Publications</a><ul class=dropdown-menu aria-labelledby=navbarDropdownPublications><li><a class="dropdown-item a" href=/github/publications/journals/>Journals</a></li><li><a class="dropdown-item a" href=/github/publications/conferences/>Conferences</a></li><li><a class="dropdown-item a" href=/github/publications/books/>Books</a></li><li><a class="dropdown-item a" href=/github/publications/talks/>Talks</a></li><li><a class="dropdown-item a" href=/github/publications/technical_reports/>Technical Reports</a></li><li><a class="dropdown-item a" href=/github/publications/theses/>Theses</a></li></ul></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/code/>Code</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/data/>Data</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/seminars/>Seminars</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/courses/>Courses</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/collaborators/>Collaborators</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/news/>News</a></li><li class="nav-item px-2 nav-item-highlight"><a class="nav-link a" aria-current=page href=/github/contact/>Contact</a></li></ul></div></div></nav><style>.navbar{--bs-navbar-padding-y:0rem !important;background-color:#222!important}.a{color:#949494!important}.a:hover{color:#fff!important}.nav-item-highlight{padding:.4rem}.nav-item-highlight:hover{background-color:#2d70aa!important}.dropdown-menu{background-color:#333!important;color:#fff!important;display:block}.dropdown-item{color:#949494!important}.dropdown-item:hover{background-color:#2d70aa!important;color:#fff!important}.navbar-nav li.nav-item .nav-link,.dropdown-menu .dropdown-item{transition:color .3s,background-color .3s}.nav-link.active,.dropdown-item.active{color:#fff!important;background-color:#007bff!important}.navbar-toggler-icon{background-image:url("data:image/svg+xml,%3csvg viewBox='0 0 30 30' xmlns='http://www.w3.org/2000/svg'%3e%3cpath stroke='white' stroke-width='2' stroke-linecap='round' stroke-miterlimit='10' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e")}.navbar-toggler{border:none}.navbar-toggler:focus{outline:none}@media(min-width:992px){.dropdown-menu{display:none}.dropdown:hover .dropdown-menu{display:block}}@media(max-width:991px){.navbar-nav{max-height:calc(100vh - 56px);overflow-y:auto}.navbar-nav::-webkit-scrollbar{width:9px}.navbar-nav::-webkit-scrollbar-thumb{background-color:#888;border-radius:10px}.navbar-nav::-webkit-scrollbar-thumb:hover{background-color:#555}.navbar-nav .nav-link{font-size:1.2rem}.dropdown-menu .dropdown-item{font-size:1rem}.dropdown-toggle::after{display:inline-block;margin-left:.255em;vertical-align:.255em;content:"";border-top:.3em solid;border-right:.3em solid transparent;border-bottom:0;border-left:.3em solid transparent}.navbar .dropdown-toggle::after{content:none!important}.navbar-toggler-icon{width:1.2em;height:1.2em}.navbar-toggler{border:none!important}.navbar-toggler:focus{box-shadow:none!important}.d-flex{height:45px}.a_logonav{text-decoration:none!important}.text-isp{font-size:1.3rem;color:#9d9d9d;display:inline-block;vertical-align:middle;text-decoration:none!important}.navbar-nav{max-height:calc(50vh - 56px);overflow-y:auto}}</style><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll(".navbar .dropdown");e.forEach(function(e){let t=e.querySelector(".dropdown-toggle");t.addEventListener("click",function(e){window.innerWidth<992&&e.target===t&&(window.location.href=t.href)});let n=e.querySelectorAll(".dropdown-item");n.forEach(function(e){e.addEventListener("click",function(){window.location.href=e.href})})}),document.addEventListener("click",function(t){window.innerWidth<992&&!t.target.closest(".navbar .dropdown")&&e.forEach(function(e){e.querySelector(".dropdown-menu").classList.remove("show")})})})</script><main><div class=container><div class="content-container grid-layout"><div class=box-single><h1>Methods and Models</h1></div><div class=box-content><p><h1 id=super-resolution-methodology>Super-Resolution Methodology</h1><p>Diffusion models have recently overtaken GAN models in the state-of-the-art of generative image methodologies. While GANs have been extensively used in image super-resolution, they are unstable due to their very delicate training process. Diffusion models, which are also probabilistic models drawing results from a likelihood distribution, have proven to be easier to train and deliver better results, surpassing other methodologies in many reconstruction metrics. This development has also been noticed in the remote sensing community, with recent super-resolution works switching to diffusion-based SR methodologies.</p><br><p align=center><img src=/images/projects/lat_px_dif.webp width=100%><p align=center><em>Figure: Pixel-space vs latent-space diffusion models</em></p></p><br><h1 id=explainable-ai>Explainable AI</h1><p>The use of deep learning in SR does not usually provide any insight besides the final outcome, which makes the EO community reluctant to adopt machine learning due to the lack of transparency and trust. Explainable artificial intelligence (xAI) aims to increase our understanding of DL models while preserving their predictive power. In OpenSR, we will provide quality indices and xAI tools for trusted and accountable SR. In particular, we will combine traditional model inspection and interpretation methods with more specific post-hoc methods. These quality metrics will be crystallized in a quality assurance band (BQA) accompanying the SR product.
Regarding the quality metrics and uncertainty estimation for remote sensing super-resolution, most of the proposed super-resolution algorithms utilize three commonly used metrics: PSNR, SSIM, and LPIPS. While these metrics are frequently reported in remote sensing super-resolution works, other types of degradation, such as chrominance differences or spatial shifts, might compromise the super-resolution evaluation scope. OpenSR will evaluate the entire super-resolution process with diferent metrics:</p><br><p align=center><img src=/images/projects/qualitymetrics.webp width=50%><p align=center><em>Figure: Quality metrics proposed to benchmark super-resolution algorithms</em></p></p><br><h1 id=benchmarking-toolbox>Benchmarking Toolbox</h1><p>Defining &lsquo;high-quality&rsquo; results in SR methodologies remains a controversial issue. Present-day literature of the field often presents SR techniques through the lens of computer vision, leaning heavily on synthetic datasets and metrics that are hyper-sensitive to factors unrelated to spatial resolution enhancement. To address this challenge, in OpenSR project we have created a comprehensive benchmark, OpenSR-test toolbox, designed exclusively for evaluating remote sensing image SR. Our framework incorporates quality metrics and three curated datasets, each spanning various scale factors with consistent metadata. The benchmarking framework will be publicly available at OpenSR-test.</p><br><p align=center><img src=/images/projects/opnsr-test.webp width=60%><p align=center><em>Figure: OpenSR-test benchmark for real-world Sentinel-2 imagery super-resolution.</em></p></p><br><p align=center><img src=/images/projects/groups_2.webp width=50%></p></p></div></div></main></body><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous defer></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js@1.0.0/src/bibtex_js.min.js defer></script></html>